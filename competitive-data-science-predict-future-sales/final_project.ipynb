{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Workflow\n",
    "1. Understand our data better in Exploratory Data Analysis\n",
    "\n",
    "2. Doing necessary data wrangling. Using sales from Oct 2015 as predictions for Nov 2015(Previous Value Benchmark)\n",
    "\n",
    "4. Baseline. Apply some variant of decision tree(without any feature engineering, compare this with previous value benchmark)\n",
    "\n",
    "5. Set up Cross Validation to try out different feature engineering ideas\n",
    "\n",
    "6. Tuning hyperparameters.\n",
    "\n",
    "7. Use Ensemble methods to boost score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: You are using pip version 19.1, however version 19.2.3 is available.\r\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip install keras-tqdm -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: You are using pip version 19.1, however version 19.2.3 is available.\r\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip install keras-rectified-adam -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "import warnings\n",
    "import os\n",
    "import gc\n",
    "import random\n",
    "import itertools\n",
    "import pickle\n",
    "import time\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "from datetime import datetime\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "# visualization \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# data preprocessing \n",
    "from itertools import product\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import missingno\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "# model\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from xgboost import plot_importance\n",
    "\n",
    "# eveluation \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import explained_variance_score\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "def reset_tf_session():\n",
    "    curr_session = tf.get_default_session()\n",
    "    # close current session\n",
    "    if curr_session is not None:\n",
    "        curr_session.close()\n",
    "    # reset graph\n",
    "    K.clear_session()\n",
    "    # create new session\n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.allow_growth = True\n",
    "    s = tf.InteractiveSession(config=config)\n",
    "    K.set_session(s)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,RepeatVector\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_encoding(data_x, data_y, feature, target):\n",
    "    data = pd.concat([data_x, data_y], axis=1)\n",
    "    prior_mean = np.mean(data[target].values)\n",
    "    enc_value = data.groupby(feature)[target].mean()\n",
    "    if isinstance(feature, list):\n",
    "        feature_name = 'enc_' + '_'.join(feature)\n",
    "        data_x[feature_name] = data_x[f].join(pd.DataFrame(enc_value), on=feature, how='left')[target]\n",
    "    else:\n",
    "        feature_name = 'enc_' + feature\n",
    "        data_x[feature_name] = data_x[feature].map(enc_value)    \n",
    "    return data_x, enc_value, prior_mean, feature_name\n",
    "\n",
    "def smooth_mean_encoding(data_x, data_y, feature, target, min_samples=1, smooth_method='stats_smooth'):\n",
    "    data = pd.concat([data_x, data_y], axis=1)\n",
    "    nrows = data.groupby(feature)[target].count()\n",
    "    target_mean = data.groupby(feature)[target].mean()\n",
    "    prior_mean = np.mean(data[target].values)    \n",
    "    if smooth_method == 'stats_smooth':\n",
    "        smooth_enc_value = (target_mean * nrows + prior_mean * min_samples) / (nrows + min_samples) \n",
    "    elif smooth_method == 'sigmoid_smooth':\n",
    "        smoothing_slope = 1\n",
    "        smooth_factor = 1 / (1 + np.exp(- (nrows - min_samples) / smoothing_slope))\n",
    "        smooth_enc_value = smooth_factor * target_mean + (1 - smooth_factor) * prior_mean        \n",
    "    if isinstance(feature, list):\n",
    "        feature_name = 'smooth_enc_' + '_'.join(feature)\n",
    "        data_x[feature_name] = data_x[f].join(pd.DataFrame(smooth_enc_value), on=feature, how='left')[target]\n",
    "    else:\n",
    "        feature_name = 'smooth_enc_' + feature\n",
    "        data_x[feature_name] = data_x[feature].map(smooth_enc_value)          \n",
    "    return data_x, smooth_enc_value, prior_mean, feature_name\n",
    "\n",
    "def beta_mean_encoding(data, feature, target, stats, prior_mean, N_min=5):\n",
    "    df_stats = pd.merge(data[[feature]], stats, how='left', on=feature)\n",
    "    df_stats['sum'].fillna(value=prior_mean, inplace = True)\n",
    "    df_stats['count'].fillna(value=1.0, inplace = True)    \n",
    "    N_prior = np.maximum(N_min - df_stats['count'].values, 0)   # prior parameters\n",
    "    df_stats[feature_name] = (prior_mean * N_prior + df_stats['sum']) / (N_prior + df_stats['count']) # Bayesian mean\n",
    "    \n",
    "    if isinstance(feature, list):\n",
    "        feature_name = 'mec_' + '_'.join(feature)\n",
    "        data[feature_name] = df_stats[feature_name].values\n",
    "    else:\n",
    "        feature_name = 'mec_' + feature\n",
    "        data[feature_name] = df_stats[feature_name].values         \n",
    "    return data, feature_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_future_sales_path = Path('../input/competitive-data-science-predict-future-sales')\n",
    "\n",
    "item_categories_data = pd.read_csv(str(predict_future_sales_path / 'item_categories.csv'), \n",
    "                                   dtype={'item_category_name': 'str', \n",
    "                                          'item_category_id': 'int32'})\n",
    "items_data = pd.read_csv(str(predict_future_sales_path / 'items.csv'), \n",
    "                         dtype={'item_name': 'str', \n",
    "                                'item_id': 'int32', \n",
    "                                'item_category_id': 'int32'})\n",
    "\n",
    "sales_data = pd.read_csv(str(predict_future_sales_path / 'sales_train.csv'),\n",
    "                         dtype={'date': 'str', \n",
    "                                'date_block_num': 'int32', \n",
    "                                'shop_id': 'int32', \n",
    "                                'item_id': 'int32', \n",
    "                                'item_price': 'float32', \n",
    "                                'item_cnt_day': 'int32'})\n",
    "\n",
    "shop_data = pd.read_csv(str(predict_future_sales_path / 'shops.csv'),\n",
    "                        dtype={'shop_name': 'str', \n",
    "                               'shop_id': 'int32'})\n",
    "\n",
    "test_data = pd.read_csv(str(predict_future_sales_path / 'test.csv'),\n",
    "                        dtype={'ID': 'int32', \n",
    "                               'shop_id': 'int32', \n",
    "                               'item_id': 'int32'})\n",
    "test_data.set_index('ID', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train data:2935849 \n",
      "Number of test data:214200\n"
     ]
    }
   ],
   "source": [
    "print('Number of train data:{} \\nNumber of test data:{}'.format(sales_data.shape[0], test_data.shape[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Number of good pairs: 111404\n",
      "2. No Data Items: 15246\n",
      "3. Only Item_id Info: 87550\n"
     ]
    }
   ],
   "source": [
    "good_sales = test_data.merge(sales_data, on=['item_id', 'shop_id'], how='left').dropna()\n",
    "good_pairs = test_data[test_data['ID'].isin(good_sales['ID'])]\n",
    "no_data_items = test_data[~(test_data['item_id'].isin(sales_data['item_id']))]\n",
    "\n",
    "print('1. Number of good pairs:', len(good_pairs))\n",
    "print('2. No Data Items:', len(no_data_items))\n",
    "print('3. Only Item_id Info:', len(test_data)-len(no_data_items)-len(good_pairs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Check missing value***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date              0\n",
       "date_block_num    0\n",
       "shop_id           0\n",
       "item_id           0\n",
       "item_price        0\n",
       "item_cnt_day      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date              0\n",
       "date_block_num    0\n",
       "shop_id           0\n",
       "item_id           0\n",
       "item_price        0\n",
       "item_cnt_day      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales_data.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Remove outlier***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_block_num</th>\n",
       "      <th>shop_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>item_price</th>\n",
       "      <th>item_cnt_day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2.935849e+06</td>\n",
       "      <td>2.935849e+06</td>\n",
       "      <td>2.935849e+06</td>\n",
       "      <td>2.935849e+06</td>\n",
       "      <td>2.935849e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.456991e+01</td>\n",
       "      <td>3.300173e+01</td>\n",
       "      <td>1.019723e+04</td>\n",
       "      <td>8.908532e+02</td>\n",
       "      <td>1.242641e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9.422988e+00</td>\n",
       "      <td>1.622697e+01</td>\n",
       "      <td>6.324297e+03</td>\n",
       "      <td>1.729800e+03</td>\n",
       "      <td>2.618834e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>-2.200000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>7.000000e+00</td>\n",
       "      <td>2.200000e+01</td>\n",
       "      <td>4.476000e+03</td>\n",
       "      <td>2.490000e+02</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.400000e+01</td>\n",
       "      <td>3.100000e+01</td>\n",
       "      <td>9.343000e+03</td>\n",
       "      <td>3.990000e+02</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.300000e+01</td>\n",
       "      <td>4.700000e+01</td>\n",
       "      <td>1.568400e+04</td>\n",
       "      <td>9.990000e+02</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.300000e+01</td>\n",
       "      <td>5.900000e+01</td>\n",
       "      <td>2.216900e+04</td>\n",
       "      <td>3.079800e+05</td>\n",
       "      <td>2.169000e+03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       date_block_num       shop_id       item_id    item_price  item_cnt_day\n",
       "count    2.935849e+06  2.935849e+06  2.935849e+06  2.935849e+06  2.935849e+06\n",
       "mean     1.456991e+01  3.300173e+01  1.019723e+04  8.908532e+02  1.242641e+00\n",
       "std      9.422988e+00  1.622697e+01  6.324297e+03  1.729800e+03  2.618834e+00\n",
       "min      0.000000e+00  0.000000e+00  0.000000e+00 -1.000000e+00 -2.200000e+01\n",
       "25%      7.000000e+00  2.200000e+01  4.476000e+03  2.490000e+02  1.000000e+00\n",
       "50%      1.400000e+01  3.100000e+01  9.343000e+03  3.990000e+02  1.000000e+00\n",
       "75%      2.300000e+01  4.700000e+01  1.568400e+04  9.990000e+02  1.000000e+00\n",
       "max      3.300000e+01  5.900000e+01  2.216900e+04  3.079800e+05  2.169000e+03"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fe920ed8940>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(-22, 2385.9)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fe920f47cc0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(-1.0, 338778.0)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(10, 6))\n",
    "sns.boxplot(x=sales_data['item_cnt_day'], ax=ax[0])\n",
    "ax[0].set_xlim([sales_data.item_cnt_day.min(), sales_data.item_cnt_day.max()*1.1])  \n",
    "\n",
    "sns.boxplot(x=sales_data['item_price'], ax=ax[1])\n",
    "ax[1].set_xlim([sales_data.item_price.min(), sales_data.item_price.max()*1.1])  \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How many number of item_price less than 0:0\n",
      "How many number of item_cnt_day less than 0: 7356\n"
     ]
    }
   ],
   "source": [
    "sales_data = sales_data[sales_data.item_price < 100000]\n",
    "sales_data = sales_data[sales_data.item_cnt_day < 1000]\n",
    "\n",
    "# replace the NA value of item price \n",
    "condition = (sales_data.shop_id == 32) & (sales_data.item_id == 2973)\n",
    "sales_data.loc[sales_data.item_price < 0, 'item_price'] = sales_data[condition]['item_price'].median()\n",
    "\n",
    "print('How many number of item_price less than 0:{}'.format(sales_data[sales_data.item_price < 0].shape[0]))   \n",
    "print('How many number of item_cnt_day less than 0: {}'.format(sales_data[sales_data.item_cnt_day < 0].shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Shops / Cats / Items preprocessing***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shop id 0 is as same as 57,  Якутск Орджоникидзе, 56\n",
    "# shop id 1 is as same as 58,  Якутск ТЦ \"Центральный\"\n",
    "# shop id 10 is as same as 11, Жуковский ул. Чкалова 39м²\n",
    "# change the shop_id\n",
    "sales_data.loc[sales_data.shop_id == 0, 'shop_id'] = 57\n",
    "test_data.loc[test_data.shop_id == 0, 'shop_id'] = 57\n",
    "\n",
    "sales_data.loc[sales_data.shop_id == 1, 'shop_id'] = 58\n",
    "test_data.loc[test_data.shop_id == 1, 'shop_id'] = 58\n",
    "\n",
    "sales_data.loc[sales_data.shop_id == 10, 'shop_id'] = 11\n",
    "test_data.loc[test_data.shop_id == 10, 'shop_id'] = 11\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60, 2) (22170, 3) (84, 2) (2935846, 6) (214200, 3)\n"
     ]
    }
   ],
   "source": [
    "print(shop_data.shape, items_data.shape, item_categories_data.shape, sales_data.shape, test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "shop_data.loc[shop_data.shop_name == 'Сергиев Посад ТЦ \"7Я\"', 'shop_name'] = 'СергиевПосад ТЦ \"7Я\"'\n",
    "\n",
    "shop_data['city'] = shop_data['shop_name'].apply(lambda x:x.split(' ')[0])\n",
    "shop_data.loc[shop_data.city == '!Якутск', 'city'] = 'Якутск'\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "shop_data['city_code'] = label_encoder.fit_transform(shop_data['city'])\n",
    "shop_data = shop_data[['shop_id', 'city_code']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splite item categories name to get item type\n",
    "item_categories_data['split'] = item_categories_data['item_category_name'].apply(lambda x:x.split('-'))\n",
    "item_categories_data['type'] = item_categories_data['split'].apply(lambda x:x[0].strip())\n",
    "item_categories_data['type_code'] = LabelEncoder().fit_transform(item_categories_data['type'])\n",
    "\n",
    "item_categories_data['subtype'] = item_categories_data['split'].apply(lambda x:x[1].strip() if len(x) > 1 else x[0].strip())\n",
    "item_categories_data['subtype_code'] = LabelEncoder().fit_transform(item_categories_data['subtype'])\n",
    "item_categories_data = item_categories_data[['item_category_id', 'type_code', 'subtype_code']]\n",
    "\n",
    "items_data.drop(['item_name'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_data['revenue'] = sales_data['item_price'] * sales_data['item_cnt_day']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For every month we create a grid from all shops/items combinations from that month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "matrix = []\n",
    "cols = ['date_block_num', 'shop_id','item_id']\n",
    "for i in range(34):\n",
    "    sales = sales_data[sales_data.date_block_num == i]\n",
    "    matrix.append(np.array(list(product([i], sales.shop_id.unique(), sales.item_id.unique())), dtype='int16'))\n",
    "    \n",
    "matrix = pd.DataFrame(np.vstack(matrix), columns=cols)\n",
    "matrix['date_block_num'] = matrix['date_block_num'].astype(np.int8)\n",
    "matrix['shop_id'] = matrix['shop_id'].astype(np.int8)\n",
    "matrix['item_id'] = matrix['item_id'].astype(np.int16)\n",
    "matrix.sort_values(cols, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of complete month of year for each shop_id and item_id: 10913804\n"
     ]
    }
   ],
   "source": [
    "print('Number of complete month of year for each shop_id and item_id: {}'.format(matrix.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_block_num</th>\n",
       "      <th>shop_id</th>\n",
       "      <th>item_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [date_block_num, shop_id, item_id]\n",
       "Index: []"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data check\n",
    "condition = (matrix.shop_id == 0) & (matrix.item_id == 0)\n",
    "matrix[condition]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Submissions are evaluated by root mean squared error (RMSE). True target values are clipped into [0,20] range.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "groupby_cols = ['shop_id', 'item_id', 'date_block_num']\n",
    "train_df = sales_data.groupby(groupby_cols).agg({\n",
    "    'item_cnt_day':['sum']\n",
    "}).reset_index()\n",
    "\n",
    "train_df.columns = ['_'.join(cols).strip() for cols in train_df.columns.values]\n",
    "train_df.rename({\n",
    "    'shop_id_': 'shop_id',\n",
    "    'item_id_': 'item_id',\n",
    "    'date_block_num_': 'date_block_num',\n",
    "    'item_cnt_day_sum': 'item_cnt_month'\n",
    "}, inplace=True, axis=1)\n",
    "\n",
    "matrix = pd.merge(matrix, train_df, on=groupby_cols, how='left')\n",
    "matrix['item_cnt_month'] = matrix['item_cnt_month'].fillna(0).clip(0, 20).astype(np.float16)\n",
    "                            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*merge other data info*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = pd.merge(matrix, shop_data, on=['shop_id'], how='left')\n",
    "matrix = pd.merge(matrix, items_data, on=['item_id'], how='left')\n",
    "matrix = pd.merge(matrix, item_categories_data, on=['item_category_id'], how='left')\n",
    "\n",
    "matrix['city_code'] = matrix['city_code'].astype(np.int8)\n",
    "matrix['item_category_id'] = matrix['item_category_id'].astype(np.int8)\n",
    "matrix['type_code'] = matrix['type_code'].astype(np.int8)\n",
    "matrix['subtype_code'] = matrix['subtype_code'].astype(np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data['date_block_num'] = 34\n",
    "test_data['date_block_num'] = test_data['date_block_num'].astype(np.int8)\n",
    "test_data['shop_id'] = test_data['shop_id'].astype(np.int8)\n",
    "test_data['item_id'] = test_data['item_id'].astype(np.int16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = pd.concat([matrix, test_data], ignore_index=True, sort=False, keys=groupby_cols)\n",
    "matrix.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_block_num</th>\n",
       "      <th>shop_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>item_cnt_month</th>\n",
       "      <th>city_code</th>\n",
       "      <th>item_category_id</th>\n",
       "      <th>type_code</th>\n",
       "      <th>subtype_code</th>\n",
       "      <th>ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>27</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>29</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   date_block_num  shop_id  item_id  item_cnt_month  city_code  \\\n",
       "0               0        2       19             0.0        0.0   \n",
       "1               0        2       27             1.0        0.0   \n",
       "2               0        2       28             0.0        0.0   \n",
       "3               0        2       29             0.0        0.0   \n",
       "4               0        2       32             0.0        0.0   \n",
       "\n",
       "   item_category_id  type_code  subtype_code   ID  \n",
       "0              40.0       11.0           4.0  0.0  \n",
       "1              19.0        5.0          10.0  0.0  \n",
       "2              30.0        8.0          55.0  0.0  \n",
       "3              23.0        5.0          16.0  0.0  \n",
       "4              40.0       11.0           4.0  0.0  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train + test data:11128004\n"
     ]
    }
   ],
   "source": [
    "print('Number of train + test data:{}'.format(matrix.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('all_month_data.pkl', 'wb') as handle:\n",
    "    pickle.dump(matrix, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Target lags*\n",
    "\n",
    "Lag 為此次比賽的關鍵 feature，因為是要預測下一個月的總量，所以用 Lags 可以彌補 `date_block_num:34` 所需要的資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "lags_list = list(range(1, 13))\n",
    "\n",
    "def lag_feature(df, lags, col):\n",
    "    start_time = time.time()\n",
    "    tmp = df[['date_block_num','shop_id','item_id', col]]\n",
    "    for i in lags:\n",
    "        shifted = tmp.copy()\n",
    "        shifted.columns = ['date_block_num','shop_id','item_id', col + '_lag_' + str(i)]\n",
    "        shifted['date_block_num'] += i\n",
    "        df = pd.merge(df, shifted, on=['date_block_num','shop_id','item_id'], how='left')\n",
    "        del shifted\n",
    "    end_time = time.time()    \n",
    "    print('Computing time:{}'.format(end_time - start_time))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing time:144.4366819858551\n"
     ]
    }
   ],
   "source": [
    "matrix = lag_feature(matrix, lags_list, 'item_cnt_month')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group based lag features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_count(data, group_cols, target_col, new_col_name, col_type):\n",
    "    print('[INFO] Count {} with group by {} combination...'.format(target_col, '-'.join(group_cols)))\n",
    "    cols = group_cols.copy()\n",
    "    cols.append(target_col)\n",
    "    group_data = data[cols].groupby(by=group_cols)[[target_col]].count()\\\n",
    "        .reset_index()\\\n",
    "        .rename(index=str, columns={target_col: new_col_name})\n",
    "    data = data.merge(group_data, on=group_cols, how='left')\n",
    "    del group_data\n",
    "    data[new_col_name] = data[new_col_name].astype(col_type)\n",
    "    gc.collect()\n",
    "    return data\n",
    "    \n",
    "def do_mean(data, group_cols, target_col, new_col_name, col_type):\n",
    "    print('[INFO] Compute mean {} with group by {} combination...'.format(target_col, '-'.join(group_cols)))\n",
    "    cols = group_cols.copy()\n",
    "    cols.append(target_col)\n",
    "    group_data = data[cols].groupby(by=group_cols)[[target_col]].mean()\\\n",
    "        .reset_index().rename(index=str, columns={target_col: new_col_name})\n",
    "    data = data.merge(group_data, on=group_cols, how='left')\n",
    "    del group_data\n",
    "    data[new_col_name] = data[new_col_name].astype(col_type)\n",
    "    gc.collect()\n",
    "    return data\n",
    "\n",
    "def do_sum(data, group_cols, target_col, new_col_name, col_type):\n",
    "    print('[INFO] Compute mean {} with group by {} combination...'.format(target_col, '-'.join(group_cols)))\n",
    "    cols = group_cols.copy()\n",
    "    cols.append(target_col)\n",
    "    group_data = data[cols].groupby(by=group_cols)[[target_col]].sum()\\\n",
    "        .reset_index().rename(index=str, columns={target_col: new_col_name})\n",
    "    data = data.merge(group_data, on=group_cols, how='left')\n",
    "    del group_data\n",
    "    data[new_col_name] = data[new_col_name].astype(col_type)\n",
    "    gc.collect()\n",
    "    return data\n",
    "\n",
    "def do_max(data, group_cols, target_col, new_col_name, col_type):\n",
    "    print('[INFO] Compute mean {} with group by {} combination...'.format(target_col, '-'.join(group_cols)))\n",
    "    cols = group_cols.copy()\n",
    "    cols.append(target_col)\n",
    "    group_data = data[cols].groupby(by=group_cols)[[target_col]].max()\\\n",
    "        .reset_index().rename(index=str, columns={target_col: new_col_name})\n",
    "    data = data.merge(group_data, on=group_cols, how='left')\n",
    "    del group_data\n",
    "    data[new_col_name] = data[new_col_name].astype(col_type)\n",
    "    gc.collect()\n",
    "    return data\n",
    "\n",
    "def do_min(data, group_cols, target_col, new_col_name, col_type):\n",
    "    print('[INFO] Compute mean {} with group by {} combination...'.format(target_col, '-'.join(group_cols)))\n",
    "    cols = group_cols.copy()\n",
    "    cols.append(target_col)\n",
    "    group_data = data[cols].groupby(by=group_cols)[[target_col]].min()\\\n",
    "        .reset_index().rename(index=str, columns={target_col: new_col_name})\n",
    "    data = data.merge(group_data, on=group_cols, how='left')\n",
    "    del group_data\n",
    "    data[new_col_name] = data[new_col_name].astype(col_type)\n",
    "    gc.collect()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Compute mean item_cnt_month with group by date_block_num combination...\n",
      "Computing time:13.271844625473022\n"
     ]
    }
   ],
   "source": [
    "group_cols = ['date_block_num']\n",
    "target_col = 'item_cnt_month'\n",
    "new_col_name = 'date_avg_item_cnt_month'\n",
    "col_type = 'float16'\n",
    "\n",
    "matrix = do_mean(data=matrix,\n",
    "                   group_cols=group_cols,\n",
    "                   target_col=target_col,\n",
    "                   new_col_name=new_col_name,\n",
    "                   col_type=col_type)\n",
    "\n",
    "matrix = lag_feature(matrix, [1], new_col_name)\n",
    "matrix.drop([new_col_name], axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Compute mean item_cnt_month with group by date_block_num-item_id combination...\n",
      "Computing time:160.10187125205994\n"
     ]
    }
   ],
   "source": [
    "group_cols = ['date_block_num', 'item_id']\n",
    "target_col = 'item_cnt_month'\n",
    "new_col_name = 'date_item_avg_item_cnt_month'\n",
    "col_type = 'float16'\n",
    "\n",
    "matrix = do_mean(data=matrix,\n",
    "                   group_cols=group_cols,\n",
    "                   target_col=target_col,\n",
    "                   new_col_name=new_col_name,\n",
    "                   col_type=col_type)\n",
    "\n",
    "matrix = lag_feature(matrix, lags_list, new_col_name)\n",
    "matrix.drop([new_col_name], axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Compute mean item_cnt_month with group by date_block_num-shop_id combination...\n",
      "Computing time:170.39596271514893\n"
     ]
    }
   ],
   "source": [
    "group_cols = ['date_block_num', 'shop_id']\n",
    "target_col = 'item_cnt_month'\n",
    "new_col_name = 'date_shop_avg_item_cnt_month'\n",
    "col_type = 'float16'\n",
    "\n",
    "matrix = do_mean(data=matrix,\n",
    "                   group_cols=group_cols,\n",
    "                   target_col=target_col,\n",
    "                   new_col_name=new_col_name,\n",
    "                   col_type=col_type)\n",
    "\n",
    "matrix = lag_feature(matrix, lags_list, new_col_name)\n",
    "matrix.drop([new_col_name], axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Compute mean item_cnt_month with group by date_block_num-item_category_id combination...\n",
      "Computing time:17.533079147338867\n"
     ]
    }
   ],
   "source": [
    "group_cols = ['date_block_num', 'item_category_id']\n",
    "target_col = 'item_cnt_month'\n",
    "new_col_name = 'date_cat_avg_item_cnt_month'\n",
    "col_type = 'float16'\n",
    "\n",
    "matrix = do_mean(data=matrix,\n",
    "                   group_cols=group_cols,\n",
    "                   target_col=target_col,\n",
    "                   new_col_name=new_col_name,\n",
    "                   col_type=col_type)\n",
    "\n",
    "matrix = lag_feature(matrix, [1], new_col_name)\n",
    "matrix.drop([new_col_name], axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Compute mean item_cnt_month with group by date_block_num-shop_id-item_category_id combination...\n",
      "Computing time:17.784915685653687\n"
     ]
    }
   ],
   "source": [
    "group_cols = ['date_block_num', 'shop_id', 'item_category_id']\n",
    "target_col = 'item_cnt_month'\n",
    "new_col_name = 'date_shop_cat_avg_item_cnt_month'\n",
    "col_type = 'float16'\n",
    "\n",
    "matrix = do_mean(data=matrix,\n",
    "                   group_cols=group_cols,\n",
    "                   target_col=target_col,\n",
    "                   new_col_name=new_col_name,\n",
    "                   col_type=col_type)\n",
    "\n",
    "matrix = lag_feature(matrix, [1], new_col_name)\n",
    "matrix.drop([new_col_name], axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Compute mean item_cnt_month with group by date_block_num-shop_id-type_code combination...\n",
      "Computing time:17.237791538238525\n"
     ]
    }
   ],
   "source": [
    "group_cols = ['date_block_num', 'shop_id', 'type_code']\n",
    "target_col = 'item_cnt_month'\n",
    "new_col_name = 'date_shop_type_avg_item_cnt_month'\n",
    "col_type = 'float16'\n",
    "\n",
    "matrix = do_mean(data=matrix,\n",
    "                   group_cols=group_cols,\n",
    "                   target_col=target_col,\n",
    "                   new_col_name=new_col_name,\n",
    "                   col_type=col_type)\n",
    "\n",
    "matrix = lag_feature(matrix, [1], new_col_name)\n",
    "matrix.drop([new_col_name], axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Compute mean item_cnt_month with group by date_block_num-shop_id-subtype_code combination...\n",
      "Computing time:17.892373085021973\n"
     ]
    }
   ],
   "source": [
    "group_cols = ['date_block_num', 'shop_id', 'subtype_code']\n",
    "target_col = 'item_cnt_month'\n",
    "new_col_name = 'date_city_subtype_avg_item_cnt_month'\n",
    "col_type = 'float16'\n",
    "\n",
    "matrix = do_mean(data=matrix,\n",
    "                   group_cols=group_cols,\n",
    "                   target_col=target_col,\n",
    "                   new_col_name=new_col_name,\n",
    "                   col_type=col_type)\n",
    "\n",
    "matrix = lag_feature(matrix, [1], new_col_name)\n",
    "matrix.drop([new_col_name], axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Compute mean item_cnt_month with group by date_block_num-city_code combination...\n",
      "Computing time:17.715256214141846\n"
     ]
    }
   ],
   "source": [
    "group_cols = ['date_block_num', 'city_code']\n",
    "target_col = 'item_cnt_month'\n",
    "new_col_name = 'date_city_avg_item_cnt_month'\n",
    "col_type = 'float16'\n",
    "\n",
    "matrix = do_mean(data=matrix,\n",
    "                   group_cols=group_cols,\n",
    "                   target_col=target_col,\n",
    "                   new_col_name=new_col_name,\n",
    "                   col_type=col_type)\n",
    "\n",
    "matrix = lag_feature(matrix, [1], new_col_name)\n",
    "matrix.drop([new_col_name], axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Compute mean item_cnt_month with group by date_block_num-item_id-city_code combination...\n",
      "Computing time:18.783292293548584\n"
     ]
    }
   ],
   "source": [
    "group_cols = ['date_block_num', 'item_id', 'city_code']\n",
    "target_col = 'item_cnt_month'\n",
    "new_col_name = 'date_item_city_avg_item_cnt_month'\n",
    "col_type = 'float16'\n",
    "\n",
    "matrix = do_mean(data=matrix,\n",
    "                   group_cols=group_cols,\n",
    "                   target_col=target_col,\n",
    "                   new_col_name=new_col_name,\n",
    "                   col_type=col_type)\n",
    "\n",
    "matrix = lag_feature(matrix, [1], new_col_name)\n",
    "matrix.drop([new_col_name], axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Compute mean item_cnt_month with group by date_block_num-type_code combination...\n",
      "Computing time:19.222887754440308\n"
     ]
    }
   ],
   "source": [
    "group_cols = ['date_block_num', 'type_code']\n",
    "target_col = 'item_cnt_month'\n",
    "new_col_name = 'date_type_avg_item_cnt_month'\n",
    "col_type = 'float16'\n",
    "\n",
    "matrix = do_mean(data=matrix,\n",
    "                   group_cols=group_cols,\n",
    "                   target_col=target_col,\n",
    "                   new_col_name=new_col_name,\n",
    "                   col_type=col_type)\n",
    "\n",
    "matrix = lag_feature(matrix, [1], new_col_name)\n",
    "matrix.drop([new_col_name], axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Compute mean item_cnt_month with group by date_block_num-subtype_code combination...\n",
      "Computing time:18.79897427558899\n"
     ]
    }
   ],
   "source": [
    "group_cols = ['date_block_num', 'subtype_code']\n",
    "target_col = 'item_cnt_month'\n",
    "new_col_name = 'date_subtype_avg_item_cnt_month'\n",
    "col_type = 'float16'\n",
    "\n",
    "matrix = do_mean(data=matrix,\n",
    "                   group_cols=group_cols,\n",
    "                   target_col=target_col,\n",
    "                   new_col_name=new_col_name,\n",
    "                   col_type=col_type)\n",
    "\n",
    "matrix = lag_feature(matrix, [1], new_col_name)\n",
    "matrix.drop([new_col_name], axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Trend features***\n",
    "\n",
    "Price trend for the last six months."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Compute mean item_price with group by item_id combination...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "group_cols = ['item_id']\n",
    "target_col = 'item_price'\n",
    "new_col_name = 'item_avg_item_price'\n",
    "col_type = 'float16'\n",
    "\n",
    "sales_data = do_mean(data=sales_data,\n",
    "                     group_cols=group_cols,\n",
    "                     target_col=target_col,\n",
    "                     new_col_name=new_col_name,\n",
    "                     col_type=col_type)\n",
    "\n",
    "tmp_data = sales_data[group_cols + [new_col_name]].drop_duplicates()\n",
    "matrix = pd.merge(matrix, tmp_data, on=group_cols, how='left')\n",
    "del tmp_data\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Compute mean item_price with group by date_block_num-item_id combination...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "group_cols = ['date_block_num', 'item_id']\n",
    "target_col = 'item_price'\n",
    "new_col_name = 'date_item_avg_item_price'\n",
    "col_type = 'float16'\n",
    "\n",
    "sales_data = do_mean(data=sales_data,\n",
    "                     group_cols=group_cols,\n",
    "                     target_col=target_col,\n",
    "                     new_col_name=new_col_name,\n",
    "                     col_type=col_type)\n",
    "\n",
    "tmp_data = sales_data[group_cols + [new_col_name]].drop_duplicates()\n",
    "matrix = pd.merge(matrix, tmp_data, on=group_cols, how='left')\n",
    "del tmp_data\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing time:95.3943612575531\n"
     ]
    }
   ],
   "source": [
    "lags = [1, 2, 3, 4, 5, 6]\n",
    "matrix = lag_feature(matrix, lags, new_col_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in lags:\n",
    "    matrix['delta_price_lag_' + str(i)] = (matrix['date_item_avg_item_price_lag_'+ str(i)] - \n",
    "                                             matrix['item_avg_item_price']) / matrix['item_avg_item_price']\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_cols = [i for i in matrix.columns.tolist() if i.startswith('delta_price_lag_')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_trend(row):\n",
    "    for i in lags:\n",
    "        if row['delta_price_lag_'+ str(i)]:\n",
    "            return row['delta_price_lag_'+ str(i)]\n",
    "    return 0\n",
    "\n",
    "matrix['delta_price_lag'] = matrix[delta_cols].apply(select_trend, axis=1)\n",
    "matrix['delta_price_lag'] = matrix['delta_price_lag'].astype(np.float16)\n",
    "matrix['delta_price_lag'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "140"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fetures_to_drop = ['date_item_avg_item_price', 'item_avg_item_price']\n",
    "for i in lags:\n",
    "    fetures_to_drop += ['date_item_avg_item_price_lag_' + str(i)]\n",
    "    fetures_to_drop += ['delta_price_lag_' + str(i)]\n",
    "\n",
    "matrix.drop(fetures_to_drop, axis=1, inplace=True)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Last month shop revenue trend***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Compute mean revenue with group by date_block_num-shop_id combination...\n"
     ]
    }
   ],
   "source": [
    "group_cols = ['date_block_num', 'shop_id']\n",
    "target_col = 'revenue'\n",
    "new_col_name = 'date_shop_revenue'\n",
    "col_type = 'float32'\n",
    "\n",
    "sales_data = do_sum(data=sales_data,\n",
    "                    group_cols=group_cols,\n",
    "                    target_col=target_col,\n",
    "                    new_col_name=new_col_name,\n",
    "                    col_type=col_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_data = sales_data[group_cols + [new_col_name]].drop_duplicates()\n",
    "matrix = pd.merge(matrix, tmp_data, on=group_cols, how='left')\n",
    "del tmp_data\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Compute mean revenue with group by shop_id combination...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "group_cols = ['shop_id']\n",
    "target_col = 'revenue'\n",
    "new_col_name = 'shop_avg_revenue'\n",
    "col_type = 'float32'\n",
    "\n",
    "sales_data = do_mean(data=sales_data,\n",
    "                     group_cols=group_cols,\n",
    "                     target_col=target_col,\n",
    "                     new_col_name=new_col_name,\n",
    "                     col_type=col_type)\n",
    "\n",
    "tmp_data = sales_data[group_cols + [new_col_name]].drop_duplicates()\n",
    "matrix = pd.merge(matrix, tmp_data, on=group_cols, how='left')\n",
    "del tmp_data\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing time:18.989776611328125\n"
     ]
    }
   ],
   "source": [
    "matrix['delta_revenue'] = (matrix['date_shop_revenue'] - matrix['shop_avg_revenue']) / matrix['shop_avg_revenue']\n",
    "matrix['delta_revenue'] = matrix['delta_revenue'].astype(np.float16)\n",
    "matrix = lag_feature(matrix, [1], 'delta_revenue')\n",
    "matrix.drop(['date_shop_revenue', 'shop_avg_revenue', 'delta_revenue'], axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*add month and day featue*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix['month'] = matrix['date_block_num'] % 12\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "days = pd.Series([31, 28, 31, 30, 31, 30, 31, 31, 30, 31, 30, 31])\n",
    "matrix['days'] = matrix['month'].map(days).astype(np.int8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create HashTable with key equals to `{shop_id, item_id}` and value equals to date_block_num. Iterate data from the top. Foreach row if `{row.shop_id,row.item_id}` is not present in the table, then add it to the table and set its value to row.date_block_num. If HashTable contains key, then calculate the difference beteween cached value and `row.date_block_num`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "cache = {}\n",
    "matrix['item_shop_last_sale'] = -1\n",
    "matrix['item_shop_last_sale'] = matrix['item_shop_last_sale'].astype(np.int8)\n",
    "for idx, row in matrix.iterrows():    \n",
    "    key = str(row.item_id) + '_' + str(row.shop_id)\n",
    "    if key not in cache:\n",
    "        if row.item_cnt_month != 0:\n",
    "            cache[key] = row.date_block_num\n",
    "    else:\n",
    "        last_date_block_num = cache[key]\n",
    "        matrix.at[idx, 'item_shop_last_sale'] = row.date_block_num - last_date_block_num\n",
    "        cache[key] = row.date_block_num         \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "cache = {}\n",
    "matrix['item_last_sale'] = -1\n",
    "matrix['item_last_sale'] = matrix['item_last_sale'].astype(np.int8)\n",
    "for idx, row in matrix.iterrows():    \n",
    "    key = row.item_id\n",
    "    if key not in cache:\n",
    "        if row.item_cnt_month! = 0:\n",
    "            cache[key] = row.date_block_num\n",
    "    else:\n",
    "        last_date_block_num = cache[key]\n",
    "        if row.date_block_num > last_date_block_num:\n",
    "            matrix.at[idx, 'item_last_sale'] = row.date_block_num - last_date_block_num\n",
    "            cache[key] = row.date_block_num  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2832"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del cache\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix['item_shop_first_sale'] = matrix['date_block_num'] - matrix.groupby(['item_id','shop_id'])['date_block_num'].transform('min')\n",
    "matrix['item_first_sale'] = matrix['date_block_num'] - matrix.groupby('item_id')['date_block_num'].transform('min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = matrix[matrix.date_block_num > 11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_na(df):\n",
    "    for col in df.columns:\n",
    "        if ('_lag_' in col) & (df[col].isnull().any()):\n",
    "            if ('item_cnt' in col):\n",
    "                df[col].fillna(0, inplace=True)         \n",
    "    return df\n",
    "\n",
    "matrix = fill_na(matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save data with feature engineering\n",
    "with open('all_month_data_with_fe.pkl', 'wb') as handle:\n",
    "    pickle.dump(matrix, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('all_month_data_with_fe.pkl', 'rb') as handle:\n",
    "    matrix = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6639294, 62)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_cols = [c for c in matrix.columns.tolist() if c not in ['item_cnt_month', 'ID']]\n",
    "target_col = 'item_cnt_month'\n",
    "cat_features = ['date_block_num', 'shop_id', 'item_id', 'city_code', 'item_category_id', \n",
    "                'type_code', 'subtype_code']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = matrix[matrix.date_block_num < 33]\n",
    "valid_df = matrix[matrix.date_block_num == 33]\n",
    "test_df = matrix[matrix.date_block_num == 34]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_of_iter = 1000\n",
    "num_early_stopping = 20\n",
    "num_verbose_eval = 100\n",
    "seed = 9527\n",
    "metric = 'rmse'\n",
    "    \n",
    "xgb_sk_params = {\n",
    "    'learning_rate': 0.3,\n",
    "    'n_estimators': num_of_iter,                                   \n",
    "    'objective': 'reg:squarederror', # binary:logistic\n",
    "    'n_jobs': multiprocessing.cpu_count(),\n",
    "    'eval_metric': [metric], # logloss\n",
    "    'random_state':  seed,\n",
    "    'max_depth': 8, # 0 means no limit (useful only for depth wise grow policy).\n",
    "    'min_child_weight': 300, # Minimum sum of instance weight (hessian) needed in a child.\n",
    "    'subsample': 0.8, # Subsample ratio of the training instances.\n",
    "    'colsample_bytree': 0.8, # subsample ratio of columns when constructing each tree.\n",
    "}\n",
    "\n",
    "lgb_sk_params = {\n",
    "    'boosting_type': 'gbdt', # goss, dart\n",
    "    'learning_rate': 0.1,\n",
    "    'n_estimators': num_of_iter,\n",
    "    'objective': 'regression_l2',\n",
    "    'metrics': [metric],\n",
    "    'random_state': seed,\n",
    "    'n_jobs': multiprocessing.cpu_count(),\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[06:29:43] WARNING: /workspace/src/learner.cc:686: Tree method is automatically selected to be 'approx' for faster speed. To use old behavior (exact greedy algorithm on single machine), set tree_method to 'exact'.\n",
      "[0]\tvalidation_0-rmse:1.0728\tvalidation_1-rmse:1.06573\n",
      "Multiple eval metrics have been passed: 'validation_1-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-rmse hasn't improved in 20 rounds.\n",
      "Stopping. Best iteration:\n",
      "[8]\tvalidation_0-rmse:0.831928\tvalidation_1-rmse:0.913173\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=0.8, eval_metric=['rmse'],\n",
       "             gamma=0, importance_type='gain', learning_rate=0.3,\n",
       "             max_delta_step=0, max_depth=8, min_child_weight=300, missing=None,\n",
       "             n_estimators=1000, n_jobs=8, nthread=None,\n",
       "             objective='reg:squarederror', random_state=9527, reg_alpha=0,\n",
       "             reg_lambda=1, scale_pos_weight=1, seed=None, silent=None,\n",
       "             subsample=0.8, verbosity=1)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_set = [(train_df[features_cols], train_df[target_col]),\n",
    "            (valid_df[features_cols], valid_df[target_col])]\n",
    "model = xgb.XGBRegressor(**xgb_sk_params)\n",
    "model.fit(X=train_df[features_cols],\n",
    "          y=train_df[target_col], \n",
    "          eval_set=eval_set,             \n",
    "          early_stopping_rounds=num_early_stopping, \n",
    "          verbose=num_verbose_eval)\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(valid_df[features_cols], ntree_limit=model.best_iteration_)\n",
    "\n",
    "print('MSE:', mean_squared_error(valid_df[target_col], y_pred))\n",
    "print('RMSE:', np.sqrt(mean_squared_error(valid_df[target_col], y_pred)))\n",
    "print('R2 score:', r2_score(valid_df[target_col], y_pred))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15, 15))\n",
    "xgb.plot_importance(model, importance_type='weight', max_num_features=-1, height=0.5, ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[29]\tvalidation_0's rmse: 0.859803\tvalidation_1's rmse: 0.940769\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
       "              importance_type='split', learning_rate=0.1, max_depth=-1,\n",
       "              metrics=['rmse'], min_child_samples=20, min_child_weight=0.001,\n",
       "              min_split_gain=0.0, n_estimators=1000, n_jobs=8, num_leaves=31,\n",
       "              objective='regression_l2', random_state=9527, reg_alpha=0.0,\n",
       "              reg_lambda=0.0, silent=True, subsample=1.0,\n",
       "              subsample_for_bin=200000, subsample_freq=0)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_set = [(train_df[features_cols], train_df[target_col]),\n",
    "            (valid_df[features_cols], valid_df[target_col])]\n",
    "model = lgb.LGBMRegressor(**lgb_sk_params)    \n",
    "model.fit(X=train_df[features_cols],\n",
    "          y=train_df[target_col], \n",
    "          eval_set=eval_set, \n",
    "          eval_names=['validation_0', 'validation_1'],\n",
    "          early_stopping_rounds=num_early_stopping, \n",
    "          verbose=num_verbose_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.8850470959300232\n",
      "RMSE: 0.9407694169827286\n",
      "R2 score: 0.31425523196476757\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(valid_df[features_cols], ntree_limit=model.best_iteration_)\n",
    "\n",
    "print('MSE:', mean_squared_error(valid_df[target_col], y_pred))\n",
    "print('RMSE:', np.sqrt(mean_squared_error(valid_df[target_col], y_pred)))\n",
    "print('R2 score:', r2_score(valid_df[target_col], y_pred))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fea9aa71860>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1080 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(15, 15))\n",
    "lgb.plot_importance(model, max_num_features=30, height=0.5, importance_type='split', ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(test_df[features_cols],\n",
    "                       ntree_limit=model.best_iteration)\n",
    "y_pred = y_pred.clip(0, 20)\n",
    "submission_df = pd.DataFrame({\n",
    "    \"ID\": list(range(test_df.shape[0])), \n",
    "    \"item_cnt_month\": y_pred\n",
    "})\n",
    "submission_df.to_csv('submission_bs_{}.csv'.format(datetime.now().strftime('%Y%m%d%H%M%S')), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross validation with time split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = matrix[matrix.date_block_num <= 33]\n",
    "test_df = matrix[matrix.date_block_num == 34]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_of_iter = 1000\n",
    "num_early_stopping = 50\n",
    "num_verbose_eval = 100\n",
    "seed = 9527\n",
    "metric = 'rmse'\n",
    "    \n",
    "xgb_sk_params = {\n",
    "    'learning_rate': 0.1,\n",
    "    'n_estimators': num_of_iter,                                   \n",
    "    'objective': 'reg:squarederror', # binary:logistic\n",
    "    'n_jobs': multiprocessing.cpu_count(),\n",
    "    #'tree_method': \"gpu_hist\",  # gpu_hist\n",
    "    #'n_gpus': -1,\n",
    "    'eval_metric': [metric], # logloss\n",
    "    'random_state':  seed,\n",
    "    #'gamma': 0, # Minimum loss reduction required to make a further partition on a leaf node of the tree, alias min_split_loss. It acts as a regularization parameter. Either 0, 1 or 5.\n",
    "    #'max_depth': 8, # 0 means no limit (useful only for depth wise grow policy).\n",
    "    #'min_child_weight': 300, # Minimum sum of instance weight (hessian) needed in a child.\n",
    "    #'subsample': 0.8, # Subsample ratio of the training instances.\n",
    "    #'colsample_bytree': 0.8, # subsample ratio of columns when constructing each tree.\n",
    "    #'colsample_bylevel': 1, # subsample ratio of columns for each level.\n",
    "    #'reg_lambda': 1e-3, # L2 regularization. Increasing this value will make model more conservative.\n",
    "    #'reg_alpha': 0, # L1 regularization. Increasing this value will make model more conservative.\n",
    "    #'scale_pos_weight': weight_ratio, # Control the balance of positive and negative weights, useful for unbalanced classes.\n",
    "    #'grow_policy': \"lossguide\", # split at nodes with highest loss change.\n",
    "    #'max_leaves': 255, # Maximum number of nodes to be added. (for lossguide grow policy).\n",
    "    #'max_bin': 100, # Increasing this number improves the optimality of splits at the cost of higher computation time.\n",
    "}\n",
    "\n",
    "lgb_sk_params = {\n",
    "    'boosting_type': 'gbdt', # goss, dart\n",
    "    #'num_leaves': 80,\n",
    "    #'max_depth': 5,\n",
    "    'learning_rate': 0.0010151324067998776,\n",
    "    'n_estimators': num_of_iter,\n",
    "    #'subsample_for_bin': 200000,  # Number of samples for constructing bin\n",
    "    'objective': 'regression_l2',\n",
    "    'metrics': [metric],\n",
    "    #'min_split_gain': 0,  # lambda_l1, lambda_l2 and min_gain_to_split to regularization\n",
    "    #'min_child_weight': 1,  # Minimum sum of instance weight(hessian) needed in a child(leaf)\n",
    "    #'min_child_samples': 100,  # Minimum number of data need in a child(min_data_in_leaf)\n",
    "    #'subsample': 0.8,\n",
    "    #'colsample_bytree': 0.8,\n",
    "    #'reg_alpha': 3,  # L1 regularization term on weights\n",
    "    #'reg_lambda': 1e-3,\n",
    "    'random_state': seed,\n",
    "    'n_jobs': multiprocessing.cpu_count(),\n",
    "    #'scale_pos_weight': 0.5,\n",
    "    #'max_bin': 255\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Fold 0 =====\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[100]\tvalidation_0's rmse: 1.14219\tvalidation_1's rmse: 1.14307\n",
      "[200]\tvalidation_0's rmse: 1.10288\tvalidation_1's rmse: 1.1043\n",
      "[300]\tvalidation_0's rmse: 1.06921\tvalidation_1's rmse: 1.07111\n",
      "[400]\tvalidation_0's rmse: 1.0406\tvalidation_1's rmse: 1.04294\n",
      "[500]\tvalidation_0's rmse: 1.01607\tvalidation_1's rmse: 1.01876\n",
      "[600]\tvalidation_0's rmse: 0.995053\tvalidation_1's rmse: 0.998082\n",
      "[700]\tvalidation_0's rmse: 0.977017\tvalidation_1's rmse: 0.980329\n",
      "[800]\tvalidation_0's rmse: 0.961582\tvalidation_1's rmse: 0.965132\n",
      "[900]\tvalidation_0's rmse: 0.948353\tvalidation_1's rmse: 0.952134\n",
      "[1000]\tvalidation_0's rmse: 0.936986\tvalidation_1's rmse: 0.941028\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalidation_0's rmse: 0.936986\tvalidation_1's rmse: 0.941028\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
       "              importance_type='split', learning_rate=0.0010151324067998776,\n",
       "              max_depth=-1, metrics=['rmse'], min_child_samples=20,\n",
       "              min_child_weight=0.001, min_split_gain=0.0, n_estimators=1000,\n",
       "              n_jobs=8, num_leaves=31, objective='regression_l2',\n",
       "              random_state=9569, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
       "              subsample=1.0, subsample_for_bin=200000, subsample_freq=0)"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MSE: 0.8855329603973645\n",
      "RMSE: 0.9410276087327961\n",
      "R2 score: 0.37317718323490723\n",
      "===== Fold 1 =====\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[100]\tvalidation_0's rmse: 1.14232\tvalidation_1's rmse: 1.14249\n",
      "[200]\tvalidation_0's rmse: 1.10316\tvalidation_1's rmse: 1.10327\n",
      "[300]\tvalidation_0's rmse: 1.06962\tvalidation_1's rmse: 1.06973\n",
      "[400]\tvalidation_0's rmse: 1.04107\tvalidation_1's rmse: 1.04114\n",
      "[500]\tvalidation_0's rmse: 1.01662\tvalidation_1's rmse: 1.01668\n",
      "[600]\tvalidation_0's rmse: 0.995685\tvalidation_1's rmse: 0.995732\n",
      "[700]\tvalidation_0's rmse: 0.977722\tvalidation_1's rmse: 0.977741\n",
      "[800]\tvalidation_0's rmse: 0.962325\tvalidation_1's rmse: 0.962328\n",
      "[900]\tvalidation_0's rmse: 0.94918\tvalidation_1's rmse: 0.949172\n",
      "[1000]\tvalidation_0's rmse: 0.937873\tvalidation_1's rmse: 0.937852\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalidation_0's rmse: 0.937873\tvalidation_1's rmse: 0.937852\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
       "              importance_type='split', learning_rate=0.0010151324067998776,\n",
       "              max_depth=-1, metrics=['rmse'], min_child_samples=20,\n",
       "              min_child_weight=0.001, min_split_gain=0.0, n_estimators=1000,\n",
       "              n_jobs=8, num_leaves=31, objective='regression_l2',\n",
       "              random_state=9936, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
       "              subsample=1.0, subsample_for_bin=200000, subsample_freq=0)"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MSE: 0.8795654444230848\n",
      "RMSE: 0.937851504462772\n",
      "R2 score: 0.3773971988164574\n",
      "===== Fold 2 =====\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[100]\tvalidation_0's rmse: 1.14252\tvalidation_1's rmse: 1.14169\n",
      "[200]\tvalidation_0's rmse: 1.10349\tvalidation_1's rmse: 1.10192\n",
      "[300]\tvalidation_0's rmse: 1.07019\tvalidation_1's rmse: 1.06802\n",
      "[400]\tvalidation_0's rmse: 1.04177\tvalidation_1's rmse: 1.03912\n",
      "[500]\tvalidation_0's rmse: 1.01745\tvalidation_1's rmse: 1.01447\n",
      "[600]\tvalidation_0's rmse: 0.996533\tvalidation_1's rmse: 0.993228\n",
      "[700]\tvalidation_0's rmse: 0.97857\tvalidation_1's rmse: 0.974955\n",
      "[800]\tvalidation_0's rmse: 0.963192\tvalidation_1's rmse: 0.959341\n",
      "[900]\tvalidation_0's rmse: 0.950026\tvalidation_1's rmse: 0.945987\n",
      "[1000]\tvalidation_0's rmse: 0.938717\tvalidation_1's rmse: 0.934534\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalidation_0's rmse: 0.938717\tvalidation_1's rmse: 0.934534\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
       "              importance_type='split', learning_rate=0.0010151324067998776,\n",
       "              max_depth=-1, metrics=['rmse'], min_child_samples=20,\n",
       "              min_child_weight=0.001, min_split_gain=0.0, n_estimators=1000,\n",
       "              n_jobs=8, num_leaves=31, objective='regression_l2',\n",
       "              random_state=10253, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
       "              subsample=1.0, subsample_for_bin=200000, subsample_freq=0)"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MSE: 0.8733542352413964\n",
      "RMSE: 0.9345342343870536\n",
      "R2 score: 0.3816214042623145\n",
      "===== Fold 3 =====\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[100]\tvalidation_0's rmse: 1.14245\tvalidation_1's rmse: 1.14229\n",
      "[200]\tvalidation_0's rmse: 1.10326\tvalidation_1's rmse: 1.10308\n",
      "[300]\tvalidation_0's rmse: 1.0698\tvalidation_1's rmse: 1.06962\n",
      "[400]\tvalidation_0's rmse: 1.04124\tvalidation_1's rmse: 1.04112\n",
      "[500]\tvalidation_0's rmse: 1.01682\tvalidation_1's rmse: 1.01677\n",
      "[600]\tvalidation_0's rmse: 0.995755\tvalidation_1's rmse: 0.995747\n",
      "[700]\tvalidation_0's rmse: 0.977759\tvalidation_1's rmse: 0.977799\n",
      "[800]\tvalidation_0's rmse: 0.962366\tvalidation_1's rmse: 0.962453\n",
      "[900]\tvalidation_0's rmse: 0.949194\tvalidation_1's rmse: 0.949334\n",
      "[1000]\tvalidation_0's rmse: 0.937855\tvalidation_1's rmse: 0.938053\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalidation_0's rmse: 0.937855\tvalidation_1's rmse: 0.938053\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
       "              importance_type='split', learning_rate=0.0010151324067998776,\n",
       "              max_depth=-1, metrics=['rmse'], min_child_samples=20,\n",
       "              min_child_weight=0.001, min_split_gain=0.0, n_estimators=1000,\n",
       "              n_jobs=8, num_leaves=31, objective='regression_l2',\n",
       "              random_state=9870, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
       "              subsample=1.0, subsample_for_bin=200000, subsample_freq=0)"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MSE: 0.8799441476791774\n",
      "RMSE: 0.9380533821052922\n",
      "R2 score: 0.37676208794632304\n",
      "===== Fold 4 =====\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[100]\tvalidation_0's rmse: 1.14232\tvalidation_1's rmse: 1.14252\n",
      "[200]\tvalidation_0's rmse: 1.10303\tvalidation_1's rmse: 1.1039\n",
      "[300]\tvalidation_0's rmse: 1.06941\tvalidation_1's rmse: 1.07087\n",
      "[400]\tvalidation_0's rmse: 1.04082\tvalidation_1's rmse: 1.04272\n",
      "[500]\tvalidation_0's rmse: 1.01631\tvalidation_1's rmse: 1.01865\n",
      "[600]\tvalidation_0's rmse: 0.995271\tvalidation_1's rmse: 0.998023\n",
      "[700]\tvalidation_0's rmse: 0.977246\tvalidation_1's rmse: 0.98039\n",
      "[800]\tvalidation_0's rmse: 0.961847\tvalidation_1's rmse: 0.965333\n",
      "[900]\tvalidation_0's rmse: 0.948614\tvalidation_1's rmse: 0.952401\n",
      "[1000]\tvalidation_0's rmse: 0.937229\tvalidation_1's rmse: 0.941288\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalidation_0's rmse: 0.937229\tvalidation_1's rmse: 0.941288\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
       "              importance_type='split', learning_rate=0.0010151324067998776,\n",
       "              max_depth=-1, metrics=['rmse'], min_child_samples=20,\n",
       "              min_child_weight=0.001, min_split_gain=0.0, n_estimators=1000,\n",
       "              n_jobs=8, num_leaves=31, objective='regression_l2',\n",
       "              random_state=10464, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
       "              subsample=1.0, subsample_for_bin=200000, subsample_freq=0)"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MSE: 0.8860222129777016\n",
      "RMSE: 0.9412875293860541\n",
      "R2 score: 0.37209408841973834\n",
      "---------------------------\n",
      "MSE: 0.8808837958101539\n",
      "RMSE: 0.9385540984994706\n",
      "R2 score: 0.3762109871805164\n"
     ]
    }
   ],
   "source": [
    "n_splits = 5\n",
    "folds = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=seed)\n",
    "Kflods = folds.split(train_df[features_cols].values, train_df[target_col].values)\n",
    "#folds = TimeSeriesSplit(n_splits=n_splits)\n",
    "#Kflods = folds.split(train_df[features_cols].values, train_df[target_col].values)\n",
    "\n",
    "oof = np.zeros(len(train_df))\n",
    "predictions = np.zeros(len(test_df))\n",
    "feature_importance_df = pd.DataFrame()\n",
    "total_fold_loss_df = pd.DataFrame()\n",
    "y_true = test_df[target_col].values.tolist()\n",
    "y_pred = np.zeros(test_df.shape[0])\n",
    "test_acc_score = []\n",
    "test_auc_score = []\n",
    "target_encoding_cols = ['date_block_num', 'shop_id', 'item_id']\n",
    "mean_enc = None\n",
    "model_name = 'lgb'\n",
    "\n",
    "for fold, (trn_idx, val_idx) in enumerate(Kflods):\n",
    "    print(\"===== Fold {} =====\".format(fold))\n",
    "    trn_idx = shuffle(trn_idx)\n",
    "    train_x, train_y = train_df.iloc[trn_idx][features_cols], train_df.iloc[trn_idx][target_col]\n",
    "    valid_x, valid_y = train_df.iloc[val_idx][features_cols], train_df.iloc[val_idx][target_col]\n",
    "    features_cols_v2 = features_cols.copy()\n",
    "    if mean_enc == 'mean':\n",
    "        for f in target_encoding_cols:\n",
    "            train_x, enc_value, prior_mean, feature_name = mean_encoding(train_x, train_y, f, target_col)\n",
    "            valid_x[feature_name] = valid_x[f].map(enc_value)\n",
    "            valid_x[feature_name].fillna(prior_mean, inplace=True)    \n",
    "            test_df[feature_name] = test_df[f].map(enc_value)\n",
    "            test_df[feature_name].fillna(prior_mean, inplace=True)\n",
    "            features_cols_v2.remove(f)\n",
    "            features_cols_v2.append(feature_name)\n",
    "    elif mean_enc == 'smooth':\n",
    "        for f in target_encoding_cols:\n",
    "            train_x, enc_value, prior_mean, feature_name = smooth_mean_encoding(train_x, train_y, f, target_col)\n",
    "            valid_x[feature_name] = valid_x[f].map(enc_value)\n",
    "            valid_x[feature_name].fillna(prior_mean, inplace=True)    \n",
    "            test_df[feature_name] = test_df[f].map(enc_value)\n",
    "            test_df[feature_name].fillna(prior_mean, inplace=True)\n",
    "            features_cols_v2.append(feature_name)\n",
    "    elif mean_enc == 'beta':\n",
    "        prior_mean = np.mean(train_y)\n",
    "        for f in target_encoding_cols:\n",
    "            stats = train_df.iloc[trn_idx].groupby(f).agg(['sum', 'count'])['label'].reset_index()\n",
    "            train_x, feature_name = beta_mean_encoding(train_x, f, target_col, stats, prior_mean)\n",
    "            valid_x, _ = beta_mean_encoding(valid_x, f, target_col, stats, prior_mean)\n",
    "            test_df, _ = beta_mean_encoding(test_df, f, target_col, stats, prior_mean)\n",
    "            features_cols_v2.append(feature_name)\n",
    "\n",
    "    eval_set = [(train_x[features_cols_v2], train_y), (valid_x[features_cols_v2], valid_y)]\n",
    "    if model_name == 'xgb':\n",
    "        xgb_sk_params.update({'random_state': fold + np.random.randint(999) + seed})\n",
    "        cv_model = xgb.XGBRegressor(**xgb_sk_params)\n",
    "        cv_model.fit(X=train_x[features_cols_v2],\n",
    "                     y=train_y, \n",
    "                     eval_set=eval_set,             \n",
    "                     early_stopping_rounds=num_early_stopping, \n",
    "                     verbose=num_verbose_eval) \n",
    "        loss = cv_model.evals_result().items()\n",
    "    elif model_name == 'lgb':\n",
    "        lgb_sk_params.update({'random_state': fold + np.random.randint(999) + seed})\n",
    "        cv_model = lgb.LGBMRegressor(**lgb_sk_params)    \n",
    "        cv_model.fit(X=train_x[features_cols_v2],\n",
    "                     y=train_y, \n",
    "                     eval_set=eval_set,    \n",
    "                     eval_names=['validation_0', 'validation_1'],\n",
    "                     early_stopping_rounds=num_early_stopping, \n",
    "                     verbose=num_verbose_eval) \n",
    "        loss = cv_model.evals_result_.items()\n",
    "    \n",
    "    # loss \n",
    "    fold_loss_df = pd.DataFrame(columns=['fold', 'type', 'loss'])\n",
    "    for k, v in loss:\n",
    "        if k == 'validation_0':        \n",
    "            fold_loss_df['loss'] = v[list(v.keys())[0]]\n",
    "            fold_loss_df['fold'] = fold + 1\n",
    "            fold_loss_df['type'] = 'train'                \n",
    "        elif k == 'validation_1':\n",
    "            fold_loss_df['loss'] = v[list(v.keys())[0]]\n",
    "            fold_loss_df['fold'] = fold + 1\n",
    "            fold_loss_df['type'] = 'valid'                \n",
    "        total_fold_loss_df = pd.concat([total_fold_loss_df, fold_loss_df], axis=0)\n",
    "    \n",
    "    # feature importance\n",
    "    fold_importance_df = pd.DataFrame()\n",
    "    fold_importance_df[\"feature\"] = features_cols_v2\n",
    "    fold_importance_df[\"importance\"] = cv_model.feature_importances_\n",
    "    fold_importance_df[\"fold\"] = fold + 1\n",
    "    feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
    "    \n",
    "    # evaluation\n",
    "    if model_name == 'xgb':\n",
    "        oof[val_idx] += cv_model.predict(valid_x[features_cols_v2], \n",
    "                                         ntree_limit=cv_model.best_iteration)\n",
    "        y_pred += cv_model.predict(test_df[features_cols_v2], \n",
    "                                   ntree_limit=cv_model.best_iteration) / folds.n_splits\n",
    "    elif model_name == 'lgb':\n",
    "        oof[val_idx] += cv_model.predict(valid_x[features_cols_v2], \n",
    "                                               ntree_limit=cv_model.best_iteration_)\n",
    "        y_pred += cv_model.predict(test_df[features_cols_v2], \n",
    "                                         ntree_limit=cv_model.best_iteration_) / folds.n_splits\n",
    "        \n",
    "    print()\n",
    "    print('MSE:', mean_squared_error(valid_y, oof[val_idx]))\n",
    "    print('RMSE:', np.sqrt(mean_squared_error(valid_y, oof[val_idx])))\n",
    "    print('R2 score:', r2_score(valid_y, oof[val_idx]))\n",
    "\n",
    "print('---------------------------')\n",
    "print('MSE:', mean_squared_error(train_df[target_col], oof))\n",
    "print('RMSE:', np.sqrt(mean_squared_error(train_df[target_col], oof)))\n",
    "print('R2 score:', r2_score(train_df[target_col], oof))    \n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = y_pred.clip(0, 20)\n",
    "submission_df = pd.DataFrame({\n",
    "    \"ID\": list(range(test_df.shape[0])), \n",
    "    \"item_cnt_month\": y_pred\n",
    "})\n",
    "submission_df.to_csv('lgb_cv_submission_{}.csv'.format(datetime.now().strftime('%Y%m%d%H%M%S')), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_result = pd.read_csv('lgb_cv_submission_20190830173409.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_cnt_month</th>\n",
       "      <th>item_cnt_month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>item_cnt_month</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.949295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>item_cnt_month</th>\n",
       "      <td>0.949295</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                item_cnt_month  item_cnt_month\n",
       "item_cnt_month        1.000000        0.949295\n",
       "item_cnt_month        0.949295        1.000000"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([main_result['item_cnt_month'], submission_df['item_cnt_month']], axis=1).corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use Nested LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "import warnings\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras import activations\n",
    "from keras import initializers\n",
    "from keras import regularizers\n",
    "from keras import constraints\n",
    "from keras.engine import Layer\n",
    "from keras.engine import InputSpec\n",
    "from keras.legacy import interfaces\n",
    "from keras.layers import RNN\n",
    "from keras.layers.recurrent import _generate_dropout_mask\n",
    "from keras.layers import LSTMCell, LSTM, Bidirectional\n",
    "from keras.layers import Dropout\n",
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "from keras import optimizers\n",
    "from keras_tqdm import TQDMNotebookCallback\n",
    "from keras_radam import RAdam\n",
    "from nested_lstm import NestedLSTM\n",
    "from clr_callback import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters setting\n",
    "LEARNING_RATE = 0.01\n",
    "BATCH_SIZE = 1024\n",
    "EPOCHS = 10\n",
    "TIME_PERIOD = 24\n",
    "#TIME_SPLIE_SHIFT = train_cnt_df.shape[1] - TIME_PERIOD\n",
    "#RANDOM_SAMPLE_SIZE = int(np.floor(train_cnt_df.shape[0] / 5))\n",
    "\n",
    "#NUM_STEPS = train_x.shape[0] / NUM_BATCH_SIZE\n",
    "DECAY_FACTOR = 0.96"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, LearningRateScheduler, ReduceLROnPlateau\n",
    "\n",
    "\n",
    "#checkpoint = ModelCheckpoint(weight_path, \n",
    "#                             monitor='val_loss', \n",
    "#                             verbose=1, \n",
    "#                             save_best_only=True, \n",
    "#                             mode='min',\n",
    "#                             save_weights_only=True)\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', \n",
    "                              factor=DECAY_FACTOR, \n",
    "                              patience=3, \n",
    "                              verbose=1, \n",
    "                              min_delta=0.001,\n",
    "                              mode='min', \n",
    "                              cooldown=2, \n",
    "                              min_lr=1e-6)\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', \n",
    "                               mode='min', \n",
    "                               patience=3)\n",
    "\n",
    "clr = CyclicLR(base_lr=LEARNING_RATE, max_lr=0.006,\n",
    "               step_size=2000, mode='exp_range',\n",
    "               gamma=0.99994)\n",
    "\n",
    "callbacks_list = [early_stopping, clr, TQDMNotebookCallback()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.client.session.InteractiveSession at 0x7fe91977e1d0>"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "nested_lstm_1 (NestedLSTM)   (None, 1, 64)             97536     \n",
      "_________________________________________________________________\n",
      "nested_lstm_2 (NestedLSTM)   (None, 1, 32)             29056     \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 1)                 136       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                20        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 126,759\n",
      "Trainable params: 126,759\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "reset_tf_session()\n",
    "adam = optimizers.Adam(LEARNING_RATE, decay=DECAY_FACTOR)\n",
    "\n",
    "lstm_model = Sequential()\n",
    "lstm_model.add(NestedLSTM(units=64, input_shape=(1, len(features_cols)), depth=3, dropout=0.2, \n",
    "                          recurrent_dropout=0.2, return_sequences=True))\n",
    "lstm_model.add(NestedLSTM(units=32, depth=3, dropout=0.2, recurrent_dropout=0.2, return_sequences=True))\n",
    "lstm_model.add(LSTM(1, activation='relu', return_sequences=False))\n",
    "lstm_model.add(Dense(10, kernel_initializer='glorot_normal', activation='relu'))\n",
    "#lstm_model.add(Dense(10, kernel_initializer='glorot_normal', activation='relu'))\n",
    "lstm_model.add(Dense(1))\n",
    "lstm_model.compile(loss='mse', \n",
    "                   optimizer=RAdam(total_steps=10000, warmup_proportion=LEARNING_RATE, min_lr=1e-5),\n",
    "                   metrics=['mean_squared_error'])\n",
    "lstm_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = matrix[matrix.date_block_num < 33]\n",
    "valid_df = matrix[matrix.date_block_num == 33]\n",
    "test_df = matrix[matrix.date_block_num == 34]\n",
    "\n",
    "train_x = np.expand_dims(train_df[features_cols].values, axis=1)\n",
    "valid_x = np.expand_dims(valid_df[features_cols].values, axis=1)\n",
    "train_y = train_df[target_col]\n",
    "valid_y = valid_df[target_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method BaseSession._Callable.__del__ of <tensorflow.python.client.session.BaseSession._Callable object at 0x7fe92af35a20>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\", line 1455, in __del__\n",
      "    self._session._session, self._handle, status)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/errors_impl.py\", line 528, in __exit__\n",
      "    c_api.TF_GetCode(self.status.status))\n",
      "tensorflow.python.framework.errors_impl.CancelledError: Session has been closed.\n",
      "Exception ignored in: <bound method BaseSession._Callable.__del__ of <tensorflow.python.client.session.BaseSession._Callable object at 0x7fe92aec4ba8>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\", line 1455, in __del__\n",
      "    self._session._session, self._handle, status)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/errors_impl.py\", line 528, in __exit__\n",
      "    c_api.TF_GetCode(self.status.status))\n",
      "tensorflow.python.framework.errors_impl.CancelledError: Session has been closed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6186922 samples, validate on 238172 samples\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c2070612a624b75b94e46d1796d2db7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Training', max=10, style=ProgressStyle(description_width='ini…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 0', max=6186922, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6186922/6186922 [==============================] - 168s 27us/step - loss: 1.4134 - mean_squared_error: 1.4134 - val_loss: 1.2916 - val_mean_squared_error: 1.2916\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 1', max=6186922, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6186922/6186922 [==============================] - 169s 27us/step - loss: 1.4119 - mean_squared_error: 1.4119 - val_loss: 1.2917 - val_mean_squared_error: 1.2917\n",
      "Epoch 3/10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 2', max=6186922, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6186922/6186922 [==============================] - 168s 27us/step - loss: 1.4119 - mean_squared_error: 1.4119 - val_loss: 1.2918 - val_mean_squared_error: 1.2918\n",
      "Epoch 4/10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 3', max=6186922, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6186922/6186922 [==============================] - 169s 27us/step - loss: 1.4119 - mean_squared_error: 1.4119 - val_loss: 1.2918 - val_mean_squared_error: 1.2918\n"
     ]
    }
   ],
   "source": [
    "history = [lstm_model.fit(train_x, train_y,\n",
    "                          validation_data=(valid_x, valid_y),\n",
    "                          epochs=EPOCHS,\n",
    "                          batch_size=BATCH_SIZE,\n",
    "                          verbose=1,\n",
    "                          callbacks=callbacks_list)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "n_splits = 5\n",
    "#folds = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=seed)\n",
    "#Kflods = folds.split(train_df[features_cols].values, train_df[target_col].values)\n",
    "folds = TimeSeriesSplit(n_splits=n_splits)\n",
    "Kflods = folds.split(train_df[features_cols].values, train_df[target_col].values)\n",
    "\n",
    "oof = np.zeros(len(train_df))\n",
    "predictions = np.zeros(len(test_df))\n",
    "feature_importance_df = pd.DataFrame()\n",
    "total_fold_loss_df = pd.DataFrame()\n",
    "y_true = test_df[target_col].values.tolist()\n",
    "y_pred = np.zeros(test_df.shape[0])\n",
    "test_acc_score = []\n",
    "test_auc_score = []\n",
    "target_encoding_cols = ['date_block_num', 'shop_id', 'item_id']\n",
    "mean_enc = None\n",
    "model_name = 'lgb'\n",
    "\n",
    "for fold, (trn_idx, val_idx) in enumerate(Kflods):\n",
    "    print(\"===== Fold {} =====\".format(fold))\n",
    "    trn_idx = shuffle(trn_idx)\n",
    "    train_x, train_y = train_df.iloc[trn_idx][features_cols], train_df.iloc[trn_idx][target_col]\n",
    "    valid_x, valid_y = train_df.iloc[val_idx][features_cols], train_df.iloc[val_idx][target_col]\n",
    "    features_cols_v2 = features_cols.copy()\n",
    "    train_x = np.expand_dims(train_x, axis=1)\n",
    "    valid_x = np.expand_dims(valid_x, axis=1)\n",
    "    history = [lstm_model.fit(train_x, train_y,\n",
    "                              validation_data=(valid_x, valid_y),\n",
    "                              epochs=EPOCHS,\n",
    "                              batch_size=BATCH_SIZE,\n",
    "                              verbose=1,\n",
    "                              callbacks=callbacks_list)]\n",
    "    # evaluation\n",
    "    test_data = np.expand_dims(test_df[features_cols].values, axis=1)\n",
    "    y_pred += lstm_model.predict(test_data).reshape(-1) / folds.n_splits\n",
    "    \n",
    "    print()\n",
    "    print('MSE:', mean_squared_error(valid_y, oof[val_idx]))\n",
    "    print('RMSE:', np.sqrt(mean_squared_error(valid_y, oof[val_idx])))\n",
    "    print('R2 score:', r2_score(valid_y, oof[val_idx]))\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/externals/joblib/__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Categorical, Integer\n",
    "from skopt.utils import use_named_args\n",
    "from skopt import gp_minimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_space  = [\n",
    "    Real(0.001, 0.1, name='learning_rate'),\n",
    "    Integer(3, 10, name='max_depth'),\n",
    "    Integer(50, 200, name='min_child_weight'),\n",
    "    Real(1, 400,  name='scale_pos_weight'),\n",
    "    Real(0.6, 0.9, name='subsample'),\n",
    "    Real(0.6, 0.9, name='colsample_bytree'),\n",
    "    Real(0, 5, name='reg_lambda'),\n",
    "    Integer(100, 255, name='max_bin'),\n",
    "    Real(0, 10, name='gamma')\n",
    "]\n",
    "\n",
    "lgb_space  = [\n",
    "    #Real(0.001, 0.1, name='learning_rate'),\n",
    "    Integer(3, 10, name='max_depth'),\n",
    "    Integer(50, 200, name='min_child_weight'),\n",
    "    Real(1, 400,  name='scale_pos_weight'),\n",
    "    Real(0.6, 0.9, name='subsample'),\n",
    "    Real(0.6, 0.9, name='colsample_bytree'),\n",
    "    Real(0, 5, name='reg_lambda'),\n",
    "    Integer(100, 255, name='max_bin')\n",
    "]\n",
    "\n",
    "cat_space = [\n",
    "    Real(0.001, 0.1, name='learning_rate'),\n",
    "    Integer(3, 10, name='depth'),\n",
    "    Real(1, 400,  name='scale_pos_weight'),\n",
    "    Real(0.1, 0.9, name='subsample'),\n",
    "    Real(0.1, 0.9, name='rsm'), # Alias: colsample_bylevel\n",
    "    Real(0, 5, name='l2_leaf_reg'),\n",
    "    Integer(100, 255, name='max_bin'),\n",
    "    Categorical(['Gradient'], name='leaf_estimation_method'),\n",
    "    Categorical(['Bernoulli'], name='bootstrap_type'), # Bayesian not support subsample\n",
    "    Integer(1, 8, name='leaf_estimation_iterations'),\n",
    "    Integer(10, 31, name='one_hot_max_size')\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_of_iter = 1000\n",
    "num_early_stopping = 50\n",
    "num_verbose_eval = 100\n",
    "metric = 'rmse'\n",
    "\n",
    "xgb_sk_params = {\n",
    "    'learning_rate': 0.1,\n",
    "    'n_estimators': num_of_iter,                                   \n",
    "    'objective': 'reg:squarederror', # binary:logistic\n",
    "    'n_jobs': multiprocessing.cpu_count(),\n",
    "    #'tree_method': \"gpu_hist\",  # gpu_hist\n",
    "    #'n_gpus': -1,\n",
    "    'eval_metric': [metric], # logloss\n",
    "    'random_state':  seed,\n",
    "    'verbosity ': 0,\n",
    "    #'gamma': 1.718862, # Minimum loss reduction required to make a further partition on a leaf node of the tree, alias min_split_loss. It acts as a regularization parameter. Either 0, 1 or 5.\n",
    "    #'max_depth': 3, # 0 means no limit (useful only for depth wise grow policy).\n",
    "    #'min_child_weight': 156, # Minimum sum of instance weight (hessian) needed in a child.\n",
    "    #'subsample': 0.729009, # Subsample ratio of the training instances.\n",
    "    #'colsample_bytree': 0.884221, # subsample ratio of columns when constructing each tree.\n",
    "    #'colsample_bylevel': 0.034, # subsample ratio of columns for each level.\n",
    "    #'reg_lambda': 1e-3, # L2 regularization. Increasing this value will make model more conservative.\n",
    "    #'reg_alpha': 0, # L1 regularization. Increasing this value will make model more conservative.\n",
    "    #'scale_pos_weight': weight_ratio, # Control the balance of positive and negative weights, useful for unbalanced classes.\n",
    "    #'grow_policy': \"lossguide\", # split at nodes with highest loss change.\n",
    "    #'max_leaves': 255, # Maximum number of nodes to be added. (for lossguide grow policy).\n",
    "    #'max_bin': 115, # Increasing this number improves the optimality of splits at the cost of higher computation time.\n",
    "}\n",
    "\n",
    "lgb_sk_params = {\n",
    "    'boosting_type': 'gbdt', # goss, dart\n",
    "    #'num_leaves': 80,\n",
    "    #'max_depth': 5,\n",
    "    'learning_rate': 0.0010151324067998776,\n",
    "    'n_estimators': num_of_iter,\n",
    "    #'subsample_for_bin': 200000,  # Number of samples for constructing bin\n",
    "    'objective': 'regression_l2',\n",
    "    'metrics': [metric],\n",
    "    #'min_split_gain': 0,  # lambda_l1, lambda_l2 and min_gain_to_split to regularization\n",
    "    #'min_child_weight': 1,  # Minimum sum of instance weight(hessian) needed in a child(leaf)\n",
    "    #'min_child_samples': 100,  # Minimum number of data need in a child(min_data_in_leaf)\n",
    "    #'subsample': 0.8,\n",
    "    #'colsample_bytree': 0.8,\n",
    "    #'reg_alpha': 3,  # L1 regularization term on weights\n",
    "    #'reg_lambda': 0.191472,\n",
    "    'random_state': seed,\n",
    "    'n_jobs': multiprocessing.cpu_count(),\n",
    "    #'scale_pos_weight': 7.369937,\n",
    "    #'max_bin': 255\n",
    "}\n",
    "\n",
    "cat_sk_params = {\n",
    "    'loss_function': 'RMSE',\n",
    "    'iterations': num_of_iter,\n",
    "    'learning_rate': 0.1,\n",
    "    'random_state': seed,\n",
    "    'eval_metric': ['RMSE', 'MAPE'],\n",
    "    #'l2_leaf_reg': 0.01,\n",
    "    #'bootstrap_type': 'Bayesian',\n",
    "    #'subsample': 0.8, # only use at bootstrap type is [Poisson, Bernoulli]\n",
    "    'use_best_model': True,\n",
    "    #'depth': 5,\n",
    "    #'one_hot_max_size': 31,\n",
    "    #'colsample_bylevel': 0.8,\n",
    "    #'leaf_estimation_method': 'Gradient', # [Newton, Gradient]\n",
    "    #'class_weights': [1, 0.9038461538461537],\n",
    "    #'max_bin': 128, # alias max_bin\n",
    "    'thread_count': multiprocessing.cpu_count()    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "@use_named_args(lgb_space)\n",
    "def objective(**params):\n",
    "    print('--- params ---\\n{}'.format(params))\n",
    "    num_of_iter = 1000\n",
    "    num_early_stopping = 50\n",
    "    num_verbose_eval = 100\n",
    "\n",
    "    n_splits = 3\n",
    "    #folds = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=seed)\n",
    "    #Kflods = folds.split(train_df[features_cols].values, train_df[target_col].values)\n",
    "    folds = TimeSeriesSplit(n_splits=5)\n",
    "    Kflods = folds.split(train_df[features_cols].values, train_df[target_col].values)\n",
    "\n",
    "    oof = np.zeros(len(train_df))\n",
    "    feature_importance_df = pd.DataFrame()\n",
    "    total_fold_loss_df = pd.DataFrame()\n",
    "    target_encoding_cols = ['date_block_num', 'shop_id', 'item_id']\n",
    "    mean_enc = None\n",
    "    model_name = 'lgb'\n",
    "\n",
    "    for fold, (trn_idx, val_idx) in enumerate(Kflods):\n",
    "        print(\"===== Fold {} =====\".format(fold))\n",
    "        trn_idx = shuffle(trn_idx)\n",
    "        train_x, train_y = train_df.iloc[trn_idx][features_cols], train_df.iloc[trn_idx][target_col]\n",
    "        valid_x, valid_y = train_df.iloc[val_idx][features_cols], train_df.iloc[val_idx][target_col]\n",
    "        features_cols_v2 = features_cols.copy()\n",
    "        if mean_enc == 'mean':\n",
    "            for f in target_encoding_cols:\n",
    "                train_x, enc_value, prior_mean, feature_name = mean_encoding(train_x, train_y, f, target_col)\n",
    "                valid_x[feature_name] = valid_x[f].map(enc_value)\n",
    "                valid_x[feature_name].fillna(prior_mean, inplace=True)    \n",
    "                features_cols_v2.remove(f)\n",
    "                features_cols_v2.append(feature_name)\n",
    "        elif mean_enc == 'smooth':\n",
    "            for f in target_encoding_cols:\n",
    "                train_x, enc_value, prior_mean, feature_name = smooth_mean_encoding(train_x, train_y, f, target_col)\n",
    "                valid_x[feature_name] = valid_x[f].map(enc_value)\n",
    "                valid_x[feature_name].fillna(prior_mean, inplace=True)    \n",
    "                features_cols_v2.append(feature_name)\n",
    "        elif mean_enc == 'beta':\n",
    "            prior_mean = np.mean(train_y)\n",
    "            for f in target_encoding_cols:\n",
    "                stats = train_df.iloc[trn_idx].groupby(f).agg(['sum', 'count'])['label'].reset_index()\n",
    "                train_x, feature_name = beta_mean_encoding(train_x, f, target_col, stats, prior_mean)\n",
    "                valid_x, _ = beta_mean_encoding(valid_x, f, target_col, stats, prior_mean)\n",
    "                features_cols_v2.append(feature_name)\n",
    "\n",
    "        eval_set = [(train_x[features_cols_v2], train_y), (valid_x[features_cols_v2], valid_y)]\n",
    "        if model_name == 'xgb':\n",
    "            xgb_sk_params.update({'random_state': fold + np.random.randint(999) + seed})\n",
    "            cv_model = xgb.XGBRegressor(**xgb_sk_params)\n",
    "            cv_model.fit(X=train_x[features_cols_v2],\n",
    "                         y=train_y, \n",
    "                         eval_set=eval_set,             \n",
    "                         early_stopping_rounds=num_early_stopping, \n",
    "                         verbose=num_verbose_eval) \n",
    "            loss = cv_model.evals_result().items()\n",
    "        elif model_name == 'lgb':\n",
    "            lgb_sk_params.update({'random_state': fold + np.random.randint(999) + seed})\n",
    "            cv_model = lgb.LGBMRegressor(**lgb_sk_params)    \n",
    "            cv_model.fit(X=train_x[features_cols_v2],\n",
    "                         y=train_y, \n",
    "                         eval_set=eval_set,    \n",
    "                         eval_names=['validation_0', 'validation_1'],\n",
    "                         early_stopping_rounds=num_early_stopping, \n",
    "                         verbose=num_verbose_eval) \n",
    "            loss = cv_model.evals_result_.items()\n",
    "\n",
    "        # loss \n",
    "        fold_loss_df = pd.DataFrame(columns=['fold', 'type', 'loss'])\n",
    "        for k, v in loss:\n",
    "            if k == 'validation_0':        \n",
    "                fold_loss_df['loss'] = v[list(v.keys())[0]]\n",
    "                fold_loss_df['fold'] = fold + 1\n",
    "                fold_loss_df['type'] = 'train'                \n",
    "            elif k == 'validation_1':\n",
    "                fold_loss_df['loss'] = v[list(v.keys())[0]]\n",
    "                fold_loss_df['fold'] = fold + 1\n",
    "                fold_loss_df['type'] = 'valid'                \n",
    "            total_fold_loss_df = pd.concat([total_fold_loss_df, fold_loss_df], axis=0)\n",
    "\n",
    "        # feature importance\n",
    "        fold_importance_df = pd.DataFrame()\n",
    "        fold_importance_df[\"feature\"] = features_cols_v2\n",
    "        fold_importance_df[\"importance\"] = cv_model.feature_importances_\n",
    "        fold_importance_df[\"fold\"] = fold + 1\n",
    "        feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
    "\n",
    "        # evaluation\n",
    "        if model_name == 'xgb':\n",
    "            oof[val_idx] += cv_model.predict(valid_x[features_cols_v2], \n",
    "                                             ntree_limit=cv_model.best_iteration)\n",
    "        elif model_name == 'lgb':\n",
    "            oof[val_idx] += cv_model.predict(valid_x[features_cols_v2], \n",
    "                                                   ntree_limit=cv_model.best_iteration_)\n",
    "\n",
    "        #print()\n",
    "        #print('MSE:', mean_squared_error(valid_y, oof[val_idx]))\n",
    "        #print('RMSE:', np.sqrt(mean_squared_error(valid_y, oof[val_idx])))\n",
    "        #print('R2 score:', r2_score(valid_y, oof[val_idx]))\n",
    "\n",
    "    rmse = np.sqrt(mean_squared_error(train_df[target_col], oof))        \n",
    "    gc.collect()    \n",
    "    return  rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- params ---\n",
      "{'scale_pos_weight': 384.5916265944546, 'reg_lambda': 3.761154658733963, 'min_child_weight': 81, 'colsample_bytree': 0.7459169401086646, 'subsample': 0.6980429935283096, 'max_depth': 10, 'max_bin': 247}\n",
      "===== Fold 0 =====\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[100]\tvalidation_0's rmse: 1.17778\tvalidation_1's rmse: 1.06014\n",
      "[200]\tvalidation_0's rmse: 1.13259\tvalidation_1's rmse: 1.02608\n",
      "[300]\tvalidation_0's rmse: 1.09344\tvalidation_1's rmse: 0.996503\n",
      "[400]\tvalidation_0's rmse: 1.05943\tvalidation_1's rmse: 0.971622\n",
      "[500]\tvalidation_0's rmse: 1.03026\tvalidation_1's rmse: 0.950167\n",
      "[600]\tvalidation_0's rmse: 1.00491\tvalidation_1's rmse: 0.931386\n",
      "[700]\tvalidation_0's rmse: 0.982868\tvalidation_1's rmse: 0.915454\n",
      "[800]\tvalidation_0's rmse: 0.963882\tvalidation_1's rmse: 0.902229\n",
      "[900]\tvalidation_0's rmse: 0.947543\tvalidation_1's rmse: 0.891156\n",
      "[1000]\tvalidation_0's rmse: 0.933357\tvalidation_1's rmse: 0.881882\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalidation_0's rmse: 0.933357\tvalidation_1's rmse: 0.881882\n",
      "===== Fold 1 =====\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[100]\tvalidation_0's rmse: 1.11899\tvalidation_1's rmse: 1.14987\n",
      "[200]\tvalidation_0's rmse: 1.07786\tvalidation_1's rmse: 1.11727\n",
      "[300]\tvalidation_0's rmse: 1.04274\tvalidation_1's rmse: 1.08917\n",
      "[400]\tvalidation_0's rmse: 1.01267\tvalidation_1's rmse: 1.06524\n",
      "[500]\tvalidation_0's rmse: 0.986845\tvalidation_1's rmse: 1.0447\n",
      "[600]\tvalidation_0's rmse: 0.964689\tvalidation_1's rmse: 1.02755\n",
      "[700]\tvalidation_0's rmse: 0.945579\tvalidation_1's rmse: 1.0126\n",
      "[800]\tvalidation_0's rmse: 0.929115\tvalidation_1's rmse: 0.999388\n",
      "[900]\tvalidation_0's rmse: 0.915027\tvalidation_1's rmse: 0.98821\n",
      "[1000]\tvalidation_0's rmse: 0.902887\tvalidation_1's rmse: 0.978731\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalidation_0's rmse: 0.902887\tvalidation_1's rmse: 0.978731\n",
      "===== Fold 2 =====\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[100]\tvalidation_0's rmse: 1.12753\tvalidation_1's rmse: 1.35844\n",
      "[200]\tvalidation_0's rmse: 1.08805\tvalidation_1's rmse: 1.31627\n",
      "[300]\tvalidation_0's rmse: 1.05437\tvalidation_1's rmse: 1.28019\n",
      "[400]\tvalidation_0's rmse: 1.02563\tvalidation_1's rmse: 1.2488\n",
      "[500]\tvalidation_0's rmse: 1.00093\tvalidation_1's rmse: 1.22172\n",
      "[600]\tvalidation_0's rmse: 0.980036\tvalidation_1's rmse: 1.19889\n",
      "[700]\tvalidation_0's rmse: 0.962091\tvalidation_1's rmse: 1.17929\n",
      "[800]\tvalidation_0's rmse: 0.946609\tvalidation_1's rmse: 1.16241\n",
      "[900]\tvalidation_0's rmse: 0.933387\tvalidation_1's rmse: 1.14783\n",
      "[1000]\tvalidation_0's rmse: 0.922015\tvalidation_1's rmse: 1.1351\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalidation_0's rmse: 0.922015\tvalidation_1's rmse: 1.1351\n",
      "===== Fold 3 =====\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[100]\tvalidation_0's rmse: 1.18734\tvalidation_1's rmse: 1.04894\n",
      "[200]\tvalidation_0's rmse: 1.14573\tvalidation_1's rmse: 1.01003\n",
      "[300]\tvalidation_0's rmse: 1.11022\tvalidation_1's rmse: 0.977366\n",
      "[400]\tvalidation_0's rmse: 1.07984\tvalidation_1's rmse: 0.95011\n",
      "[500]\tvalidation_0's rmse: 1.05377\tvalidation_1's rmse: 0.927073\n",
      "[600]\tvalidation_0's rmse: 1.03151\tvalidation_1's rmse: 0.908231\n",
      "[700]\tvalidation_0's rmse: 1.01242\tvalidation_1's rmse: 0.892302\n",
      "[1000]\tvalidation_0's rmse: 0.97001\tvalidation_1's rmse: 0.859734\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalidation_0's rmse: 0.97001\tvalidation_1's rmse: 0.859734\n",
      "===== Fold 4 =====\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[100]\tvalidation_0's rmse: 1.1623\tvalidation_1's rmse: 1.03755\n",
      "[200]\tvalidation_0's rmse: 1.12219\tvalidation_1's rmse: 1.00333\n",
      "[300]\tvalidation_0's rmse: 1.08796\tvalidation_1's rmse: 0.97423\n",
      "[400]\tvalidation_0's rmse: 1.05871\tvalidation_1's rmse: 0.949506\n",
      "[500]\tvalidation_0's rmse: 1.03367\tvalidation_1's rmse: 0.928444\n",
      "[600]\tvalidation_0's rmse: 1.01219\tvalidation_1's rmse: 0.910514\n",
      "[700]\tvalidation_0's rmse: 0.993786\tvalidation_1's rmse: 0.895096\n",
      "[800]\tvalidation_0's rmse: 0.978075\tvalidation_1's rmse: 0.881812\n",
      "[900]\tvalidation_0's rmse: 0.964586\tvalidation_1's rmse: 0.870483\n",
      "[1000]\tvalidation_0's rmse: 0.953013\tvalidation_1's rmse: 0.860802\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalidation_0's rmse: 0.953013\tvalidation_1's rmse: 0.860802\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method BaseSession._Callable.__del__ of <tensorflow.python.client.session.BaseSession._Callable object at 0x7fe9789a3470>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\", line 1455, in __del__\n",
      "    self._session._session, self._handle, status)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/errors_impl.py\", line 528, in __exit__\n",
      "    c_api.TF_GetCode(self.status.status))\n",
      "tensorflow.python.framework.errors_impl.CancelledError: Session has been closed.\n",
      "Exception ignored in: <bound method BaseSession._Callable.__del__ of <tensorflow.python.client.session.BaseSession._Callable object at 0x7fe978981780>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\", line 1455, in __del__\n",
      "    self._session._session, self._handle, status)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/errors_impl.py\", line 528, in __exit__\n",
      "    c_api.TF_GetCode(self.status.status))\n",
      "tensorflow.python.framework.errors_impl.CancelledError: Session has been closed.\n",
      "Exception ignored in: <bound method BaseSession._Callable.__del__ of <tensorflow.python.client.session.BaseSession._Callable object at 0x7fe978a13390>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\", line 1455, in __del__\n",
      "    self._session._session, self._handle, status)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/errors_impl.py\", line 528, in __exit__\n",
      "    c_api.TF_GetCode(self.status.status))\n",
      "tensorflow.python.framework.errors_impl.CancelledError: Session has been closed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- params ---\n",
      "{'scale_pos_weight': 376.5782491234839, 'reg_lambda': 1.8685942788711083, 'min_child_weight': 151, 'colsample_bytree': 0.6302239906759548, 'subsample': 0.8936072645681281, 'max_depth': 5, 'max_bin': 156}\n",
      "===== Fold 0 =====\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[100]\tvalidation_0's rmse: 1.17781\tvalidation_1's rmse: 1.06013\n",
      "[200]\tvalidation_0's rmse: 1.1326\tvalidation_1's rmse: 1.02605\n",
      "[300]\tvalidation_0's rmse: 1.09342\tvalidation_1's rmse: 0.996502\n",
      "[400]\tvalidation_0's rmse: 1.05944\tvalidation_1's rmse: 0.971703\n",
      "[500]\tvalidation_0's rmse: 1.03024\tvalidation_1's rmse: 0.950275\n",
      "[600]\tvalidation_0's rmse: 1.00489\tvalidation_1's rmse: 0.931518\n",
      "[700]\tvalidation_0's rmse: 0.982846\tvalidation_1's rmse: 0.915557\n",
      "[800]\tvalidation_0's rmse: 0.9638\tvalidation_1's rmse: 0.902302\n",
      "[900]\tvalidation_0's rmse: 0.94742\tvalidation_1's rmse: 0.891304\n",
      "[1000]\tvalidation_0's rmse: 0.93324\tvalidation_1's rmse: 0.88201\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalidation_0's rmse: 0.93324\tvalidation_1's rmse: 0.88201\n",
      "===== Fold 1 =====\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[100]\tvalidation_0's rmse: 1.11907\tvalidation_1's rmse: 1.14999\n",
      "[200]\tvalidation_0's rmse: 1.07805\tvalidation_1's rmse: 1.11705\n",
      "[300]\tvalidation_0's rmse: 1.04301\tvalidation_1's rmse: 1.08859\n",
      "[400]\tvalidation_0's rmse: 1.0129\tvalidation_1's rmse: 1.06427\n",
      "[500]\tvalidation_0's rmse: 0.987053\tvalidation_1's rmse: 1.04352\n",
      "[600]\tvalidation_0's rmse: 0.964917\tvalidation_1's rmse: 1.02607\n",
      "[700]\tvalidation_0's rmse: 0.945862\tvalidation_1's rmse: 1.01077\n",
      "[800]\tvalidation_0's rmse: 0.929374\tvalidation_1's rmse: 0.997559\n",
      "[900]\tvalidation_0's rmse: 0.915269\tvalidation_1's rmse: 0.986329\n",
      "[1000]\tvalidation_0's rmse: 0.903114\tvalidation_1's rmse: 0.976756\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalidation_0's rmse: 0.903114\tvalidation_1's rmse: 0.976756\n",
      "===== Fold 2 =====\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[100]\tvalidation_0's rmse: 1.12753\tvalidation_1's rmse: 1.35842\n",
      "[200]\tvalidation_0's rmse: 1.08806\tvalidation_1's rmse: 1.31633\n",
      "[300]\tvalidation_0's rmse: 1.05438\tvalidation_1's rmse: 1.28036\n",
      "[400]\tvalidation_0's rmse: 1.02562\tvalidation_1's rmse: 1.24904\n",
      "[500]\tvalidation_0's rmse: 1.00095\tvalidation_1's rmse: 1.22186\n",
      "[600]\tvalidation_0's rmse: 0.980001\tvalidation_1's rmse: 1.19935\n",
      "[700]\tvalidation_0's rmse: 0.96208\tvalidation_1's rmse: 1.1799\n",
      "[800]\tvalidation_0's rmse: 0.946631\tvalidation_1's rmse: 1.16309\n",
      "[900]\tvalidation_0's rmse: 0.933396\tvalidation_1's rmse: 1.14859\n",
      "[1000]\tvalidation_0's rmse: 0.922022\tvalidation_1's rmse: 1.13599\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalidation_0's rmse: 0.922022\tvalidation_1's rmse: 1.13599\n",
      "===== Fold 3 =====\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[100]\tvalidation_0's rmse: 1.18736\tvalidation_1's rmse: 1.04895\n",
      "[200]\tvalidation_0's rmse: 1.14577\tvalidation_1's rmse: 1.00991\n",
      "[300]\tvalidation_0's rmse: 1.11027\tvalidation_1's rmse: 0.977261\n",
      "[400]\tvalidation_0's rmse: 1.0799\tvalidation_1's rmse: 0.949976\n",
      "[500]\tvalidation_0's rmse: 1.05385\tvalidation_1's rmse: 0.927021\n",
      "[600]\tvalidation_0's rmse: 1.03159\tvalidation_1's rmse: 0.908151\n",
      "[700]\tvalidation_0's rmse: 1.01251\tvalidation_1's rmse: 0.892225\n",
      "[800]\tvalidation_0's rmse: 0.996157\tvalidation_1's rmse: 0.879271\n",
      "[900]\tvalidation_0's rmse: 0.982141\tvalidation_1's rmse: 0.868492\n",
      "[1000]\tvalidation_0's rmse: 0.970117\tvalidation_1's rmse: 0.859675\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalidation_0's rmse: 0.970117\tvalidation_1's rmse: 0.859675\n",
      "===== Fold 4 =====\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[100]\tvalidation_0's rmse: 1.16228\tvalidation_1's rmse: 1.0376\n",
      "[200]\tvalidation_0's rmse: 1.12212\tvalidation_1's rmse: 1.00343\n",
      "[300]\tvalidation_0's rmse: 1.08786\tvalidation_1's rmse: 0.974228\n",
      "[400]\tvalidation_0's rmse: 1.05857\tvalidation_1's rmse: 0.949376\n",
      "[500]\tvalidation_0's rmse: 1.03351\tvalidation_1's rmse: 0.928193\n",
      "[600]\tvalidation_0's rmse: 1.01196\tvalidation_1's rmse: 0.910142\n",
      "[700]\tvalidation_0's rmse: 0.993526\tvalidation_1's rmse: 0.894666\n",
      "[800]\tvalidation_0's rmse: 0.977768\tvalidation_1's rmse: 0.881446\n",
      "[900]\tvalidation_0's rmse: 0.964249\tvalidation_1's rmse: 0.870138\n",
      "[1000]\tvalidation_0's rmse: 0.952645\tvalidation_1's rmse: 0.860404\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalidation_0's rmse: 0.952645\tvalidation_1's rmse: 0.860404\n",
      "--- params ---\n",
      "{'scale_pos_weight': 42.27804148101679, 'reg_lambda': 3.221241629900831, 'min_child_weight': 114, 'colsample_bytree': 0.8437459342370678, 'subsample': 0.7702716888064499, 'max_depth': 5, 'max_bin': 210}\n",
      "===== Fold 0 =====\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[100]\tvalidation_0's rmse: 1.17776\tvalidation_1's rmse: 1.06043\n",
      "[200]\tvalidation_0's rmse: 1.13253\tvalidation_1's rmse: 1.02615\n",
      "[300]\tvalidation_0's rmse: 1.09334\tvalidation_1's rmse: 0.996572\n",
      "[400]\tvalidation_0's rmse: 1.05932\tvalidation_1's rmse: 0.971667\n",
      "[500]\tvalidation_0's rmse: 1.03009\tvalidation_1's rmse: 0.950184\n",
      "[600]\tvalidation_0's rmse: 1.00477\tvalidation_1's rmse: 0.931465\n",
      "[700]\tvalidation_0's rmse: 0.982807\tvalidation_1's rmse: 0.915552\n",
      "[800]\tvalidation_0's rmse: 0.96378\tvalidation_1's rmse: 0.902393\n",
      "[900]\tvalidation_0's rmse: 0.947469\tvalidation_1's rmse: 0.891336\n",
      "[1000]\tvalidation_0's rmse: 0.933263\tvalidation_1's rmse: 0.881973\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalidation_0's rmse: 0.933263\tvalidation_1's rmse: 0.881973\n",
      "===== Fold 1 =====\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[100]\tvalidation_0's rmse: 1.11896\tvalidation_1's rmse: 1.15037\n",
      "[200]\tvalidation_0's rmse: 1.07794\tvalidation_1's rmse: 1.1181\n",
      "[300]\tvalidation_0's rmse: 1.0428\tvalidation_1's rmse: 1.09017\n",
      "[400]\tvalidation_0's rmse: 1.01274\tvalidation_1's rmse: 1.0662\n",
      "[500]\tvalidation_0's rmse: 0.986904\tvalidation_1's rmse: 1.04554\n",
      "[600]\tvalidation_0's rmse: 0.964745\tvalidation_1's rmse: 1.02824\n",
      "[700]\tvalidation_0's rmse: 0.945611\tvalidation_1's rmse: 1.01315\n",
      "[800]\tvalidation_0's rmse: 0.929133\tvalidation_1's rmse: 0.999963\n",
      "[900]\tvalidation_0's rmse: 0.915075\tvalidation_1's rmse: 0.988798\n",
      "[1000]\tvalidation_0's rmse: 0.902933\tvalidation_1's rmse: 0.979345\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalidation_0's rmse: 0.902933\tvalidation_1's rmse: 0.979345\n",
      "===== Fold 2 =====\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[100]\tvalidation_0's rmse: 1.12753\tvalidation_1's rmse: 1.35842\n",
      "[200]\tvalidation_0's rmse: 1.08805\tvalidation_1's rmse: 1.31631\n",
      "[300]\tvalidation_0's rmse: 1.05438\tvalidation_1's rmse: 1.28025\n",
      "[400]\tvalidation_0's rmse: 1.0256\tvalidation_1's rmse: 1.24898\n",
      "[500]\tvalidation_0's rmse: 1.0009\tvalidation_1's rmse: 1.22165\n",
      "[600]\tvalidation_0's rmse: 0.979957\tvalidation_1's rmse: 1.19877\n",
      "[700]\tvalidation_0's rmse: 0.96203\tvalidation_1's rmse: 1.17917\n",
      "[800]\tvalidation_0's rmse: 0.946541\tvalidation_1's rmse: 1.16216\n",
      "[900]\tvalidation_0's rmse: 0.933348\tvalidation_1's rmse: 1.14755\n",
      "[1000]\tvalidation_0's rmse: 0.921983\tvalidation_1's rmse: 1.13483\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalidation_0's rmse: 0.921983\tvalidation_1's rmse: 1.13483\n",
      "===== Fold 3 =====\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[100]\tvalidation_0's rmse: 1.18736\tvalidation_1's rmse: 1.04883\n",
      "[200]\tvalidation_0's rmse: 1.14577\tvalidation_1's rmse: 1.00982\n",
      "[300]\tvalidation_0's rmse: 1.11025\tvalidation_1's rmse: 0.977146\n",
      "[400]\tvalidation_0's rmse: 1.07986\tvalidation_1's rmse: 0.949888\n",
      "[500]\tvalidation_0's rmse: 1.05377\tvalidation_1's rmse: 0.927001\n",
      "[600]\tvalidation_0's rmse: 1.03151\tvalidation_1's rmse: 0.908164\n",
      "[700]\tvalidation_0's rmse: 1.01241\tvalidation_1's rmse: 0.89224\n",
      "[800]\tvalidation_0's rmse: 0.996019\tvalidation_1's rmse: 0.879189\n",
      "[900]\tvalidation_0's rmse: 0.982004\tvalidation_1's rmse: 0.868453\n",
      "[1000]\tvalidation_0's rmse: 0.969947\tvalidation_1's rmse: 0.859555\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalidation_0's rmse: 0.969947\tvalidation_1's rmse: 0.859555\n",
      "===== Fold 4 =====\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[100]\tvalidation_0's rmse: 1.16213\tvalidation_1's rmse: 1.03765\n",
      "[200]\tvalidation_0's rmse: 1.12188\tvalidation_1's rmse: 1.00354\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[300]\tvalidation_0's rmse: 1.08755\tvalidation_1's rmse: 0.974418\n",
      "[400]\tvalidation_0's rmse: 1.05821\tvalidation_1's rmse: 0.949617\n",
      "[500]\tvalidation_0's rmse: 1.03314\tvalidation_1's rmse: 0.928505\n",
      "[600]\tvalidation_0's rmse: 1.0116\tvalidation_1's rmse: 0.910558\n",
      "[700]\tvalidation_0's rmse: 0.993162\tvalidation_1's rmse: 0.895049\n",
      "[800]\tvalidation_0's rmse: 0.977366\tvalidation_1's rmse: 0.881801\n",
      "[900]\tvalidation_0's rmse: 0.963824\tvalidation_1's rmse: 0.870499\n",
      "[1000]\tvalidation_0's rmse: 0.95221\tvalidation_1's rmse: 0.86084\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalidation_0's rmse: 0.95221\tvalidation_1's rmse: 0.86084\n",
      "--- params ---\n",
      "{'scale_pos_weight': 195.02460619317566, 'reg_lambda': 3.3769098780033415, 'min_child_weight': 130, 'colsample_bytree': 0.6346565260900119, 'subsample': 0.7686997271683054, 'max_depth': 4, 'max_bin': 190}\n",
      "===== Fold 0 =====\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[100]\tvalidation_0's rmse: 1.17766\tvalidation_1's rmse: 1.05999\n",
      "[200]\tvalidation_0's rmse: 1.13253\tvalidation_1's rmse: 1.02592\n",
      "[300]\tvalidation_0's rmse: 1.09339\tvalidation_1's rmse: 0.996329\n",
      "[400]\tvalidation_0's rmse: 1.05939\tvalidation_1's rmse: 0.971369\n",
      "[500]\tvalidation_0's rmse: 1.03017\tvalidation_1's rmse: 0.9499\n",
      "[600]\tvalidation_0's rmse: 1.00483\tvalidation_1's rmse: 0.93117\n",
      "[700]\tvalidation_0's rmse: 0.982763\tvalidation_1's rmse: 0.915222\n",
      "[800]\tvalidation_0's rmse: 0.963752\tvalidation_1's rmse: 0.90212\n",
      "[900]\tvalidation_0's rmse: 0.947325\tvalidation_1's rmse: 0.891077\n",
      "[1000]\tvalidation_0's rmse: 0.933134\tvalidation_1's rmse: 0.881832\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalidation_0's rmse: 0.933134\tvalidation_1's rmse: 0.881832\n",
      "===== Fold 1 =====\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[100]\tvalidation_0's rmse: 1.11892\tvalidation_1's rmse: 1.14997\n",
      "[200]\tvalidation_0's rmse: 1.07782\tvalidation_1's rmse: 1.11724\n",
      "[300]\tvalidation_0's rmse: 1.04271\tvalidation_1's rmse: 1.08895\n",
      "[400]\tvalidation_0's rmse: 1.01264\tvalidation_1's rmse: 1.06479\n",
      "[500]\tvalidation_0's rmse: 0.986864\tvalidation_1's rmse: 1.04425\n",
      "[600]\tvalidation_0's rmse: 0.964685\tvalidation_1's rmse: 1.02683\n",
      "[700]\tvalidation_0's rmse: 0.945453\tvalidation_1's rmse: 1.0117\n",
      "[800]\tvalidation_0's rmse: 0.928918\tvalidation_1's rmse: 0.998422\n",
      "[900]\tvalidation_0's rmse: 0.914825\tvalidation_1's rmse: 0.987221\n",
      "[1000]\tvalidation_0's rmse: 0.90268\tvalidation_1's rmse: 0.977713\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalidation_0's rmse: 0.90268\tvalidation_1's rmse: 0.977713\n",
      "===== Fold 2 =====\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[100]\tvalidation_0's rmse: 1.12752\tvalidation_1's rmse: 1.35847\n",
      "[200]\tvalidation_0's rmse: 1.08804\tvalidation_1's rmse: 1.31625\n",
      "[300]\tvalidation_0's rmse: 1.05437\tvalidation_1's rmse: 1.28001\n",
      "[400]\tvalidation_0's rmse: 1.0256\tvalidation_1's rmse: 1.24872\n",
      "[500]\tvalidation_0's rmse: 1.00089\tvalidation_1's rmse: 1.22143\n",
      "[600]\tvalidation_0's rmse: 0.979965\tvalidation_1's rmse: 1.1985\n",
      "[700]\tvalidation_0's rmse: 0.962038\tvalidation_1's rmse: 1.17888\n",
      "[800]\tvalidation_0's rmse: 0.946546\tvalidation_1's rmse: 1.16189\n",
      "[900]\tvalidation_0's rmse: 0.933314\tvalidation_1's rmse: 1.14738\n",
      "[1000]\tvalidation_0's rmse: 0.921933\tvalidation_1's rmse: 1.13459\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalidation_0's rmse: 0.921933\tvalidation_1's rmse: 1.13459\n",
      "===== Fold 3 =====\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[100]\tvalidation_0's rmse: 1.18732\tvalidation_1's rmse: 1.04887\n",
      "[200]\tvalidation_0's rmse: 1.14569\tvalidation_1's rmse: 1.00985\n",
      "[300]\tvalidation_0's rmse: 1.11018\tvalidation_1's rmse: 0.977118\n",
      "[400]\tvalidation_0's rmse: 1.07982\tvalidation_1's rmse: 0.949854\n",
      "[500]\tvalidation_0's rmse: 1.05375\tvalidation_1's rmse: 0.926866\n",
      "[600]\tvalidation_0's rmse: 1.03148\tvalidation_1's rmse: 0.907952\n",
      "[700]\tvalidation_0's rmse: 1.01241\tvalidation_1's rmse: 0.892061\n",
      "[800]\tvalidation_0's rmse: 0.996028\tvalidation_1's rmse: 0.879062\n",
      "[900]\tvalidation_0's rmse: 0.982006\tvalidation_1's rmse: 0.8683\n",
      "[1000]\tvalidation_0's rmse: 0.970013\tvalidation_1's rmse: 0.859513\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalidation_0's rmse: 0.970013\tvalidation_1's rmse: 0.859513\n",
      "===== Fold 4 =====\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[100]\tvalidation_0's rmse: 1.16225\tvalidation_1's rmse: 1.03758\n",
      "[200]\tvalidation_0's rmse: 1.12212\tvalidation_1's rmse: 1.00344\n",
      "[300]\tvalidation_0's rmse: 1.08787\tvalidation_1's rmse: 0.974361\n",
      "[400]\tvalidation_0's rmse: 1.05859\tvalidation_1's rmse: 0.94964\n",
      "[500]\tvalidation_0's rmse: 1.03356\tvalidation_1's rmse: 0.928597\n",
      "[600]\tvalidation_0's rmse: 1.01201\tvalidation_1's rmse: 0.910574\n",
      "[700]\tvalidation_0's rmse: 0.993558\tvalidation_1's rmse: 0.89512\n",
      "[800]\tvalidation_0's rmse: 0.977825\tvalidation_1's rmse: 0.881964\n",
      "[900]\tvalidation_0's rmse: 0.964346\tvalidation_1's rmse: 0.870697\n",
      "[1000]\tvalidation_0's rmse: 0.952781\tvalidation_1's rmse: 0.860944\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalidation_0's rmse: 0.952781\tvalidation_1's rmse: 0.860944\n",
      "--- params ---\n",
      "{'scale_pos_weight': 113.74807226501284, 'reg_lambda': 0.7434321866582173, 'min_child_weight': 110, 'colsample_bytree': 0.860164119435469, 'subsample': 0.6881598320062081, 'max_depth': 5, 'max_bin': 110}\n",
      "===== Fold 0 =====\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[1000]\tvalidation_0's rmse: 0.933357\tvalidation_1's rmse: 0.882305\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalidation_0's rmse: 0.933357\tvalidation_1's rmse: 0.882305\n",
      "===== Fold 1 =====\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[100]\tvalidation_0's rmse: 1.11904\tvalidation_1's rmse: 1.14995\n",
      "[200]\tvalidation_0's rmse: 1.07798\tvalidation_1's rmse: 1.1175\n",
      "[300]\tvalidation_0's rmse: 1.04297\tvalidation_1's rmse: 1.08926\n",
      "[400]\tvalidation_0's rmse: 1.01294\tvalidation_1's rmse: 1.0653\n",
      "[500]\tvalidation_0's rmse: 0.987185\tvalidation_1's rmse: 1.04478\n",
      "[600]\tvalidation_0's rmse: 0.965047\tvalidation_1's rmse: 1.02736\n",
      "[700]\tvalidation_0's rmse: 0.945996\tvalidation_1's rmse: 1.01226\n",
      "[800]\tvalidation_0's rmse: 0.929577\tvalidation_1's rmse: 0.999206\n",
      "[900]\tvalidation_0's rmse: 0.915487\tvalidation_1's rmse: 0.988028\n",
      "[1000]\tvalidation_0's rmse: 0.90335\tvalidation_1's rmse: 0.978714\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalidation_0's rmse: 0.90335\tvalidation_1's rmse: 0.978714\n",
      "===== Fold 2 =====\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[100]\tvalidation_0's rmse: 1.12753\tvalidation_1's rmse: 1.3584\n",
      "[200]\tvalidation_0's rmse: 1.08808\tvalidation_1's rmse: 1.31629\n",
      "[300]\tvalidation_0's rmse: 1.05437\tvalidation_1's rmse: 1.28026\n",
      "[400]\tvalidation_0's rmse: 1.0256\tvalidation_1's rmse: 1.24897\n",
      "[500]\tvalidation_0's rmse: 1.0009\tvalidation_1's rmse: 1.22153\n",
      "[600]\tvalidation_0's rmse: 0.97997\tvalidation_1's rmse: 1.19854\n",
      "[700]\tvalidation_0's rmse: 0.96205\tvalidation_1's rmse: 1.17899\n",
      "[800]\tvalidation_0's rmse: 0.946597\tvalidation_1's rmse: 1.162\n",
      "[900]\tvalidation_0's rmse: 0.933342\tvalidation_1's rmse: 1.14746\n",
      "[1000]\tvalidation_0's rmse: 0.922007\tvalidation_1's rmse: 1.13465\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalidation_0's rmse: 0.922007\tvalidation_1's rmse: 1.13465\n",
      "===== Fold 3 =====\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[100]\tvalidation_0's rmse: 1.18734\tvalidation_1's rmse: 1.04906\n",
      "[200]\tvalidation_0's rmse: 1.14567\tvalidation_1's rmse: 1.01019\n",
      "[300]\tvalidation_0's rmse: 1.1101\tvalidation_1's rmse: 0.977592\n",
      "[400]\tvalidation_0's rmse: 1.07968\tvalidation_1's rmse: 0.950375\n",
      "[500]\tvalidation_0's rmse: 1.05356\tvalidation_1's rmse: 0.927376\n",
      "[600]\tvalidation_0's rmse: 1.0313\tvalidation_1's rmse: 0.908517\n",
      "[700]\tvalidation_0's rmse: 1.01218\tvalidation_1's rmse: 0.892602\n",
      "[800]\tvalidation_0's rmse: 0.995781\tvalidation_1's rmse: 0.879589\n",
      "[900]\tvalidation_0's rmse: 0.981759\tvalidation_1's rmse: 0.868833\n",
      "[1000]\tvalidation_0's rmse: 0.969736\tvalidation_1's rmse: 0.860048\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalidation_0's rmse: 0.969736\tvalidation_1's rmse: 0.860048\n",
      "===== Fold 4 =====\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[100]\tvalidation_0's rmse: 1.16213\tvalidation_1's rmse: 1.03774\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[200]\tvalidation_0's rmse: 1.12189\tvalidation_1's rmse: 1.00354\n",
      "[300]\tvalidation_0's rmse: 1.08755\tvalidation_1's rmse: 0.974377\n",
      "[400]\tvalidation_0's rmse: 1.0582\tvalidation_1's rmse: 0.949536\n",
      "[500]\tvalidation_0's rmse: 1.03313\tvalidation_1's rmse: 0.928431\n",
      "[600]\tvalidation_0's rmse: 1.01156\tvalidation_1's rmse: 0.910433\n",
      "[700]\tvalidation_0's rmse: 0.99309\tvalidation_1's rmse: 0.894895\n",
      "[800]\tvalidation_0's rmse: 0.977317\tvalidation_1's rmse: 0.881617\n",
      "[900]\tvalidation_0's rmse: 0.96379\tvalidation_1's rmse: 0.870279\n",
      "[1000]\tvalidation_0's rmse: 0.952207\tvalidation_1's rmse: 0.860562\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalidation_0's rmse: 0.952207\tvalidation_1's rmse: 0.860562\n",
      "--- params ---\n",
      "{'scale_pos_weight': 304.9719037703267, 'reg_lambda': 3.8943111498219736, 'min_child_weight': 94, 'colsample_bytree': 0.6834767188235036, 'subsample': 0.7387651355599998, 'max_depth': 8, 'max_bin': 116}\n",
      "===== Fold 0 =====\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[100]\tvalidation_0's rmse: 1.17772\tvalidation_1's rmse: 1.06041\n",
      "[200]\tvalidation_0's rmse: 1.13255\tvalidation_1's rmse: 1.02625\n",
      "[300]\tvalidation_0's rmse: 1.0934\tvalidation_1's rmse: 0.996719\n",
      "[400]\tvalidation_0's rmse: 1.05943\tvalidation_1's rmse: 0.971859\n",
      "[500]\tvalidation_0's rmse: 1.03027\tvalidation_1's rmse: 0.950383\n",
      "[600]\tvalidation_0's rmse: 1.0049\tvalidation_1's rmse: 0.93152\n",
      "[700]\tvalidation_0's rmse: 0.982829\tvalidation_1's rmse: 0.915475\n",
      "[800]\tvalidation_0's rmse: 0.963913\tvalidation_1's rmse: 0.902358\n",
      "[900]\tvalidation_0's rmse: 0.947593\tvalidation_1's rmse: 0.891326\n",
      "[1000]\tvalidation_0's rmse: 0.933398\tvalidation_1's rmse: 0.882016\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalidation_0's rmse: 0.933398\tvalidation_1's rmse: 0.882016\n",
      "===== Fold 1 =====\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[100]\tvalidation_0's rmse: 1.11907\tvalidation_1's rmse: 1.15031\n",
      "[200]\tvalidation_0's rmse: 1.07806\tvalidation_1's rmse: 1.11805\n",
      "[300]\tvalidation_0's rmse: 1.04299\tvalidation_1's rmse: 1.08994\n",
      "[400]\tvalidation_0's rmse: 1.01298\tvalidation_1's rmse: 1.06597\n",
      "[500]\tvalidation_0's rmse: 0.987215\tvalidation_1's rmse: 1.04547\n",
      "[600]\tvalidation_0's rmse: 0.96508\tvalidation_1's rmse: 1.02819\n",
      "[700]\tvalidation_0's rmse: 0.945963\tvalidation_1's rmse: 1.01307\n",
      "[800]\tvalidation_0's rmse: 0.929487\tvalidation_1's rmse: 0.999902\n",
      "[900]\tvalidation_0's rmse: 0.915407\tvalidation_1's rmse: 0.988701\n",
      "[1000]\tvalidation_0's rmse: 0.903298\tvalidation_1's rmse: 0.979303\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalidation_0's rmse: 0.903298\tvalidation_1's rmse: 0.979303\n",
      "===== Fold 2 =====\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[100]\tvalidation_0's rmse: 1.12752\tvalidation_1's rmse: 1.35834\n",
      "[200]\tvalidation_0's rmse: 1.08804\tvalidation_1's rmse: 1.31607\n",
      "[300]\tvalidation_0's rmse: 1.05434\tvalidation_1's rmse: 1.28001\n",
      "[400]\tvalidation_0's rmse: 1.02557\tvalidation_1's rmse: 1.24872\n",
      "[500]\tvalidation_0's rmse: 1.00089\tvalidation_1's rmse: 1.22139\n",
      "[600]\tvalidation_0's rmse: 0.979937\tvalidation_1's rmse: 1.19842\n",
      "[700]\tvalidation_0's rmse: 0.961995\tvalidation_1's rmse: 1.17886\n",
      "[800]\tvalidation_0's rmse: 0.946555\tvalidation_1's rmse: 1.16196\n",
      "[900]\tvalidation_0's rmse: 0.933322\tvalidation_1's rmse: 1.14745\n",
      "[1000]\tvalidation_0's rmse: 0.921957\tvalidation_1's rmse: 1.13463\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalidation_0's rmse: 0.921957\tvalidation_1's rmse: 1.13463\n",
      "===== Fold 3 =====\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[100]\tvalidation_0's rmse: 1.1873\tvalidation_1's rmse: 1.0483\n",
      "[200]\tvalidation_0's rmse: 1.14565\tvalidation_1's rmse: 1.00918\n",
      "[300]\tvalidation_0's rmse: 1.1101\tvalidation_1's rmse: 0.976476\n",
      "[400]\tvalidation_0's rmse: 1.0797\tvalidation_1's rmse: 0.949151\n",
      "[500]\tvalidation_0's rmse: 1.05359\tvalidation_1's rmse: 0.926158\n",
      "[600]\tvalidation_0's rmse: 1.03129\tvalidation_1's rmse: 0.90733\n",
      "[700]\tvalidation_0's rmse: 1.0122\tvalidation_1's rmse: 0.891446\n",
      "[800]\tvalidation_0's rmse: 0.99579\tvalidation_1's rmse: 0.878475\n",
      "[900]\tvalidation_0's rmse: 0.981775\tvalidation_1's rmse: 0.867726\n",
      "[1000]\tvalidation_0's rmse: 0.969729\tvalidation_1's rmse: 0.85891\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalidation_0's rmse: 0.969729\tvalidation_1's rmse: 0.85891\n",
      "===== Fold 4 =====\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[100]\tvalidation_0's rmse: 1.16229\tvalidation_1's rmse: 1.03746\n",
      "[200]\tvalidation_0's rmse: 1.12218\tvalidation_1's rmse: 1.00325\n",
      "[300]\tvalidation_0's rmse: 1.08796\tvalidation_1's rmse: 0.974097\n",
      "[400]\tvalidation_0's rmse: 1.05872\tvalidation_1's rmse: 0.949363\n",
      "[500]\tvalidation_0's rmse: 1.03365\tvalidation_1's rmse: 0.928231\n",
      "[600]\tvalidation_0's rmse: 1.01212\tvalidation_1's rmse: 0.910219\n",
      "[700]\tvalidation_0's rmse: 0.993721\tvalidation_1's rmse: 0.894777\n",
      "[800]\tvalidation_0's rmse: 0.977999\tvalidation_1's rmse: 0.881577\n",
      "[900]\tvalidation_0's rmse: 0.96452\tvalidation_1's rmse: 0.870308\n",
      "[1000]\tvalidation_0's rmse: 0.952945\tvalidation_1's rmse: 0.860665\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalidation_0's rmse: 0.952945\tvalidation_1's rmse: 0.860665\n",
      "--- params ---\n",
      "{'scale_pos_weight': 259.3882358465522, 'reg_lambda': 1.5996773463910088, 'min_child_weight': 194, 'colsample_bytree': 0.7934071276940435, 'subsample': 0.6680698003991048, 'max_depth': 6, 'max_bin': 202}\n",
      "===== Fold 0 =====\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[100]\tvalidation_0's rmse: 1.17763\tvalidation_1's rmse: 1.06033\n",
      "[200]\tvalidation_0's rmse: 1.13243\tvalidation_1's rmse: 1.02607\n",
      "[300]\tvalidation_0's rmse: 1.09324\tvalidation_1's rmse: 0.996516\n",
      "[400]\tvalidation_0's rmse: 1.05924\tvalidation_1's rmse: 0.97159\n",
      "[500]\tvalidation_0's rmse: 1.03002\tvalidation_1's rmse: 0.9501\n",
      "[600]\tvalidation_0's rmse: 1.0047\tvalidation_1's rmse: 0.931305\n",
      "[700]\tvalidation_0's rmse: 0.982729\tvalidation_1's rmse: 0.915341\n",
      "[800]\tvalidation_0's rmse: 0.963776\tvalidation_1's rmse: 0.902234\n",
      "[900]\tvalidation_0's rmse: 0.947486\tvalidation_1's rmse: 0.891195\n",
      "[1000]\tvalidation_0's rmse: 0.933256\tvalidation_1's rmse: 0.881879\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalidation_0's rmse: 0.933256\tvalidation_1's rmse: 0.881879\n",
      "===== Fold 1 =====\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[100]\tvalidation_0's rmse: 1.11897\tvalidation_1's rmse: 1.15\n",
      "[200]\tvalidation_0's rmse: 1.07783\tvalidation_1's rmse: 1.11742\n",
      "[300]\tvalidation_0's rmse: 1.04267\tvalidation_1's rmse: 1.08947\n",
      "[400]\tvalidation_0's rmse: 1.01255\tvalidation_1's rmse: 1.06549\n",
      "[500]\tvalidation_0's rmse: 0.986742\tvalidation_1's rmse: 1.04501\n",
      "[600]\tvalidation_0's rmse: 0.964553\tvalidation_1's rmse: 1.02775\n",
      "[700]\tvalidation_0's rmse: 0.945415\tvalidation_1's rmse: 1.01278\n",
      "[800]\tvalidation_0's rmse: 0.928948\tvalidation_1's rmse: 0.999523\n",
      "[900]\tvalidation_0's rmse: 0.914873\tvalidation_1's rmse: 0.988376\n",
      "[1000]\tvalidation_0's rmse: 0.902709\tvalidation_1's rmse: 0.978931\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalidation_0's rmse: 0.902709\tvalidation_1's rmse: 0.978931\n",
      "===== Fold 2 =====\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[100]\tvalidation_0's rmse: 1.12754\tvalidation_1's rmse: 1.35836\n",
      "[200]\tvalidation_0's rmse: 1.08807\tvalidation_1's rmse: 1.31615\n",
      "[300]\tvalidation_0's rmse: 1.05436\tvalidation_1's rmse: 1.28013\n",
      "[400]\tvalidation_0's rmse: 1.02558\tvalidation_1's rmse: 1.24887\n",
      "[500]\tvalidation_0's rmse: 1.00089\tvalidation_1's rmse: 1.22153\n",
      "[600]\tvalidation_0's rmse: 0.979928\tvalidation_1's rmse: 1.19849\n",
      "[700]\tvalidation_0's rmse: 0.961989\tvalidation_1's rmse: 1.17886\n",
      "[800]\tvalidation_0's rmse: 0.946534\tvalidation_1's rmse: 1.16191\n",
      "[900]\tvalidation_0's rmse: 0.933284\tvalidation_1's rmse: 1.14735\n",
      "[1000]\tvalidation_0's rmse: 0.921887\tvalidation_1's rmse: 1.13456\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalidation_0's rmse: 0.921887\tvalidation_1's rmse: 1.13456\n",
      "===== Fold 3 =====\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[100]\tvalidation_0's rmse: 1.18731\tvalidation_1's rmse: 1.04892\n",
      "[200]\tvalidation_0's rmse: 1.14569\tvalidation_1's rmse: 1.0099\n",
      "[300]\tvalidation_0's rmse: 1.11014\tvalidation_1's rmse: 0.977188\n",
      "[400]\tvalidation_0's rmse: 1.07973\tvalidation_1's rmse: 0.949843\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[500]\tvalidation_0's rmse: 1.05363\tvalidation_1's rmse: 0.926854\n",
      "[600]\tvalidation_0's rmse: 1.03133\tvalidation_1's rmse: 0.907967\n",
      "[700]\tvalidation_0's rmse: 1.01223\tvalidation_1's rmse: 0.892088\n",
      "[800]\tvalidation_0's rmse: 0.995834\tvalidation_1's rmse: 0.8791\n",
      "[900]\tvalidation_0's rmse: 0.981809\tvalidation_1's rmse: 0.868345\n",
      "[1000]\tvalidation_0's rmse: 0.969759\tvalidation_1's rmse: 0.859493\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalidation_0's rmse: 0.969759\tvalidation_1's rmse: 0.859493\n",
      "===== Fold 4 =====\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[100]\tvalidation_0's rmse: 1.16228\tvalidation_1's rmse: 1.03759\n",
      "[200]\tvalidation_0's rmse: 1.12212\tvalidation_1's rmse: 1.00341\n",
      "[300]\tvalidation_0's rmse: 1.08787\tvalidation_1's rmse: 0.974248\n",
      "[400]\tvalidation_0's rmse: 1.05857\tvalidation_1's rmse: 0.949382\n",
      "[500]\tvalidation_0's rmse: 1.03351\tvalidation_1's rmse: 0.928251\n",
      "[600]\tvalidation_0's rmse: 1.01198\tvalidation_1's rmse: 0.910252\n",
      "[700]\tvalidation_0's rmse: 0.993552\tvalidation_1's rmse: 0.894773\n",
      "[800]\tvalidation_0's rmse: 0.977813\tvalidation_1's rmse: 0.881528\n",
      "[900]\tvalidation_0's rmse: 0.96428\tvalidation_1's rmse: 0.870172\n",
      "[1000]\tvalidation_0's rmse: 0.952704\tvalidation_1's rmse: 0.860496\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalidation_0's rmse: 0.952704\tvalidation_1's rmse: 0.860496\n",
      "--- params ---\n",
      "{'scale_pos_weight': 13.495265569035297, 'reg_lambda': 4.848940538260304, 'min_child_weight': 182, 'colsample_bytree': 0.6724079878251978, 'subsample': 0.8297429686681106, 'max_depth': 7, 'max_bin': 204}\n",
      "===== Fold 0 =====\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[100]\tvalidation_0's rmse: 1.17779\tvalidation_1's rmse: 1.06044\n",
      "[200]\tvalidation_0's rmse: 1.13261\tvalidation_1's rmse: 1.02627\n",
      "[300]\tvalidation_0's rmse: 1.09352\tvalidation_1's rmse: 0.996782\n",
      "[400]\tvalidation_0's rmse: 1.05949\tvalidation_1's rmse: 0.971914\n",
      "[500]\tvalidation_0's rmse: 1.03032\tvalidation_1's rmse: 0.950468\n",
      "[600]\tvalidation_0's rmse: 1.00497\tvalidation_1's rmse: 0.931666\n",
      "[700]\tvalidation_0's rmse: 0.982928\tvalidation_1's rmse: 0.915641\n",
      "[800]\tvalidation_0's rmse: 0.963917\tvalidation_1's rmse: 0.902414\n",
      "[900]\tvalidation_0's rmse: 0.947604\tvalidation_1's rmse: 0.891392\n",
      "[1000]\tvalidation_0's rmse: 0.933374\tvalidation_1's rmse: 0.88213\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalidation_0's rmse: 0.933374\tvalidation_1's rmse: 0.88213\n",
      "===== Fold 1 =====\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[100]\tvalidation_0's rmse: 1.119\tvalidation_1's rmse: 1.14985\n",
      "[200]\tvalidation_0's rmse: 1.07788\tvalidation_1's rmse: 1.11708\n",
      "[300]\tvalidation_0's rmse: 1.04282\tvalidation_1's rmse: 1.08903\n",
      "[400]\tvalidation_0's rmse: 1.01276\tvalidation_1's rmse: 1.06503\n",
      "[500]\tvalidation_0's rmse: 0.986911\tvalidation_1's rmse: 1.04451\n",
      "[600]\tvalidation_0's rmse: 0.964755\tvalidation_1's rmse: 1.02737\n",
      "[700]\tvalidation_0's rmse: 0.94568\tvalidation_1's rmse: 1.01237\n",
      "[800]\tvalidation_0's rmse: 0.929254\tvalidation_1's rmse: 0.999199\n",
      "[900]\tvalidation_0's rmse: 0.915198\tvalidation_1's rmse: 0.988018\n",
      "[1000]\tvalidation_0's rmse: 0.903112\tvalidation_1's rmse: 0.978592\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalidation_0's rmse: 0.903112\tvalidation_1's rmse: 0.978592\n",
      "===== Fold 2 =====\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[100]\tvalidation_0's rmse: 1.12745\tvalidation_1's rmse: 1.35842\n",
      "[200]\tvalidation_0's rmse: 1.08788\tvalidation_1's rmse: 1.31597\n",
      "[300]\tvalidation_0's rmse: 1.05415\tvalidation_1's rmse: 1.27986\n",
      "[400]\tvalidation_0's rmse: 1.02529\tvalidation_1's rmse: 1.24869\n",
      "[500]\tvalidation_0's rmse: 1.00051\tvalidation_1's rmse: 1.22146\n",
      "[600]\tvalidation_0's rmse: 0.979591\tvalidation_1's rmse: 1.19847\n",
      "[700]\tvalidation_0's rmse: 0.961576\tvalidation_1's rmse: 1.17871\n",
      "[800]\tvalidation_0's rmse: 0.946062\tvalidation_1's rmse: 1.16171\n",
      "[900]\tvalidation_0's rmse: 0.932808\tvalidation_1's rmse: 1.14709\n",
      "[1000]\tvalidation_0's rmse: 0.921401\tvalidation_1's rmse: 1.13418\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalidation_0's rmse: 0.921401\tvalidation_1's rmse: 1.13418\n",
      "===== Fold 3 =====\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[100]\tvalidation_0's rmse: 1.18733\tvalidation_1's rmse: 1.04888\n",
      "[200]\tvalidation_0's rmse: 1.14569\tvalidation_1's rmse: 1.0099\n",
      "[300]\tvalidation_0's rmse: 1.11017\tvalidation_1's rmse: 0.977217\n",
      "[400]\tvalidation_0's rmse: 1.07978\tvalidation_1's rmse: 0.949877\n",
      "[500]\tvalidation_0's rmse: 1.05372\tvalidation_1's rmse: 0.926852\n",
      "[600]\tvalidation_0's rmse: 1.03145\tvalidation_1's rmse: 0.907925\n",
      "[700]\tvalidation_0's rmse: 1.01236\tvalidation_1's rmse: 0.892062\n",
      "[800]\tvalidation_0's rmse: 0.995962\tvalidation_1's rmse: 0.879014\n",
      "[900]\tvalidation_0's rmse: 0.981945\tvalidation_1's rmse: 0.86827\n",
      "[1000]\tvalidation_0's rmse: 0.969911\tvalidation_1's rmse: 0.859451\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalidation_0's rmse: 0.969911\tvalidation_1's rmse: 0.859451\n",
      "===== Fold 4 =====\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[100]\tvalidation_0's rmse: 1.16226\tvalidation_1's rmse: 1.03763\n",
      "[200]\tvalidation_0's rmse: 1.12212\tvalidation_1's rmse: 1.00349\n",
      "[300]\tvalidation_0's rmse: 1.08787\tvalidation_1's rmse: 0.9744\n",
      "[400]\tvalidation_0's rmse: 1.05859\tvalidation_1's rmse: 0.949686\n",
      "[500]\tvalidation_0's rmse: 1.03354\tvalidation_1's rmse: 0.928583\n",
      "[600]\tvalidation_0's rmse: 1.01202\tvalidation_1's rmse: 0.91068\n",
      "[700]\tvalidation_0's rmse: 0.993587\tvalidation_1's rmse: 0.895237\n",
      "[800]\tvalidation_0's rmse: 0.977863\tvalidation_1's rmse: 0.882031\n",
      "[900]\tvalidation_0's rmse: 0.964378\tvalidation_1's rmse: 0.870821\n",
      "[1000]\tvalidation_0's rmse: 0.952798\tvalidation_1's rmse: 0.861194\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalidation_0's rmse: 0.952798\tvalidation_1's rmse: 0.861194\n",
      "--- params ---\n",
      "{'scale_pos_weight': 180.76989252716416, 'reg_lambda': 2.312002433305565, 'min_child_weight': 178, 'colsample_bytree': 0.7093874556039304, 'subsample': 0.6765656880604547, 'max_depth': 4, 'max_bin': 122}\n",
      "===== Fold 0 =====\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[100]\tvalidation_0's rmse: 1.17772\tvalidation_1's rmse: 1.06043\n",
      "[200]\tvalidation_0's rmse: 1.13256\tvalidation_1's rmse: 1.02627\n",
      "[300]\tvalidation_0's rmse: 1.09342\tvalidation_1's rmse: 0.996772\n",
      "[400]\tvalidation_0's rmse: 1.05943\tvalidation_1's rmse: 0.971863\n",
      "[500]\tvalidation_0's rmse: 1.03026\tvalidation_1's rmse: 0.950405\n",
      "[600]\tvalidation_0's rmse: 1.00491\tvalidation_1's rmse: 0.931593\n",
      "[700]\tvalidation_0's rmse: 0.982914\tvalidation_1's rmse: 0.915523\n",
      "[800]\tvalidation_0's rmse: 0.963911\tvalidation_1's rmse: 0.902269\n",
      "[900]\tvalidation_0's rmse: 0.947531\tvalidation_1's rmse: 0.891096\n",
      "[1000]\tvalidation_0's rmse: 0.933288\tvalidation_1's rmse: 0.881835\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalidation_0's rmse: 0.933288\tvalidation_1's rmse: 0.881835\n",
      "===== Fold 1 =====\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[100]\tvalidation_0's rmse: 1.11906\tvalidation_1's rmse: 1.15011\n",
      "[200]\tvalidation_0's rmse: 1.07805\tvalidation_1's rmse: 1.11768\n",
      "[300]\tvalidation_0's rmse: 1.04305\tvalidation_1's rmse: 1.08963\n",
      "[400]\tvalidation_0's rmse: 1.01301\tvalidation_1's rmse: 1.06565\n",
      "[500]\tvalidation_0's rmse: 0.987271\tvalidation_1's rmse: 1.04512\n",
      "[600]\tvalidation_0's rmse: 0.965161\tvalidation_1's rmse: 1.02783\n",
      "[700]\tvalidation_0's rmse: 0.946093\tvalidation_1's rmse: 1.01274\n",
      "[800]\tvalidation_0's rmse: 0.929583\tvalidation_1's rmse: 0.999632\n",
      "[900]\tvalidation_0's rmse: 0.915512\tvalidation_1's rmse: 0.988487\n",
      "[1000]\tvalidation_0's rmse: 0.903417\tvalidation_1's rmse: 0.979101\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalidation_0's rmse: 0.903417\tvalidation_1's rmse: 0.979101\n",
      "===== Fold 2 =====\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[100]\tvalidation_0's rmse: 1.12754\tvalidation_1's rmse: 1.35842\n",
      "[200]\tvalidation_0's rmse: 1.08808\tvalidation_1's rmse: 1.31636\n",
      "[300]\tvalidation_0's rmse: 1.0544\tvalidation_1's rmse: 1.28036\n",
      "[400]\tvalidation_0's rmse: 1.02565\tvalidation_1's rmse: 1.24906\n",
      "[500]\tvalidation_0's rmse: 1.00099\tvalidation_1's rmse: 1.22188\n",
      "[600]\tvalidation_0's rmse: 0.980063\tvalidation_1's rmse: 1.19913\n",
      "[700]\tvalidation_0's rmse: 0.96214\tvalidation_1's rmse: 1.17951\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[800]\tvalidation_0's rmse: 0.946666\tvalidation_1's rmse: 1.16255\n",
      "[900]\tvalidation_0's rmse: 0.933427\tvalidation_1's rmse: 1.14793\n",
      "[1000]\tvalidation_0's rmse: 0.92204\tvalidation_1's rmse: 1.13518\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalidation_0's rmse: 0.92204\tvalidation_1's rmse: 1.13518\n",
      "===== Fold 3 =====\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[100]\tvalidation_0's rmse: 1.18729\tvalidation_1's rmse: 1.0483\n",
      "[200]\tvalidation_0's rmse: 1.14564\tvalidation_1's rmse: 1.00916\n",
      "[300]\tvalidation_0's rmse: 1.1101\tvalidation_1's rmse: 0.976454\n",
      "[400]\tvalidation_0's rmse: 1.0797\tvalidation_1's rmse: 0.949163\n",
      "[500]\tvalidation_0's rmse: 1.05359\tvalidation_1's rmse: 0.926177\n",
      "[600]\tvalidation_0's rmse: 1.03129\tvalidation_1's rmse: 0.907373\n",
      "[700]\tvalidation_0's rmse: 1.01218\tvalidation_1's rmse: 0.891486\n",
      "[800]\tvalidation_0's rmse: 0.995752\tvalidation_1's rmse: 0.878468\n",
      "[900]\tvalidation_0's rmse: 0.981715\tvalidation_1's rmse: 0.86773\n",
      "[1000]\tvalidation_0's rmse: 0.96967\tvalidation_1's rmse: 0.858918\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalidation_0's rmse: 0.96967\tvalidation_1's rmse: 0.858918\n",
      "===== Fold 4 =====\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[100]\tvalidation_0's rmse: 1.16222\tvalidation_1's rmse: 1.0377\n",
      "[200]\tvalidation_0's rmse: 1.12208\tvalidation_1's rmse: 1.00355\n",
      "[300]\tvalidation_0's rmse: 1.08782\tvalidation_1's rmse: 0.974478\n",
      "[400]\tvalidation_0's rmse: 1.05856\tvalidation_1's rmse: 0.949751\n",
      "[500]\tvalidation_0's rmse: 1.03349\tvalidation_1's rmse: 0.928746\n",
      "[600]\tvalidation_0's rmse: 1.01197\tvalidation_1's rmse: 0.910752\n",
      "[700]\tvalidation_0's rmse: 0.993515\tvalidation_1's rmse: 0.895293\n",
      "[800]\tvalidation_0's rmse: 0.9778\tvalidation_1's rmse: 0.882086\n",
      "[900]\tvalidation_0's rmse: 0.964302\tvalidation_1's rmse: 0.870852\n",
      "[1000]\tvalidation_0's rmse: 0.952733\tvalidation_1's rmse: 0.861144\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalidation_0's rmse: 0.952733\tvalidation_1's rmse: 0.861144\n",
      "--- params ---\n",
      "{'scale_pos_weight': 357.7133799221014, 'reg_lambda': 3.119218082628714, 'min_child_weight': 69, 'colsample_bytree': 0.6447505055216364, 'subsample': 0.6189561085708415, 'max_depth': 4, 'max_bin': 101}\n",
      "===== Fold 0 =====\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[100]\tvalidation_0's rmse: 1.17776\tvalidation_1's rmse: 1.06013\n",
      "[200]\tvalidation_0's rmse: 1.1326\tvalidation_1's rmse: 1.02609\n",
      "[300]\tvalidation_0's rmse: 1.09342\tvalidation_1's rmse: 0.996467\n",
      "[400]\tvalidation_0's rmse: 1.05939\tvalidation_1's rmse: 0.971584\n",
      "[500]\tvalidation_0's rmse: 1.03022\tvalidation_1's rmse: 0.950139\n",
      "[600]\tvalidation_0's rmse: 1.00487\tvalidation_1's rmse: 0.931406\n",
      "[700]\tvalidation_0's rmse: 0.982802\tvalidation_1's rmse: 0.915492\n",
      "[800]\tvalidation_0's rmse: 0.963815\tvalidation_1's rmse: 0.902398\n",
      "[900]\tvalidation_0's rmse: 0.947442\tvalidation_1's rmse: 0.891319\n",
      "[1000]\tvalidation_0's rmse: 0.933247\tvalidation_1's rmse: 0.88198\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalidation_0's rmse: 0.933247\tvalidation_1's rmse: 0.88198\n",
      "===== Fold 1 =====\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[100]\tvalidation_0's rmse: 1.11906\tvalidation_1's rmse: 1.15026\n",
      "[200]\tvalidation_0's rmse: 1.07807\tvalidation_1's rmse: 1.11788\n",
      "[300]\tvalidation_0's rmse: 1.04306\tvalidation_1's rmse: 1.08981\n",
      "[400]\tvalidation_0's rmse: 1.01305\tvalidation_1's rmse: 1.06593\n",
      "[500]\tvalidation_0's rmse: 0.987259\tvalidation_1's rmse: 1.04536\n",
      "[600]\tvalidation_0's rmse: 0.965137\tvalidation_1's rmse: 1.02806\n",
      "[700]\tvalidation_0's rmse: 0.946034\tvalidation_1's rmse: 1.01287\n",
      "[800]\tvalidation_0's rmse: 0.92954\tvalidation_1's rmse: 0.999712\n",
      "[900]\tvalidation_0's rmse: 0.915476\tvalidation_1's rmse: 0.988534\n",
      "[1000]\tvalidation_0's rmse: 0.903317\tvalidation_1's rmse: 0.979089\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalidation_0's rmse: 0.903317\tvalidation_1's rmse: 0.979089\n",
      "===== Fold 2 =====\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[100]\tvalidation_0's rmse: 1.12753\tvalidation_1's rmse: 1.35842\n",
      "[200]\tvalidation_0's rmse: 1.08809\tvalidation_1's rmse: 1.3164\n",
      "[300]\tvalidation_0's rmse: 1.05441\tvalidation_1's rmse: 1.28037\n",
      "[400]\tvalidation_0's rmse: 1.02566\tvalidation_1's rmse: 1.24918\n",
      "[500]\tvalidation_0's rmse: 1.00095\tvalidation_1's rmse: 1.22204\n",
      "[600]\tvalidation_0's rmse: 0.980029\tvalidation_1's rmse: 1.19912\n",
      "[700]\tvalidation_0's rmse: 0.962073\tvalidation_1's rmse: 1.17943\n",
      "[800]\tvalidation_0's rmse: 0.946578\tvalidation_1's rmse: 1.1624\n",
      "[900]\tvalidation_0's rmse: 0.933357\tvalidation_1's rmse: 1.14781\n",
      "[1000]\tvalidation_0's rmse: 0.922019\tvalidation_1's rmse: 1.1351\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalidation_0's rmse: 0.922019\tvalidation_1's rmse: 1.1351\n",
      "===== Fold 3 =====\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[100]\tvalidation_0's rmse: 1.18734\tvalidation_1's rmse: 1.0489\n",
      "[200]\tvalidation_0's rmse: 1.14573\tvalidation_1's rmse: 1.00995\n",
      "[300]\tvalidation_0's rmse: 1.11023\tvalidation_1's rmse: 0.977256\n",
      "[600]\tvalidation_0's rmse: 1.03154\tvalidation_1's rmse: 0.908105\n",
      "[700]\tvalidation_0's rmse: 1.01246\tvalidation_1's rmse: 0.892179\n",
      "[800]\tvalidation_0's rmse: 0.996096\tvalidation_1's rmse: 0.879214\n",
      "[900]\tvalidation_0's rmse: 0.982071\tvalidation_1's rmse: 0.868473\n",
      "[1000]\tvalidation_0's rmse: 0.970031\tvalidation_1's rmse: 0.859636\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalidation_0's rmse: 0.970031\tvalidation_1's rmse: 0.859636\n",
      "===== Fold 4 =====\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[100]\tvalidation_0's rmse: 1.16229\tvalidation_1's rmse: 1.03747\n",
      "[200]\tvalidation_0's rmse: 1.12218\tvalidation_1's rmse: 1.00326\n",
      "[300]\tvalidation_0's rmse: 1.08794\tvalidation_1's rmse: 0.974191\n",
      "[400]\tvalidation_0's rmse: 1.05867\tvalidation_1's rmse: 0.949449\n",
      "[500]\tvalidation_0's rmse: 1.03361\tvalidation_1's rmse: 0.928474\n",
      "[600]\tvalidation_0's rmse: 1.01204\tvalidation_1's rmse: 0.910449\n",
      "[700]\tvalidation_0's rmse: 0.993605\tvalidation_1's rmse: 0.894938\n",
      "[800]\tvalidation_0's rmse: 0.977878\tvalidation_1's rmse: 0.881802\n",
      "[900]\tvalidation_0's rmse: 0.964391\tvalidation_1's rmse: 0.870578\n",
      "[1000]\tvalidation_0's rmse: 0.952827\tvalidation_1's rmse: 0.86089\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalidation_0's rmse: 0.952827\tvalidation_1's rmse: 0.86089\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Best score=1.0089'"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_gp = gp_minimize(objective, lgb_space, n_calls=10, random_state=seed, n_random_starts=10)\n",
    "\n",
    "\"Best score=%.4f\" % res_gp.fun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fe92ae41a20>"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from skopt.plots import plot_convergence\n",
    "plot_convergence(res_gp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4,\n",
       " 130,\n",
       " 195.02460619317566,\n",
       " 0.7686997271683054,\n",
       " 0.6346565260900119,\n",
       " 3.3769098780033415,\n",
       " 190]"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_gp.x"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
