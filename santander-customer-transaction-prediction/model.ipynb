{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['train.csv.zip',\n",
       " 'test.csv',\n",
       " 'sample_submission.csv.zip',\n",
       " 'test.csv.zip',\n",
       " 'sample_submission.csv',\n",
       " 'train.csv']"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "import os\n",
    "import logging\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm_notebook, tqdm\n",
    "from numba import jit\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "IS_LOCAL = True\n",
    "if(IS_LOCAL):\n",
    "    PATH = Path('/mnt/disks/data/santander-customer-transaction/')\n",
    "else:\n",
    "    PATH = Path('../input/')\n",
    "    \n",
    "os.listdir(str(PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 14 s, sys: 612 ms, total: 14.6 s\n",
      "Wall time: 14.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_df = pd.read_csv(str(PATH / 'train.csv'))\n",
    "test_df = pd.read_csv(str(PATH / 'test.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((200000, 202), (200000, 201))"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape, test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_col = 'target'\n",
    "predictor_cols = [c for c in train_df.columns if c not in ['ID_code', 'target']]\n",
    "# predictor_cols = [x for x in train_df.columns if x.startswith('var')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reverse features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "for var in predictor_cols:\n",
    "    if np.corrcoef(train_df['target'], train_df[var])[1][0] < 0:\n",
    "        train_df[var] = train_df[var] * -1\n",
    "        test_df[var] = test_df[var] * -1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count all values\n",
    "var_stats = {}\n",
    "hist_df = pd.DataFrame()\n",
    "for var in predictor_cols:\n",
    "    var_stats = train_df[var].append(test_df[var]).value_counts()\n",
    "    hist_df[var] = pd.Series(test_df[var]).map(var_stats)\n",
    "    hist_df[var] = hist_df[var] > 1\n",
    "\n",
    "# remove fake test rows\n",
    "ind = hist_df.sum(axis=1) != 200    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recount values without fake rows\n",
    "var_stats = {}\n",
    "for var in predictor_cols:\n",
    "    var_stats[var] = train_df[var].append(test_df[ind][var]).value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logit(p):\n",
    "    return np.log(p) - np.log(1 - p)\n",
    "\n",
    "def var_to_feat(vr, var_stats, feat_id):\n",
    "    new_df = pd.DataFrame()\n",
    "    new_df['var'] = vr.values\n",
    "    new_df['hist'] = pd.Series(vr).map(var_stats)\n",
    "    new_df['feature_id'] = feat_id\n",
    "    new_df['var_rank'] = new_df['var'].rank() / 200000\n",
    "    return new_df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET = np.array( list(train_df['target'].values) * 200 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRAIN = []\n",
    "var_mean = {}\n",
    "var_var  = {}\n",
    "for var in predictor_cols:\n",
    "    tmp = var_to_feat(train_df[var], var_stats[var], int(var[4:]) )\n",
    "    var_mean[var] = np.mean(tmp[:,0]) \n",
    "    var_var[var]  = np.var(tmp[:,0])\n",
    "    tmp[:,0] = (tmp[:,0]-var_mean[var])/var_var[var]\n",
    "    TRAIN.append( tmp )\n",
    "TRAIN = np.vstack( TRAIN )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# List of fake samples and public / private LB split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:06<00:00, 32.94it/s]\n"
     ]
    }
   ],
   "source": [
    "df_test = test_df[predictor_cols].values\n",
    "unique_samples = []\n",
    "unique_count = np.zeros_like(df_test)\n",
    "for feature in tqdm(range(df_test.shape[1])):\n",
    "    _, index, count = np.unique(df_test[:, feature], return_counts=True, return_index=True)\n",
    "    unique_count[index[count == 1],  i] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000\n",
      "100000\n"
     ]
    }
   ],
   "source": [
    "# Samples which have unique values are real the others are fake\n",
    "real_samples_indexes = np.argwhere(np.sum(unique_count, axis=1) > 0)[:, 0]\n",
    "synthetic_samples_indexes = np.argwhere(np.sum(unique_count, axis=1) == 0)[:, 0]\n",
    "\n",
    "print(len(real_samples_indexes))\n",
    "print(len(synthetic_samples_indexes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_test_df = df_test[real_samples_indexes].copy()\n",
    "generator_for_each_synthetic_sample = []\n",
    "\n",
    "for cur_sample_index in tqdm(synthetic_samples_indexes[:200]):\n",
    "    cur_synthetic_sample = df_test[cur_sample_index]\n",
    "    potential_generators = real_test_df == cur_synthetic_sample\n",
    "    \n",
    "    # A verified generator for a synthetic sample is achieved\n",
    "    # only if the value of a feature appears only once in the\n",
    "    # entire real samples set\n",
    "    features_mask = np.sum(potential_generators, axis=0) == 1\n",
    "    verified_generators_mask = np.any(potential_generators[:, features_mask], axis=1)\n",
    "    verified_generators_for_sample = real_samples_indexes[np.argwhere(verified_generators_mask)[:, 0]]\n",
    "    generator_for_each_synthetic_sample.append(set(verified_generators_for_sample))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  3,   1,   1,   4,   4,   1,   5,   1,   4,   2,   1,   2,  16,\n",
       "         2,   3,  10,   5,   1,   1,   1,   2,   1,   2,   9,   2,  17,\n",
       "         1,   3,   2,   2,   2,   2,   2,   2,   7,   3,   1,   5,   2,\n",
       "         1,   2,   1,   4,  14,   2,   1,   1,   1,   1,   1,   1,   2,\n",
       "         1,   6,   2,   2,   1,   5,   1,   4,   2,   1,   2,   2,   4,\n",
       "         1,   5,   3, 454,   2,   1,  16,   1,   1,   2,   1,   1,   1,\n",
       "         2,   2,   2,   4,   2,   1,   1,   1,   2,   1,   1,   1,   1,\n",
       "        19,   1,  13,   3,   5,   1,   2,   8,   3,   1,   1,   1,  19,\n",
       "         3,   2,   3,   1,  14,   1,   1,   3,   4,   2,   2,   2,   1,\n",
       "         1,   5,   4,   1,   1,   1,   1,   3,  10,   3,   1,   1,   2,\n",
       "         5,  10,   1,  13,   1,   1,   1,   2,   1,   2,   1,   3,   1,\n",
       "         1,   9,   1,   4,   1,  22,   3,   1,   2,   1,   5,   1,   1,\n",
       "         2,   4,   1,   1,   1,  21,   3,   1,   1,   1,   7,   1,   1,\n",
       "         4,   3,   2,   3,   1,   1,   2,   1,   2,   1,   1,   2,   1,\n",
       "         1,   2,   1,   5,   3,   1,   1,   2,   2,   2,   2,   1,   1,\n",
       "         1,   1,   1,   2,   1])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# After collecting the \"verified generators\" for each fake sample, \n",
    "# finding the Public/Private LB split is no more than a few set operations.\n",
    "public_LB = generator_for_each_synthetic_sample[0]\n",
    "for x in tqdm(generator_for_each_synthetic_sample):\n",
    "    if public_LB.intersection(x):\n",
    "        public_LB = public_LB.union(x)\n",
    "\n",
    "private_LB = generator_for_each_synthetic_sample[1]\n",
    "for x in tqdm(generator_for_each_synthetic_sample):\n",
    "    if private_LB.intersection(x):\n",
    "        private_LB = private_LB.union(x)\n",
    "        \n",
    "print(len(public_LB))\n",
    "print(len(private_LB))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unique count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df = pd.concat([train_df, test_df], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:58<00:00,  2.02it/s]\n"
     ]
    }
   ],
   "source": [
    "for f in tqdm(predictor_cols):\n",
    "    unique_count_dict = full_df[f].value_counts().to_dict()\n",
    "    train_df['un_real_' + f] = train_df[f].apply(lambda x: x if unique_count_dict[x] == 1 else np.nan).values\n",
    "    test_df['un_real_' + f] = test_df[f].apply(lambda x: x if unique_count_dict[x] == 1 else np.nan).values\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([train,real_test], axis = 0)\n",
    "for feat in tqdm_notebook(features):\n",
    "    df[feat+'_var'] = df.groupby([feat])[feat].transform('var')\n",
    "for feat in tqdm_notebook(features):\n",
    "    df[feat+'plus_'] = df[feat] + df[feat+'_var']\n",
    "    df[feat+'minus_'] = df[feat] - df[feat+'_var']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert var_68 to datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_datetime = pd.datetime(1900, 1, 1)\n",
    "trf_var_68_s = (train_df['var_68']*10000 - 7000 + epoch_datetime.toordinal()).astype(int)\n",
    "date_s = trf_var_68_s.map(datetime.fromordinal)\n",
    "train_df['date'] = date_s\n",
    "sorted_train_df = train_df.drop('var_68', axis=1).sort_values('date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_train_df.reset_index(inplace=True)\n",
    "sorted_train_df.drop('index', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try to use stacking method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_part_1_df = train_df.sample(train_df.shape[0] // 2, replace=False)\n",
    "train_part_2_df = train_df.iloc[~train_part_1_df.index.values, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((100000, 202), (100000, 202))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_part_1_df.shape, train_part_2_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features Interaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 14.5 s, sys: 12.3 s, total: 26.8 s\n",
      "Wall time: 26.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for df in [test_df, train_df]:\n",
    "    df['sum'] = df[features].sum(axis=1)  \n",
    "    df['min'] = df[features].min(axis=1)\n",
    "    df['max'] = df[features].max(axis=1)\n",
    "    df['mean'] = df[features].mean(axis=1)\n",
    "    df['std'] = df[features].std(axis=1)\n",
    "    df['skew'] = df[features].skew(axis=1)\n",
    "    df['kurt'] = df[features].kurtosis(axis=1)\n",
    "    df['med'] = df[features].median(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df = pd.concat([train_df.drop(['target', 'sum', 'min', 'max', 'mean', 'std', 'skew', 'kurt', 'med'], axis=1),\n",
    "                     test_df.drop(['sum', 'min', 'max', 'mean', 'std', 'skew', 'kurt', 'med'], axis=1)], \n",
    "                    axis=0).copy()\n",
    "full_df.reset_index(inplace=True)\n",
    "full_df.drop(['index'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### features slice windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_cols = ['var_68']\n",
    "train_df.drop(drop_cols, inplace=True, axis=1)\n",
    "test_df.drop(drop_cols, inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor_cols.remove(*drop_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "slice_size = [3, 7]\n",
    "stride = 2\n",
    "\n",
    "for s in slice_size:\n",
    "    total_slice = (len(predictor_cols)-s) // stride + 1\n",
    "    for i in tqdm(range(total_slice)):\n",
    "        new_feature = predictor_cols[(i*stride):((i*stride + s))]\n",
    "        # train\n",
    "        train_df['ws_mean_{}_{}'.format(s, i)] = train_df[new_feature].mean(axis=1)\n",
    "        train_df['ws_std_{}_{}'.format(s, i)] = train_df[new_feature].std(axis=1)\n",
    "        train_df['ws_min_{}_{}'.format(s, i)] = train_df[new_feature].min(axis=1)\n",
    "        train_df['ws_max_{}_{}'.format(s, i)] = train_df[new_feature].max(axis=1)\n",
    "        # test\n",
    "        test_df['ws_mean_{}_{}'.format(s, i)] = test_df[new_feature].mean(axis=1)\n",
    "        test_df['ws_std_{}_{}'.format(s, i)] = test_df[new_feature].std(axis=1)\n",
    "        test_df['ws_min_{}_{}'.format(s, i)] = test_df[new_feature].min(axis=1)\n",
    "        test_df['ws_max_{}_{}'.format(s, i)] = test_df[new_feature].max(axis=1)\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert numeric features to categories features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Binarizer\n",
    "unique_value_df = train_df.drop(['ID_code', 'target', 'sum', 'min', 'max', 'mean', 'std', 'skew', 'kurt', 'med'], \n",
    "                                axis=1).nunique().sort_values()\n",
    "convert_to_categories_cols = unique_value_df[unique_value_df > 100000].index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'convert_to_categories_cols' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'convert_to_categories_cols' is not defined"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder \n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "for c in list(convert_to_categories_cols):\n",
    "    cate_range = np.arange(full_df[c].min(), full_df[c].max(), \n",
    "                          (full_df[c].max() - full_df[c].min()) / 10).tolist() + [full_df[c].max()]\n",
    "    res = pd.cut(full_df[c], cate_range, include_lowest=True,\n",
    "                 labels=list(map(lambda i:str(i), range(1, len(cate_range)))))\n",
    "    \n",
    "    one_hot_encoder = OneHotEncoder(sparse=False).fit(np.array(res).reshape(-1, 1))\n",
    "    one_hot_res = one_hot_encoder.transform(np.array(res).reshape(-1, 1))\n",
    "    \n",
    "    cols = [c + '_' + str(i) for i in range(1, len(cate_range))]\n",
    "    res_df = pd.DataFrame(one_hot_res, columns=cols).drop(cols[-1], axis=1)\n",
    "    full_df = pd.concat([full_df, res_df], axis=1).drop(c, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "remain_cols = [i for i in predictor_cols if i not in convert_to_categories_cols]\n",
    "full_df.drop(remain_cols[2:], axis=1, inplace=True)\n",
    "\n",
    "train_df = train_df.merge(full_df, on='ID_code', how='left')\n",
    "test_df = test_df.merge(full_df, on='ID_code', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor_cols = train_df.columns.drop(['ID_code', 'target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "252"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del full_df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use the data of target 1 to cut data and convert to categoris features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_1_df = train_df.loc[train_df['target'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_predictor_cols = ['var_0', 'var_1', 'var_2', 'var_3', 'var_4', 'var_5', 'var_6',\n",
    "       'var_8', 'var_9', 'var_11', 'var_12', 'var_13', 'var_14', 'var_15',\n",
    "       'var_16', 'var_18', 'var_19', 'var_20', 'var_21', 'var_22',\n",
    "       'var_23', 'var_24', 'var_25', 'var_26', 'var_28', 'var_31',\n",
    "       'var_32', 'var_33', 'var_34', 'var_35', 'var_36', 'var_37',\n",
    "       'var_40', 'var_42', 'var_43', 'var_44', 'var_45', 'var_47',\n",
    "       'var_48', 'var_49', 'var_50', 'var_51', 'var_52', 'var_53',\n",
    "       'var_54', 'var_55', 'var_56', 'var_57', 'var_58', 'var_59',\n",
    "       'var_60', 'var_61', 'var_62', 'var_63', 'var_64', 'var_65',\n",
    "       'var_66', 'var_67', 'var_68', 'var_69', 'var_70', 'var_71',\n",
    "       'var_72', 'var_73', 'var_74', 'var_75', 'var_76', 'var_77',\n",
    "       'var_78', 'var_79', 'var_80', 'var_81', 'var_82', 'var_83',\n",
    "       'var_84', 'var_85', 'var_86', 'var_87', 'var_88', 'var_89',\n",
    "       'var_90', 'var_91', 'var_92', 'var_93', 'var_94', 'var_95',\n",
    "       'var_97', 'var_99', 'var_101', 'var_102', 'var_104', 'var_105',\n",
    "       'var_106', 'var_107', 'var_108', 'var_109', 'var_110', 'var_111',\n",
    "       'var_112', 'var_113', 'var_114', 'var_115', 'var_116', 'var_118',\n",
    "       'var_119', 'var_120', 'var_121', 'var_122', 'var_123', 'var_125',\n",
    "       'var_127', 'var_128', 'var_129', 'var_130', 'var_131', 'var_132',\n",
    "       'var_133', 'var_134', 'var_135', 'var_137', 'var_138', 'var_139',\n",
    "       'var_140', 'var_141', 'var_142', 'var_143', 'var_144', 'var_145',\n",
    "       'var_146', 'var_147', 'var_148', 'var_149', 'var_150', 'var_151',\n",
    "       'var_152', 'var_153', 'var_154', 'var_155', 'var_156', 'var_157',\n",
    "       'var_159', 'var_162', 'var_163', 'var_164', 'var_165', 'var_166',\n",
    "       'var_167', 'var_168', 'var_169', 'var_170', 'var_171', 'var_172',\n",
    "       'var_173', 'var_174', 'var_175', 'var_176', 'var_177', 'var_178',\n",
    "       'var_179', 'var_180', 'var_181', 'var_182', 'var_184', 'var_186',\n",
    "       'var_187', 'var_188', 'var_189', 'var_190', 'var_191', 'var_192',\n",
    "       'var_193', 'var_194', 'var_195', 'var_196', 'var_197', 'var_198',\n",
    "       'var_199']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_df = pd.DataFrame()\n",
    "for f in convert_predictor_cols:\n",
    "    cate_range = target_1_df[f].quantile([0.25, 0.5, 0.75]).values.tolist()\n",
    "    cate_range.insert(0, train_df[f].min() - 0.001)\n",
    "    cate_range.append(train_df[f].max() + 0.001)\n",
    "    res = pd.cut(train_df[f], cate_range, include_lowest=True,\n",
    "                 labels=list(map(lambda i:str(i), range(1, len(cate_range)))))\n",
    "    res = res.astype(int)\n",
    "    #one_hot_encoder = OneHotEncoder(sparse=False).fit(np.array(res).reshape(-1, 1))\n",
    "    #one_hot_res = one_hot_encoder.transform(np.array(res).reshape(-1, 1))\n",
    "    \n",
    "    #cols = [c + '_' + str(i) for i in range(1, len(cate_range))]\n",
    "    cols = [f + '_' + 'bin']\n",
    "    #res_df = pd.DataFrame(res, columns=cols)\n",
    "    convert_df = pd.concat([convert_df, res], axis=1)\n",
    "\n",
    "convert_df.columns = [f + '_' + 'bin' for f in convert_predictor_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({False: 200000})"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(res.isna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.concat([train_df, convert_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_test_df = pd.DataFrame()\n",
    "for f in convert_predictor_cols:\n",
    "    cate_range = target_1_df[f].quantile([0.25, 0.5, 0.75]).values.tolist()\n",
    "    cate_range.insert(0, test_df[f].min() - 0.001)\n",
    "    cate_range.append(test_df[f].max() + 0.001)\n",
    "    res = pd.cut(test_df[f], cate_range, include_lowest=True,\n",
    "                 labels=list(map(lambda i:str(i), range(1, len(cate_range)))))\n",
    "    res = res.astype(int)\n",
    "    #one_hot_encoder = OneHotEncoder(sparse=False).fit(np.array(res).reshape(-1, 1))\n",
    "    #one_hot_res = one_hot_encoder.transform(np.array(res).reshape(-1, 1))\n",
    "    \n",
    "    #cols = [c + '_' + str(i) for i in range(1, len(cate_range))]\n",
    "    cols = [f + '_' + 'bin']\n",
    "    #res_df = pd.DataFrame(res, columns=cols)\n",
    "    convert_test_df = pd.concat([convert_test_df, res], axis=1)\n",
    "\n",
    "convert_test_df.columns = [f + '_' + 'bin' for f in convert_predictor_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.concat([test_df, convert_test_df], axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train size:  150000\n",
      "valid size:  50000\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "split_probability = 0.25\n",
    "seed = 8787\n",
    "train_data, valid_data = train_test_split(train_df,\n",
    "                                          test_size=split_probability, \n",
    "                                          stratify=train_df['target'],\n",
    "                                          shuffle=True,\n",
    "                                          random_state=seed)\n",
    "\n",
    "print(\"train size: \", train_data.shape[0])\n",
    "print(\"valid size: \", valid_data.shape[0])\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "import itertools\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "import catboost as cb\n",
    "from xgboost import plot_importance\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "from skopt.space import Real, Integer\n",
    "from skopt.utils import use_named_args\n",
    "from skopt import gp_minimize\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_of_iter = 1000000\n",
    "num_early_stopping = 4000\n",
    "num_verbose_eval = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "sk_params = {\n",
    "    'learning_rate': 0.01,\n",
    "    'n_estimators': num_of_iter,                                   \n",
    "    'objective': 'binary:logistic', \n",
    "    'n_jobs': multiprocessing.cpu_count(),\n",
    "    'tree_method': \"gpu_hist\",  # auto, hist, gpu_hist\n",
    "    'n_gpus': -1,\n",
    "    'eval_metric': ['auc'], # 'logloss'\n",
    "    'random_state':  seed,\n",
    "    'verbosity': 2,\n",
    "    #'gamma': 0, # Minimum loss reduction required to make a further partition on a leaf node of the tree, alias min_split_loss. It acts as a regularization parameter. Either 0, 1 or 5.\n",
    "    'max_depth': 5, # 0 means no limit (useful only for depth wise grow policy).\n",
    "    'min_child_weight': 10.0, # Minimum sum of instance weight (hessian) needed in a child.\n",
    "    'subsample': 0.335, # Subsample ratio of the training instances.\n",
    "    'colsample_bytree': 0.04, # subsample ratio of columns when constructing each tree.\n",
    "    #'colsample_bylevel': 1, # subsample ratio of columns for each level.\n",
    "    'reg_lambda': 3, # L2 regularization. Increasing this value will make model more conservative.\n",
    "    #'reg_alpha': 3, # L1 regularization. Increasing this value will make model more conservative.\n",
    "    #'scale_pos_weight': 1, # Control the balance of positive and negative weights, useful for unbalanced classes.\n",
    "    #'grow_policy': \"lossguide\", # split at nodes with highest loss change.\n",
    "    'max_leaves': 13, # Maximum number of nodes to be added. (for lossguide grow policy).\n",
    "    'max_bin': 100, # Increasing this number improves the optimality of splits at the cost of higher computation time.\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-auc:0.563491\tvalidation_1-auc:0.557731\n",
      "Multiple eval metrics have been passed: 'validation_1-auc' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-auc hasn't improved in 4000 rounds.\n",
      "[5000]\tvalidation_0-auc:0.925126\tvalidation_1-auc:0.896326\n",
      "[10000]\tvalidation_0-auc:0.941072\tvalidation_1-auc:0.900325\n",
      "[15000]\tvalidation_0-auc:0.952876\tvalidation_1-auc:0.900694\n",
      "Stopping. Best iteration:\n",
      "[13356]\tvalidation_0-auc:0.949146\tvalidation_1-auc:0.900843\n",
      "\n",
      "CPU times: user 1h 41min 10s, sys: 4min 38s, total: 1h 45min 49s\n",
      "Wall time: 20min 50s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "xgb_clf_draft = xgb.XGBClassifier(**sk_params)\n",
    "eval_set = [(train_data[predictor_cols], train_data[target_col]), \n",
    "            (valid_data[predictor_cols], valid_data[target_col])]\n",
    "\n",
    "xgb_clf_draft.fit(X=train_data[predictor_cols],\n",
    "                  y=train_data[target_col], \n",
    "                  eval_set=eval_set,             \n",
    "                  early_stopping_rounds=num_early_stopping, \n",
    "                  verbose=num_verbose_eval)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_folds = 11\n",
    "folds = StratifiedKFold(n_splits=num_folds, shuffle=False, random_state=2319)\n",
    "oof = np.zeros(train_part_1_df.shape[0])\n",
    "oof_2 = np.zeros(train_part_2_df.shape[0])\n",
    "y_predictions = np.zeros(test_df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor_cols = features = [c for c in train_part_1_df.columns if c not in ['ID_code', 'target', 'date']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Fold 0 =====\n",
      "[0]\tvalidation_0-auc:0.524262\tvalidation_1-auc:0.528282\n",
      "Multiple eval metrics have been passed: 'validation_1-auc' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-auc hasn't improved in 4000 rounds.\n",
      "[5000]\tvalidation_0-auc:0.93808\tvalidation_1-auc:0.896612\n",
      "[10000]\tvalidation_0-auc:0.95696\tvalidation_1-auc:0.898474\n",
      "Stopping. Best iteration:\n",
      "[7702]\tvalidation_0-auc:0.948948\tvalidation_1-auc:0.898711\n",
      "\n",
      "===== Fold 1 =====\n",
      "[0]\tvalidation_0-auc:0.52261\tvalidation_1-auc:0.529029\n",
      "Multiple eval metrics have been passed: 'validation_1-auc' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-auc hasn't improved in 4000 rounds.\n",
      "[5000]\tvalidation_0-auc:0.937875\tvalidation_1-auc:0.897868\n",
      "[10000]\tvalidation_0-auc:0.957005\tvalidation_1-auc:0.898187\n",
      "Stopping. Best iteration:\n",
      "[7992]\tvalidation_0-auc:0.950111\tvalidation_1-auc:0.898544\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for fold_, (train_idx, val_idx) in enumerate(folds.split(train_part_1_df[predictor_cols].values,\n",
    "                                                         train_part_1_df[target_col].values)):\n",
    "    print(\"===== Fold {} =====\".format(fold_))\n",
    "    \n",
    "    train_X, train_y = train_part_1_df.iloc[train_idx][predictor_cols], train_part_1_df.iloc[train_idx][target_col] \n",
    "    valid_X, valid_y = train_part_1_df.iloc[val_idx][predictor_cols], train_part_1_df.iloc[val_idx][target_col]\n",
    "    eval_set = [(train_X, train_y), (valid_X, valid_y)]\n",
    "    cv_model = xgb.XGBClassifier(**sk_params)\n",
    "    cv_model.fit(X=train_X,\n",
    "                 y=train_y, \n",
    "                 eval_set=eval_set,             \n",
    "                 early_stopping_rounds=num_early_stopping, \n",
    "                 verbose=num_verbose_eval) \n",
    "    \n",
    "    oof[val_idx] = cv_model.predict_proba(train_part_1_df.iloc[val_idx][predictor_cols], \n",
    "                                          ntree_limit=cv_model.best_iteration)[:, 1]\n",
    "    oof_2[val_idx] = cv_model.predict_proba(train_part_1_df.iloc[val_idx][predictor_cols], \n",
    "                                          ntree_limit=cv_model.best_iteration)[:, 1]\n",
    "    y_predictions +=  cv_model.predict_proba(test_df[predictor_cols], \n",
    "                                             ntree_limit=cv_model.best_iteration)[:, 1] / folds.n_splits\n",
    "    \n",
    "print(\"CV score: {:<8.10f}\".format(roc_auc_score(train_part_1_df[target_col], oof)))   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Loss')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss = xgb_clf_draft.evals_result()\n",
    "train_loss = loss['validation_0']['auc']\n",
    "valid_loss = loss['validation_1']['auc']\n",
    "iteration = range(len(train_loss))\n",
    "plt.plot(iteration, train_loss, 'b-', \n",
    "         iteration, valid_loss, 'r-')\n",
    "plt.legend(['Training', 'Validation'])\n",
    "plt.title('Loss')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pred_clf = xgb_clf_draft.predict(valid_data[predictor_cols], \n",
    "                                 ntree_limit=xgb_clf_draft.best_iteration)[:, 1]\n",
    "\n",
    "#y_pred = np.argmax(pred_clf >= 0.5, 1)\n",
    "y_true = valid_data[target].values.tolist()\n",
    "print('Default setting accuracy: {:.4f}%'.format(accuracy_score(y_true, pred_clf) * 100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thresh=0.00239, n=200, Accuracy: 92.08%\n",
      "Thresh=0.00265, n=190, Accuracy: 92.17%\n",
      "Thresh=0.00272, n=180, Accuracy: 92.15%\n",
      "Thresh=0.00282, n=170, Accuracy: 92.19%\n",
      "Thresh=0.00296, n=160, Accuracy: 92.19%\n",
      "Thresh=0.00308, n=150, Accuracy: 92.19%\n",
      "Thresh=0.00318, n=140, Accuracy: 92.05%\n",
      "Thresh=0.00346, n=130, Accuracy: 92.16%\n",
      "Thresh=0.00358, n=120, Accuracy: 92.18%\n",
      "Thresh=0.00389, n=110, Accuracy: 91.96%\n"
     ]
    }
   ],
   "source": [
    "y_true = valid_data[target].values.tolist()\n",
    "thresholds = np.sort(xgb_clf_draft.feature_importances_)\n",
    "target_thresholds = list(map(lambda x:thresholds[x], range(0, thresholds.shape[0]//2, 10)))\n",
    "\n",
    "for thresh in target_thresholds:\n",
    "    # select features using threshold\n",
    "    selection = SelectFromModel(xgb_clf_draft, threshold=thresh, prefit=True)\n",
    "    select_train_data = selection.transform(train_data[predictors])\n",
    "    select_valid_data = selection.transform(valid_data[predictors])\n",
    "    \n",
    "    # train model\n",
    "    eval_set = [(select_train_data, train_data[target]), (select_valid_data, valid_data[target])]\n",
    "    selection_model = xgb.XGBClassifier(**sk_params)\n",
    "    selection_model.fit(X=select_train_data,\n",
    "                        y=train_data[target], \n",
    "                        eval_set=eval_set,  \n",
    "                        early_stopping_rounds=num_early_stopping, \n",
    "                        verbose=False)\n",
    "    # eval model\n",
    "    select_valid_data = selection.transform(valid_data[predictors])\n",
    "    y_pred = selection_model.predict(select_valid_data, ntree_limit=selection_model.best_iteration)\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    print(\"Thresh=%.5f, n=%d, Accuracy: %.2f%%\" % (thresh, select_train_data.shape[1], accuracy*100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15, 15))\n",
    "xgb.plot_importance(xgb_clf, importance_type='gain', max_num_features=30, height=0.5, ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_of_iter = 1000000\n",
    "num_early_stopping = 4000\n",
    "num_verbose_eval = 5000\n",
    "seed = 2319"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_weight = train_df['target'].value_counts()[0] / train_df['target'].value_counts()[1]\n",
    "\n",
    "sk_params = {\n",
    "    'boosting_type': 'gbdt', # goss, dart\n",
    "    'subsample_freq': 5,\n",
    "    'num_leaves': 13,\n",
    "    'max_depth': -1,\n",
    "    'learning_rate': 0.0083,\n",
    "    'n_estimators': num_of_iter,\n",
    "    #'subsample_for_bin': 200000,  # Number of samples for constructing bin\n",
    "    'objective': 'binary',\n",
    "    'metrics': ['auc'],\n",
    "    #'min_split_gain': 0,  # lambda_l1, lambda_l2 and min_gain_to_split to regularization\n",
    "    'min_child_weight': 10.0,  # Minimum sum of instance weight(hessian) needed in a child(leaf)\n",
    "    'min_child_samples': 80,  # Minimum number of data need in a child(min_data_in_leaf)\n",
    "    'subsample': 0.335,\n",
    "    'colsample_bytree': 0.041,\n",
    "    #'reg_alpha': 3,  # L1 regularization term on weights\n",
    "    #'reg_lambda': 3,\n",
    "    'random_state': seed,\n",
    "    'n_jobs': multiprocessing.cpu_count(),\n",
    "    #'scale_pos_weight': labels_weight,\n",
    "    #'max_bin': 255,\n",
    "    'boost_from_average':'false',\n",
    "    'tree_learner': 'serial'\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor_cols = [c for c in train_df.columns if c not in ['ID_code', 'target']]\n",
    "\n",
    "#categorical_cols = [f + '_' + 'bin' for f in convert_predictor_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor_cols = ['var_2', 'var_6', 'var_191', 'new_var']\n",
    "feature_1 = 'var_2'\n",
    "feature_2 = 'var_6'\n",
    "feature_3 = 'var_191'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['new_var'] = np.sqrt(train_df[feature_1].values) + np.sqrt(train_df[feature_2].values) + np.sqrt(abs(train_df[feature_3].values))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "split_probability = 0.3\n",
    "seed = 23191\n",
    "tmp_train_df, tmp_valid_df = train_test_split(train_df,\n",
    "                                              test_size=split_probability, \n",
    "                                              stratify=train_df[target_col],\n",
    "                                              shuffle=True,\n",
    "                                              random_state=seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, train_y = tmp_train_df[predictor_cols], tmp_train_df[target_col]\n",
    "valid_X, valid_y = tmp_valid_df[predictor_cols], tmp_valid_df[target_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_weight = train_df['target'].value_counts()[0] / train_df['target'].value_counts()[1]\n",
    "\n",
    "sk_params = {\n",
    "    'boosting_type': 'gbdt', # goss, dart\n",
    "    'subsample_freq': 5,\n",
    "    'num_leaves': 80,\n",
    "    'max_depth': 7,\n",
    "    'learning_rate': 0.1,\n",
    "    'n_estimators': num_of_iter,\n",
    "    #'subsample_for_bin': 200000,  # Number of samples for constructing bin\n",
    "    'objective': 'binary',\n",
    "    'metrics': ['auc'],\n",
    "    #'min_split_gain': 0,  # lambda_l1, lambda_l2 and min_gain_to_split to regularization\n",
    "    'min_child_weight': 10.0,  # Minimum sum of instance weight(hessian) needed in a child(leaf)\n",
    "    'min_child_samples': 80,  # Minimum number of data need in a child(min_data_in_leaf)\n",
    "    'subsample': 0.8,\n",
    "    'colsample_bytree': 0.8,\n",
    "    #'reg_alpha': 3,  # L1 regularization term on weights\n",
    "    #'reg_lambda': 3,\n",
    "    'random_state': seed,\n",
    "    'n_jobs': multiprocessing.cpu_count(),\n",
    "    #'scale_pos_weight': labels_weight,\n",
    "    #'max_bin': 255,\n",
    "    'boost_from_average':'false',\n",
    "    'tree_learner': 'serial'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 4000 rounds.\n",
      "[5000]\ttraining's auc: 0.999962\tvalid_1's auc: 0.909139\n",
      "Early stopping, best iteration is:\n",
      "[5855]\ttraining's auc: 0.999959\tvalid_1's auc: 0.909181\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(boost_from_average='false', boosting_type='gbdt',\n",
       "        class_weight=None, colsample_bytree=0.8, importance_type='split',\n",
       "        learning_rate=0.1, max_depth=7, metrics=['auc'],\n",
       "        min_child_samples=80, min_child_weight=10.0, min_split_gain=0.0,\n",
       "        n_estimators=1000000, n_jobs=8, num_leaves=80, objective='binary',\n",
       "        random_state=23191, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
       "        subsample=0.8, subsample_for_bin=200000, subsample_freq=5,\n",
       "        tree_learner='serial')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_set = [(train_X, train_y), (valid_X, valid_y)]\n",
    "cv_model = lgb.LGBMClassifier(**sk_params)\n",
    "cv_model.fit(X=train_X,\n",
    "             y=train_y, \n",
    "             eval_set=eval_set,             \n",
    "             early_stopping_rounds=num_early_stopping, \n",
    "             verbose=num_verbose_eval) # categorical_feature=categorical_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " >> CV score: 0.9091812049\n"
     ]
    }
   ],
   "source": [
    "oof = cv_model.predict_proba(tmp_valid_df[predictor_cols], \n",
    "                             ntree_limit=cv_model.best_iteration_)[:, 1]\n",
    "print(\"\\n >> CV score: {:<8.10f}\".format(roc_auc_score(tmp_valid_df[target_col], oof)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f63dccda550>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lgb.plot_importance(cv_model, max_num_features=25, height=0.5, importance_type='split')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predictions = cv_model.predict_proba(test_df[predictor_cols], \n",
    "                                       ntree_limit=cv_model.best_iteration_)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'lgb_submission_use_unique.csv'\n",
    "submission_df = test_df[['ID_code']]\n",
    "submission_df['target'] = y_predictions\n",
    "submission_df.to_csv(file_name, header=True, index=False, mode='w')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "smote = SMOTE(ratio='minority', n_jobs=multiprocessing.cpu_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit\n",
    "def augment(x, y, t=2, shuff_features=200):\n",
    "    xs, xn = [], []\n",
    "    for i in range(t):\n",
    "        mask = y > 0\n",
    "        x1 = x[mask].copy()\n",
    "        ids = np.arange(x1.shape[0])\n",
    "        for c in range(x1.shape[1]):\n",
    "            np.random.shuffle(ids)\n",
    "            x1[:, c] = x1[ids][:, c]\n",
    "        xs.append(x1)\n",
    "\n",
    "    for i in range(t//2):\n",
    "        mask = y==0\n",
    "        x1 = x[mask].copy()\n",
    "        ids = np.arange(x1.shape[0])\n",
    "        for c in range(x1.shape[1]):\n",
    "            np.random.shuffle(ids)\n",
    "            x1[:, c] = x1[ids][:, c]\n",
    "        xn.append(x1)\n",
    "\n",
    "    xs = np.vstack(xs)\n",
    "    xn = np.vstack(xn)\n",
    "    ys = np.ones(xs.shape[0])\n",
    "    yn = np.zeros(xn.shape[0])\n",
    "    x = np.vstack([x, xs, xn])\n",
    "    y = np.concatenate([y, ys, yn])\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor_cols = [c for c in train_df.columns if c not in ['ID_code', 'target']]\n",
    "# predictor_cols = features = [c for c in train_part_1_df.columns if c not in ['ID_code', 'target', 'date']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_folds = 10\n",
    "#folds = StratifiedKFold(n_splits=num_folds, shuffle=True, random_state=2319)\n",
    "folds = KFold(n_splits=num_folds, shuffle=False, random_state=2319)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "train_features = sc.fit_transform(train_df[features])\n",
    "test_features = sc.transform(test_df[features])\n",
    "sc_train_df = pd.DataFrame(train_features, columns=features)\n",
    "sc_test_df = pd.DataFrame(test_features, columns=features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def cv_training(_data, _test_data, _predictor_cols, _target_col, _is_augment=False):\n",
    "    y_predictions = np.zeros(_test_data.shape[0]) \n",
    "    oof = np.zeros(train_df.shape[0])\n",
    "\n",
    "    for fold_, (trn_idx, val_idx) in enumerate(folds.split(_data[_predictor_cols].values,\n",
    "                                                           _data[_target_col].values)):\n",
    "        print(\"===== Fold {} =====\".format(fold_))\n",
    "        \n",
    "        train_X, train_y = _data.iloc[trn_idx][_predictor_cols], _data.iloc[trn_idx][_target_col] \n",
    "        valid_X, valid_y = _data.iloc[val_idx][_predictor_cols], _data.iloc[val_idx][_target_col]\n",
    "        if _is_augment:\n",
    "            over_train_x, over_trian_y = augment(train_X.values, train_y.values)\n",
    "            over_train_x_df = pd.DataFrame(over_train_x)\n",
    "            eval_set = [(over_train_x, over_trian_y), (valid_X, valid_y)]\n",
    "            cv_model = lgb.LGBMClassifier(**sk_params)\n",
    "            cv_model.fit(X=over_train_x,\n",
    "                         y=over_trian_y, \n",
    "                         eval_set=eval_set,             \n",
    "                         early_stopping_rounds=num_early_stopping, \n",
    "                         verbose=num_verbose_eval)\n",
    "        else:\n",
    "            eval_set = [(train_X, train_y), (valid_X, valid_y)]\n",
    "            cv_model = lgb.LGBMClassifier(**sk_params)\n",
    "            cv_model.fit(X=train_X,\n",
    "                         y=train_y, \n",
    "                         eval_set=eval_set,             \n",
    "                         early_stopping_rounds=num_early_stopping, \n",
    "                         verbose=num_verbose_eval)\n",
    "                     #categorical_feature=list(convert_to_categories_cols)) \n",
    "\n",
    "        oof[val_idx] = cv_model.predict_proba(_data.iloc[val_idx][_predictor_cols], \n",
    "                                              ntree_limit=cv_model.best_iteration_)[:, 1]\n",
    "        #oof_2 = cv_model.predict_proba(train_part_2_df[predictor_cols], \n",
    "        #                               ntree_limit=cv_model.best_iteration_)[:, 1]     \n",
    "        #oof_2_df = pd.DataFrame(oof_2, columns=['oof_{}'.format(fold_)])\n",
    "        #part_2_df = pd.concat([part_2_df, oof_2_df], axis=1)\n",
    "\n",
    "        y_predictions += cv_model.predict_proba(_test_data[_predictor_cols], \n",
    "                                               ntree_limit=cv_model.best_iteration_)[:, 1] / folds.n_splits\n",
    "        #y_pred_tmp_df = pd.DataFrame(y_predictions, columns=['oof_{}'.format(fold_)])\n",
    "        #y_pred_df = pd.concat([y_pred_df, y_pred_tmp_df], axis=1)\n",
    "\n",
    "    print(\"\\n >> CV score: {:<8.10f}\".format(roc_auc_score(_data[_target_col], oof)))       \n",
    "    return y_predictions, roc_auc_score(_data[_target_col], oof)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv_stacking(_data_part_1, _data_part_2, _test_data, _predictor_cols, _target_col,\n",
    "                _is_augment=False):\n",
    "    y_predictions = np.zeros(_test_data.shape[0]) \n",
    "    oof_1 = np.zeros(train_part_1_df.shape[0])\n",
    "    oof_2 = np.zeros(train_part_2_df.shape[0])\n",
    "    train_level_2_df = pd.DataFrame()\n",
    "    test_level_2_df = pd.DataFrame()\n",
    "    \n",
    "    for fold_, (trn_idx, val_idx) in enumerate(folds.split(_data_part_1[_predictor_cols].values,\n",
    "                                                           _data_part_1[_target_col].values)):\n",
    "        print(\"===== Fold {} =====\".format(fold_))\n",
    "        \n",
    "        train_X, train_y = _data_part_1.iloc[trn_idx][_predictor_cols], _data_part_1.iloc[trn_idx][_target_col] \n",
    "        valid_X, valid_y = _data_part_1.iloc[val_idx][_predictor_cols], _data_part_1.iloc[val_idx][_target_col]\n",
    "        if _is_augment:\n",
    "            over_train_x, over_trian_y = augment(train_X.values, train_y.values)\n",
    "            over_train_x_df = pd.DataFrame(over_train_x)\n",
    "            eval_set = [(over_train_x, over_trian_y), (valid_X, valid_y)]\n",
    "            cv_model = lgb.LGBMClassifier(**sk_params)\n",
    "            cv_model.fit(X=over_train_x,\n",
    "                         y=over_trian_y, \n",
    "                         eval_set=eval_set,             \n",
    "                         early_stopping_rounds=num_early_stopping, \n",
    "                         verbose=num_verbose_eval)\n",
    "        else:\n",
    "            eval_set = [(train_X, train_y), (valid_X, valid_y)]\n",
    "            cv_model = lgb.LGBMClassifier(**sk_params)\n",
    "            cv_model.fit(X=train_X,\n",
    "                         y=train_y, \n",
    "                         eval_set=eval_set,             \n",
    "                         early_stopping_rounds=num_early_stopping, \n",
    "                         verbose=num_verbose_eval)\n",
    "                     #categorical_feature=list(convert_to_categories_cols)) \n",
    "\n",
    "        oof_1[val_idx] = cv_model.predict_proba(_data_part_1.iloc[val_idx][_predictor_cols], \n",
    "                                                ntree_limit=cv_model.best_iteration_)[:, 1]\n",
    "        \n",
    "        oof_2 = cv_model.predict_proba(_data_part_2[predictor_cols], \n",
    "                                        ntree_limit=cv_model.best_iteration_)[:, 1]     \n",
    "        \n",
    "        oof_2_df = pd.DataFrame(oof_2, columns=['oof_{}'.format(fold_)])\n",
    "        train_level_2_df = pd.concat([train_level_2_df, oof_2_df], axis=1)\n",
    "\n",
    "        y_predictions += cv_model.predict_proba(_test_data[_predictor_cols], \n",
    "                                               ntree_limit=cv_model.best_iteration_)[:, 1] / folds.n_splits\n",
    "        y_pred_tmp_df = pd.DataFrame(y_predictions, columns=['oof_{}'.format(fold_)])\n",
    "        test_level_2_df = pd.concat([test_level_2_df, y_pred_tmp_df], axis=1)\n",
    "\n",
    "    print(\"\\n >> CV score: {:<8.10f}\".format(roc_auc_score(_data_part_1[_target_col], oof_1)))       \n",
    "    return train_level_2_df, test_level_2_df, roc_auc_score(_data[_target_col], oof)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc_train_df = pd.concat([sc_train_df, train_df[features]], axis=1)\n",
    "sc_test_df = pd.concat([sc_test_df, test_df[features]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Fold 0 =====\n",
      "Training until validation scores don't improve for 4000 rounds.\n",
      "[5000]\tvalid_0's auc: 0.911777\tvalid_1's auc: 0.891115\n",
      "[10000]\tvalid_0's auc: 0.921512\tvalid_1's auc: 0.895066\n",
      "[15000]\tvalid_0's auc: 0.92876\tvalid_1's auc: 0.896091\n",
      "[20000]\tvalid_0's auc: 0.935329\tvalid_1's auc: 0.896092\n",
      "Early stopping, best iteration is:\n",
      "[16704]\tvalid_0's auc: 0.931034\tvalid_1's auc: 0.896435\n",
      "===== Fold 1 =====\n",
      "Training until validation scores don't improve for 4000 rounds.\n",
      "[5000]\tvalid_0's auc: 0.910914\tvalid_1's auc: 0.903078\n",
      "[10000]\tvalid_0's auc: 0.920691\tvalid_1's auc: 0.908554\n",
      "[15000]\tvalid_0's auc: 0.928017\tvalid_1's auc: 0.909565\n",
      "Early stopping, best iteration is:\n",
      "[14911]\tvalid_0's auc: 0.927895\tvalid_1's auc: 0.909584\n",
      "===== Fold 2 =====\n",
      "Training until validation scores don't improve for 4000 rounds.\n",
      "[5000]\tvalid_0's auc: 0.911766\tvalid_1's auc: 0.890725\n",
      "[10000]\tvalid_0's auc: 0.921614\tvalid_1's auc: 0.89397\n",
      "[15000]\tvalid_0's auc: 0.928868\tvalid_1's auc: 0.894558\n",
      "Early stopping, best iteration is:\n",
      "[15491]\tvalid_0's auc: 0.929553\tvalid_1's auc: 0.894661\n",
      "===== Fold 3 =====\n",
      "Training until validation scores don't improve for 4000 rounds.\n",
      "[10000]\tvalid_0's auc: 0.920877\tvalid_1's auc: 0.904965\n",
      "[15000]\tvalid_0's auc: 0.928137\tvalid_1's auc: 0.905516\n",
      "Early stopping, best iteration is:\n",
      "[15931]\tvalid_0's auc: 0.929413\tvalid_1's auc: 0.905581\n",
      "===== Fold 4 =====\n",
      "Training until validation scores don't improve for 4000 rounds.\n",
      "[5000]\tvalid_0's auc: 0.911702\tvalid_1's auc: 0.890591\n",
      "[10000]\tvalid_0's auc: 0.921349\tvalid_1's auc: 0.894028\n",
      "[15000]\tvalid_0's auc: 0.928655\tvalid_1's auc: 0.894472\n",
      "Early stopping, best iteration is:\n",
      "[14781]\tvalid_0's auc: 0.928356\tvalid_1's auc: 0.894594\n",
      "===== Fold 5 =====\n",
      "Training until validation scores don't improve for 4000 rounds.\n",
      "[5000]\tvalid_0's auc: 0.911383\tvalid_1's auc: 0.886464\n",
      "[10000]\tvalid_0's auc: 0.921285\tvalid_1's auc: 0.889092\n",
      "[15000]\tvalid_0's auc: 0.928591\tvalid_1's auc: 0.888997\n",
      "Early stopping, best iteration is:\n",
      "[11745]\tvalid_0's auc: 0.923962\tvalid_1's auc: 0.889343\n",
      "===== Fold 6 =====\n",
      "[5000]\tvalid_0's auc: 0.911557\tvalid_1's auc: 0.90246\n",
      "[10000]\tvalid_0's auc: 0.921405\tvalid_1's auc: 0.907429\n",
      "[15000]\tvalid_0's auc: 0.92875\tvalid_1's auc: 0.90769\n",
      "Early stopping, best iteration is:\n",
      "[11890]\tvalid_0's auc: 0.924302\tvalid_1's auc: 0.907876\n",
      "===== Fold 7 =====\n",
      "Training until validation scores don't improve for 4000 rounds.\n",
      "[5000]\tvalid_0's auc: 0.911239\tvalid_1's auc: 0.901679\n",
      "[10000]\tvalid_0's auc: 0.92106\tvalid_1's auc: 0.904913\n",
      "[15000]\tvalid_0's auc: 0.928356\tvalid_1's auc: 0.905201\n",
      "Early stopping, best iteration is:\n",
      "[12885]\tvalid_0's auc: 0.925391\tvalid_1's auc: 0.905289\n",
      "===== Fold 8 =====\n",
      "Training until validation scores don't improve for 4000 rounds.\n",
      "[5000]\tvalid_0's auc: 0.911718\tvalid_1's auc: 0.889539\n",
      "[10000]\tvalid_0's auc: 0.921425\tvalid_1's auc: 0.892387\n",
      "[15000]\tvalid_0's auc: 0.928663\tvalid_1's auc: 0.892399\n",
      "Early stopping, best iteration is:\n",
      "[12635]\tvalid_0's auc: 0.925355\tvalid_1's auc: 0.89274\n",
      "===== Fold 9 =====\n",
      "Training until validation scores don't improve for 4000 rounds.\n",
      "[5000]\tvalid_0's auc: 0.911055\tvalid_1's auc: 0.898493\n",
      "[10000]\tvalid_0's auc: 0.920853\tvalid_1's auc: 0.901817\n",
      "[15000]\tvalid_0's auc: 0.928185\tvalid_1's auc: 0.90232\n",
      "Early stopping, best iteration is:\n",
      "[13390]\tvalid_0's auc: 0.925955\tvalid_1's auc: 0.90235\n",
      "===== Fold 10 =====\n",
      "Training until validation scores don't improve for 4000 rounds.\n",
      "[5000]\tvalid_0's auc: 0.911355\tvalid_1's auc: 0.894095\n",
      "[10000]\tvalid_0's auc: 0.921082\tvalid_1's auc: 0.896515\n",
      "Early stopping, best iteration is:\n",
      "[9605]\tvalid_0's auc: 0.920448\tvalid_1's auc: 0.896625\n",
      "===== Fold 11 =====\n",
      "Training until validation scores don't improve for 4000 rounds.\n",
      "[5000]\tvalid_0's auc: 0.911454\tvalid_1's auc: 0.900009\n",
      "[10000]\tvalid_0's auc: 0.921211\tvalid_1's auc: 0.903018\n",
      "Early stopping, best iteration is:\n",
      "[9713]\tvalid_0's auc: 0.920744\tvalid_1's auc: 0.903094\n",
      "===== Fold 12 =====\n",
      "Training until validation scores don't improve for 4000 rounds.\n",
      "[5000]\tvalid_0's auc: 0.911843\tvalid_1's auc: 0.899191\n",
      "[10000]\tvalid_0's auc: 0.921595\tvalid_1's auc: 0.901928\n",
      "[15000]\tvalid_0's auc: 0.928855\tvalid_1's auc: 0.90183\n",
      "Early stopping, best iteration is:\n",
      "[12160]\tvalid_0's auc: 0.92482\tvalid_1's auc: 0.902026\n",
      "===== Fold 13 =====\n",
      "Training until validation scores don't improve for 4000 rounds.\n",
      "[5000]\tvalid_0's auc: 0.910562\tvalid_1's auc: 0.903944\n",
      "[10000]\tvalid_0's auc: 0.920342\tvalid_1's auc: 0.907007\n",
      "[15000]\tvalid_0's auc: 0.927743\tvalid_1's auc: 0.907646\n",
      "Early stopping, best iteration is:\n",
      "[15978]\tvalid_0's auc: 0.929102\tvalid_1's auc: 0.907738\n",
      "===== Fold 14 =====\n",
      "Training until validation scores don't improve for 4000 rounds.\n",
      "[5000]\tvalid_0's auc: 0.911457\tvalid_1's auc: 0.900197\n",
      "[10000]\tvalid_0's auc: 0.921294\tvalid_1's auc: 0.902112\n",
      "[15000]\tvalid_0's auc: 0.928569\tvalid_1's auc: 0.902519\n",
      "Early stopping, best iteration is:\n",
      "[14299]\tvalid_0's auc: 0.927581\tvalid_1's auc: 0.90261\n",
      "===== Fold 15 =====\n",
      "Training until validation scores don't improve for 4000 rounds.\n",
      "[5000]\tvalid_0's auc: 0.911512\tvalid_1's auc: 0.898429\n",
      "[10000]\tvalid_0's auc: 0.921239\tvalid_1's auc: 0.901965\n",
      "[15000]\tvalid_0's auc: 0.928523\tvalid_1's auc: 0.901837\n",
      "Early stopping, best iteration is:\n",
      "[11737]\tvalid_0's auc: 0.92389\tvalid_1's auc: 0.902122\n",
      "===== Fold 16 =====\n",
      "Training until validation scores don't improve for 4000 rounds.\n"
     ]
    }
   ],
   "source": [
    "y_pred, auc_score = cv_training(train_df, test_df, predictor_cols, target_col, \n",
    "                                _is_augment=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_level_2_df, test_level_2_df, auc_score = cv_stacking(train_part_1_df, \n",
    "                                                           train_part_2_df, test_df, \n",
    "                                                           predictor_cols, \n",
    "                                                           target_col, \n",
    "                                                           _is_augment=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'lgb_submission_only_feature_slice_windows.csv'\n",
    "submission_df = test_df[['ID_code']]\n",
    "submission_df['target'] = y_pred\n",
    "submission_df.to_csv(file_name, header=True, index=False, mode='w')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check correlations with previously result\n",
    "from scipy.stats.stats import pearsonr\n",
    "nn_df = pd.read_csv('./nn_submission.csv')\n",
    "cb_df = pd.read_csv('./cb_submission.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9810304282258011, 0.0)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pearsonr(nn_df[target_col].values, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9222933162488419, 0.0)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pearsonr(cb_df[target_col].values, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "sk_params = {\n",
    "    'loss_function': 'Logloss',\n",
    "    'eval_metric': 'AUC',\n",
    "    'iterations': num_of_iter,\n",
    "    'learning_rate': 0.005,\n",
    "    'random_state': seed,\n",
    "    #'l2_leaf_reg': 0.01,\n",
    "    'bootstrap_type': 'Bernoulli',\n",
    "    'subsample': 0.4, # only use at bootstrap type is [Poisson, Bernoulli]\n",
    "    'use_best_model': True,\n",
    "    'depth': 5,\n",
    "    'one_hot_max_size': 31,\n",
    "    'colsample_bylevel': 0.4,\n",
    "    'leaf_estimation_method': 'Gradient', # [Newton, Gradient]\n",
    "    'class_weights': [1, 8.951238929246692],\n",
    "    'max_bin': 128, # alias max_bin\n",
    "    'use_best_model': True,\n",
    "    'thread_count': multiprocessing.cpu_count()    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_folds = 11\n",
    "folds = StratifiedKFold(n_splits=num_folds, shuffle=False, random_state=2319)\n",
    "oof_cb = np.zeros(train_df.shape[0])\n",
    "y_predictions_cb = np.zeros(test_df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Fold 0 =====\n",
      "0:\ttest: 0.6196260\ttest1: 0.5973012\tbest: 0.5973012 (0)\ttotal: 173ms\tremaining: 2d 9m 21s\n",
      "5000:\ttest: 0.9152808\ttest1: 0.8918786\tbest: 0.8918791 (4999)\ttotal: 15m 30s\tremaining: 2d 3h 24m 58s\n",
      "10000:\ttest: 0.9345802\ttest1: 0.8969014\tbest: 0.8969031 (9995)\ttotal: 30m 53s\tremaining: 2d 2h 58m 2s\n",
      "15000:\ttest: 0.9492535\ttest1: 0.8979270\tbest: 0.8979644 (14684)\ttotal: 46m 15s\tremaining: 2d 2h 37m 10s\n",
      "Stopped by overfitting detector  (4000 iterations wait)\n",
      "\n",
      "bestTest = 0.897966414\n",
      "bestIteration = 15066\n",
      "\n",
      "Shrink model to first 15067 iterations.\n",
      "===== Fold 1 =====\n",
      "0:\ttest: 0.6190083\ttest1: 0.6197627\tbest: 0.6197627 (0)\ttotal: 166ms\tremaining: 1d 22h 10m 53s\n",
      "5000:\ttest: 0.9154997\ttest1: 0.8907716\tbest: 0.8907862 (4996)\ttotal: 15m 32s\tremaining: 2d 3h 31m 47s\n",
      "10000:\ttest: 0.9347703\ttest1: 0.8952405\tbest: 0.8952426 (9997)\ttotal: 31m 3s\tremaining: 2d 3h 14m 27s\n",
      "15000:\ttest: 0.9494584\ttest1: 0.8957647\tbest: 0.8957738 (14975)\ttotal: 46m 31s\tremaining: 2d 2h 54m 32s\n",
      "20000:\ttest: 0.9614148\ttest1: 0.8957074\tbest: 0.8958300 (17740)\ttotal: 1h 1m 58s\tremaining: 2d 2h 36m 14s\n",
      "Stopped by overfitting detector  (4000 iterations wait)\n",
      "\n",
      "bestTest = 0.8958300181\n",
      "bestIteration = 17740\n",
      "\n",
      "Shrink model to first 17741 iterations.\n",
      "===== Fold 2 =====\n",
      "0:\ttest: 0.6158167\ttest1: 0.6067051\tbest: 0.6067051 (0)\ttotal: 164ms\tremaining: 1d 21h 31m 46s\n",
      "5000:\ttest: 0.9160472\ttest1: 0.8853484\tbest: 0.8853484 (5000)\ttotal: 15m 35s\tremaining: 2d 3h 41m 43s\n",
      "10000:\ttest: 0.9352336\ttest1: 0.8903059\tbest: 0.8903084 (9998)\ttotal: 31m 7s\tremaining: 2d 3h 20m 57s\n",
      "20000:\ttest: 0.9616629\ttest1: 0.8913218\tbest: 0.8913338 (19844)\ttotal: 1h 2m 5s\tremaining: 2d 2h 42m 16s\n",
      "25000:\ttest: 0.9710616\ttest1: 0.8913313\tbest: 0.8914072 (23842)\ttotal: 1h 17m 30s\tremaining: 2d 2h 22m 46s\n",
      "Stopped by overfitting detector  (4000 iterations wait)\n",
      "\n",
      "bestTest = 0.8914118315\n",
      "bestIteration = 25483\n",
      "\n",
      "Shrink model to first 25484 iterations.\n",
      "===== Fold 3 =====\n",
      "0:\ttest: 0.6174334\ttest1: 0.6137183\tbest: 0.6137183 (0)\ttotal: 165ms\tremaining: 1d 21h 47m 41s\n",
      "5000:\ttest: 0.9151497\ttest1: 0.8965976\tbest: 0.8966082 (4999)\ttotal: 15m 30s\tremaining: 2d 3h 24m 4s\n",
      "10000:\ttest: 0.9344341\ttest1: 0.9000947\tbest: 0.9000992 (9884)\ttotal: 30m 59s\tremaining: 2d 3h 7m 50s\n",
      "15000:\ttest: 0.9492393\ttest1: 0.9005532\tbest: 0.9006198 (14178)\ttotal: 46m 24s\tremaining: 2d 2h 46m 51s\n",
      "20000:\ttest: 0.9611891\ttest1: 0.9006906\tbest: 0.9007847 (17204)\ttotal: 1h 1m 48s\tremaining: 2d 2h 28m 16s\n",
      "Stopped by overfitting detector  (4000 iterations wait)\n",
      "\n",
      "bestTest = 0.9007847403\n",
      "bestIteration = 17204\n",
      "\n",
      "Shrink model to first 17205 iterations.\n",
      "===== Fold 4 =====\n",
      "0:\ttest: 0.6169386\ttest1: 0.6190361\tbest: 0.6190361 (0)\ttotal: 162ms\tremaining: 1d 21h 4m 34s\n",
      "5000:\ttest: 0.9154756\ttest1: 0.8918209\tbest: 0.8918209 (5000)\ttotal: 15m 32s\tremaining: 2d 3h 33m 38s\n",
      "10000:\ttest: 0.9346432\ttest1: 0.8957429\tbest: 0.8957551 (9989)\ttotal: 30m 50s\tremaining: 2d 2h 52m 20s\n",
      "15000:\ttest: 0.9493845\ttest1: 0.8958827\tbest: 0.8959248 (13052)\ttotal: 46m 4s\tremaining: 2d 2h 25m 50s\n",
      "Stopped by overfitting detector  (4000 iterations wait)\n",
      "\n",
      "bestTest = 0.8959247618\n",
      "bestIteration = 13052\n",
      "\n",
      "Shrink model to first 13053 iterations.\n",
      "===== Fold 5 =====\n",
      "0:\ttest: 0.6173861\ttest1: 0.6149817\tbest: 0.6149817 (0)\ttotal: 161ms\tremaining: 1d 20h 46m 54s\n",
      "5000:\ttest: 0.9152654\ttest1: 0.8948367\tbest: 0.8948422 (4999)\ttotal: 15m 23s\tremaining: 2d 3h 2m 40s\n",
      "10000:\ttest: 0.9346884\ttest1: 0.8987743\tbest: 0.8987743 (10000)\ttotal: 30m 42s\tremaining: 2d 2h 39m 20s\n"
     ]
    }
   ],
   "source": [
    "for fold_, (train_idx, val_idx) in enumerate(folds.split(train_df[predictor_cols].values,\n",
    "                                                         train_df[target_col].values)):\n",
    "    print(\"===== Fold {} =====\".format(fold_))\n",
    "    \n",
    "    train_X, train_y = train_df.iloc[train_idx][predictor_cols], train_df.iloc[train_idx][target_col] \n",
    "    valid_X, valid_y = train_df.iloc[val_idx][predictor_cols], train_df.iloc[val_idx][target_col]\n",
    "    eval_set = [(train_X, train_y), (valid_X, valid_y)]\n",
    "    cv_model = cb.CatBoostClassifier(**sk_params, od_type='Iter', od_wait=20)\n",
    "    cv_model.fit(X=train_X,\n",
    "                 y=train_y, \n",
    "                 eval_set=eval_set,             \n",
    "                 early_stopping_rounds=num_early_stopping, \n",
    "                 verbose=num_verbose_eval) \n",
    "    \n",
    "    oof_cb[val_idx] = cv_model.predict_proba(train_df.iloc[val_idx][predictor_cols], \n",
    "                                             ntree_end=cv_model.best_iteration_)[:, 1]\n",
    "    y_predictions_cb +=  cv_model.predict_proba(test_df[predictor_cols], \n",
    "                                                ntree_end=cv_model.best_iteration_)[:, 1] / folds.n_splits\n",
    "    \n",
    "print(\"\\n >> CV score: {:<8.10f}\".format(roc_auc_score(train_df[target_col], oof_cb)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'cb_submission.csv'\n",
    "submission_df = test_df[['ID_code']]\n",
    "submission_df['target'] = ensemble\n",
    "submission_df.to_csv(file_name, header=True, index=False, mode='w')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN+LightBGM auc = 0.9001412910\n"
     ]
    }
   ],
   "source": [
    "ensemble = 0.75 * oof + 0.25 * oof_cb\n",
    "print('NN+LightBGM auc = {:<8.10f}'.format(roc_auc_score(train_df[target_col], ensemble)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission\n",
    "Base Line submission : 0.500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df = test_df[['ID_code']]\n",
    "submission_df['target'] = ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df.to_csv('ensemble_submission.csv', header=True, index=False, mode='w')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
