{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "from pathlib import Path\n",
    "from scipy.special import logit\n",
    "\n",
    "IS_LOCAL = False\n",
    "if(IS_LOCAL):\n",
    "    PATH = Path('/mnt/disks/data/santander-customer-transaction/')\n",
    "else:\n",
    "    PATH = Path('../input/santander-customer-transaction-prediction')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 17 s, sys: 776 ms, total: 17.8 s\n",
      "Wall time: 17.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_df = pd.read_csv(str(PATH / 'train.csv'))\n",
    "test_df = pd.read_csv(str(PATH / 'test.csv'))\n",
    "features = [x for x in train_df.columns if x.startswith(\"var\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_df = pd.DataFrame()\n",
    "for var in features:\n",
    "    var_stats = train_df[var].append(test_df[var]).value_counts()\n",
    "    hist_df[var] = pd.Series(test_df[var]).map(var_stats)\n",
    "    hist_df[var] = hist_df[var] > 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         200\n",
       "1         200\n",
       "2         200\n",
       "3         184\n",
       "4         200\n",
       "5         200\n",
       "6         200\n",
       "7         185\n",
       "8         200\n",
       "9         200\n",
       "10        200\n",
       "11        183\n",
       "12        200\n",
       "13        200\n",
       "14        200\n",
       "15        189\n",
       "16        189\n",
       "17        181\n",
       "18        186\n",
       "19        200\n",
       "20        186\n",
       "21        187\n",
       "22        192\n",
       "23        200\n",
       "24        185\n",
       "25        200\n",
       "26        200\n",
       "27        200\n",
       "28        200\n",
       "29        185\n",
       "         ... \n",
       "199970    184\n",
       "199971    200\n",
       "199972    190\n",
       "199973    190\n",
       "199974    183\n",
       "199975    200\n",
       "199976    188\n",
       "199977    200\n",
       "199978    200\n",
       "199979    200\n",
       "199980    194\n",
       "199981    200\n",
       "199982    193\n",
       "199983    186\n",
       "199984    186\n",
       "199985    179\n",
       "199986    186\n",
       "199987    200\n",
       "199988    200\n",
       "199989    200\n",
       "199990    200\n",
       "199991    200\n",
       "199992    200\n",
       "199993    187\n",
       "199994    200\n",
       "199995    192\n",
       "199996    187\n",
       "199997    200\n",
       "199998    200\n",
       "199999    187\n",
       "Length: 200000, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist_df.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = hist_df.sum(axis=1) != 200\n",
    "var_stats = {var:train_df[var].append(test_df[ind][var]).value_counts() for var in features}\n",
    "pred = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -1.0914,   2.    ],\n",
       "       [  1.9518,   2.    ],\n",
       "       [  0.3965,   2.    ],\n",
       "       ...,\n",
       "       [  4.1995,   1.    ],\n",
       "       [-13.9001,   1.    ],\n",
       "       [  0.1385,   1.    ]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.hstack([train_df[var].values.reshape(-1,1), train_df[var].map(var_stats[var]).values.reshape(-1,1)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **One question, I see your submission file contains a lot of negative large values like -440.xxxxx. Is this the final results you submitted with .922 auc?**\n",
    "\n",
    "Ans:\n",
    "Yes, as the scale makes no difference for AUROC. These are summed logOdds, so you should be able to get back to probabilities by dividing them by 200 and applying a logisitc function.\n",
    "\n",
    "2. **Why did `pred += logit(model.predict_proba())` instead of `pred += log10(model.predict_proba())`**\n",
    "\n",
    "Ans:\n",
    "That's a valid question. We actually did += log for long time (which is the same as multiplication of probabilities). But logit does transformation of probabilities to odds first and it gives a slight boost over simple log."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for var in features:\n",
    "    model = lgb.LGBMClassifier(**{\n",
    "        'learning_rate':0.05, \n",
    "        'max_bin': 165, \n",
    "        'max_depth': 5, \n",
    "        'min_child_samples': 150,\n",
    "        'min_child_weight': 0.1, \n",
    "        'min_split_gain': 0.0018, \n",
    "        'n_estimators': 41,\n",
    "        'num_leaves': 6, \n",
    "        'reg_alpha': 2.0, \n",
    "        'reg_lambda': 2.54, \n",
    "        'objective': 'binary', \n",
    "        'n_jobs': -1})\n",
    "    model = model.fit(np.hstack([train_df[var].values.reshape(-1,1),\n",
    "                                 train_df[var].map(var_stats[var]).values.reshape(-1,1)]),\n",
    "                               train_df[\"target\"].values)\n",
    "    pred += logit(model.predict_proba(np.hstack([test_df[var].values.reshape(-1,1),\n",
    "                                 test_df[var].map(var_stats[var]).values.reshape(-1,1)]))[:,1])\n",
    "    \n",
    "pd.DataFrame({\"ID_code\":test_df[\"ID_code\"], \"target\":pred}).to_csv(\"submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
