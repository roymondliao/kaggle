{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/externals/joblib/__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing\n",
    "import warnings\n",
    "import os\n",
    "import gc\n",
    "import random\n",
    "import itertools\n",
    "import pickle\n",
    "import time\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "from datetime import datetime\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "# visualization \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# data preprocessing \n",
    "from itertools import product\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import missingno\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "# model\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "import catboost as cb \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# eveluation \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_recall_fscore_support, roc_curve\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "# hyperparameters tuning \n",
    "from skopt.space import Real, Integer\n",
    "from skopt.utils import use_named_args\n",
    "from skopt import gp_minimize\n",
    "\n",
    "# utils\n",
    "import sys\n",
    "sys.path.insert(0, '/tf/notebooks/other/kaggle')\n",
    "from utils import utils_featexp\n",
    "from utils import utils_features_engineering\n",
    "from utils import utils_features_plots\n",
    "from utils import utils_reduce_memory\n",
    "from utils import utils_statistic\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "seed = 9527"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_path = Path('../input/ieee-cis-fraud-detection/')\n",
    "\n",
    "with open(str(main_path / 'train_df.pkl'), 'rb') as handle:\n",
    "    train_df = pickle.load(handle)\n",
    "    \n",
    "with open(str(main_path / 'test_df.pkl'), 'rb') as handle:\n",
    "    test_df = pickle.load(handle)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of train data:{}'.format(train_df.shape))\n",
    "print('Number of test data:{}'.format(test_df.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_col = 'isFraud'\n",
    "redundant_cols = ['P_emaildomain', 'R_emaildomain', 'DeviceType', 'DeviceInfo', 'TransactionDT', 'tran_date']\n",
    "features_cols = [c for c in train_df.columns.tolist() if c not in redundant_cols + ['TransactionID', 'isFraud']]\n",
    "cat_features = [i for i in features_cols if str(train_df[i].dtype) in ['object', 'category']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc = LabelEncoder()\n",
    "for f in cat_features:\n",
    "    if train_df[f].dtype =='O': \n",
    "        df1_tmp = train_df[f].fillna('NaN')\n",
    "        df2_tmp = test_df[f].fillna('NaN')        \n",
    "        enc.fit(np.concatenate([df1_tmp.values, df2_tmp.values], axis=0).astype(str))\n",
    "        train_df[f] = enc.transform(df1_tmp.values)\n",
    "        test_df[f] = enc.transform(df2_tmp.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneHotEncoder(categorical_features=None, categories=None, drop=None,\n",
       "              dtype='uint8', handle_unknown='error', n_values=None,\n",
       "              sparse=True)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "OneHotEncoder(categorical_features=None, categories=None, drop=None,\n",
       "              dtype='uint8', handle_unknown='error', n_values=None,\n",
       "              sparse=True)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "OneHotEncoder(categorical_features=None, categories=None, drop=None,\n",
       "              dtype='uint8', handle_unknown='error', n_values=None,\n",
       "              sparse=True)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "OneHotEncoder(categorical_features=None, categories=None, drop=None,\n",
       "              dtype='uint8', handle_unknown='error', n_values=None,\n",
       "              sparse=True)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "OneHotEncoder(categorical_features=None, categories=None, drop=None,\n",
       "              dtype='uint8', handle_unknown='error', n_values=None,\n",
       "              sparse=True)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "OneHotEncoder(categorical_features=None, categories=None, drop=None,\n",
       "              dtype='uint8', handle_unknown='error', n_values=None,\n",
       "              sparse=True)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "OneHotEncoder(categorical_features=None, categories=None, drop=None,\n",
       "              dtype='uint8', handle_unknown='error', n_values=None,\n",
       "              sparse=True)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "OneHotEncoder(categorical_features=None, categories=None, drop=None,\n",
       "              dtype='uint8', handle_unknown='error', n_values=None,\n",
       "              sparse=True)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "OneHotEncoder(categorical_features=None, categories=None, drop=None,\n",
       "              dtype='uint8', handle_unknown='error', n_values=None,\n",
       "              sparse=True)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "OneHotEncoder(categorical_features=None, categories=None, drop=None,\n",
       "              dtype='uint8', handle_unknown='error', n_values=None,\n",
       "              sparse=True)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "OneHotEncoder(categorical_features=None, categories=None, drop=None,\n",
       "              dtype='uint8', handle_unknown='error', n_values=None,\n",
       "              sparse=True)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "OneHotEncoder(categorical_features=None, categories=None, drop=None,\n",
       "              dtype='uint8', handle_unknown='error', n_values=None,\n",
       "              sparse=True)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "OneHotEncoder(categorical_features=None, categories=None, drop=None,\n",
       "              dtype='uint8', handle_unknown='error', n_values=None,\n",
       "              sparse=True)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "OneHotEncoder(categorical_features=None, categories=None, drop=None,\n",
       "              dtype='uint8', handle_unknown='error', n_values=None,\n",
       "              sparse=True)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "OneHotEncoder(categorical_features=None, categories=None, drop=None,\n",
       "              dtype='uint8', handle_unknown='error', n_values=None,\n",
       "              sparse=True)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "OneHotEncoder(categorical_features=None, categories=None, drop=None,\n",
       "              dtype='uint8', handle_unknown='error', n_values=None,\n",
       "              sparse=True)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "OneHotEncoder(categorical_features=None, categories=None, drop=None,\n",
       "              dtype='uint8', handle_unknown='error', n_values=None,\n",
       "              sparse=True)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "OneHotEncoder(categorical_features=None, categories=None, drop=None,\n",
       "              dtype='uint8', handle_unknown='error', n_values=None,\n",
       "              sparse=True)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "OneHotEncoder(categorical_features=None, categories=None, drop=None,\n",
       "              dtype='uint8', handle_unknown='error', n_values=None,\n",
       "              sparse=True)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "OneHotEncoder(categorical_features=None, categories=None, drop=None,\n",
       "              dtype='uint8', handle_unknown='error', n_values=None,\n",
       "              sparse=True)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "OneHotEncoder(categorical_features=None, categories=None, drop=None,\n",
       "              dtype='uint8', handle_unknown='error', n_values=None,\n",
       "              sparse=True)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "OneHotEncoder(categorical_features=None, categories=None, drop=None,\n",
       "              dtype='uint8', handle_unknown='error', n_values=None,\n",
       "              sparse=True)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "OneHotEncoder(categorical_features=None, categories=None, drop=None,\n",
       "              dtype='uint8', handle_unknown='error', n_values=None,\n",
       "              sparse=True)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "OneHotEncoder(categorical_features=None, categories=None, drop=None,\n",
       "              dtype='uint8', handle_unknown='error', n_values=None,\n",
       "              sparse=True)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "OneHotEncoder(categorical_features=None, categories=None, drop=None,\n",
       "              dtype='uint8', handle_unknown='error', n_values=None,\n",
       "              sparse=True)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "OneHotEncoder(categorical_features=None, categories=None, drop=None,\n",
       "              dtype='uint8', handle_unknown='error', n_values=None,\n",
       "              sparse=True)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "OneHotEncoder(categorical_features=None, categories=None, drop=None,\n",
       "              dtype='uint8', handle_unknown='error', n_values=None,\n",
       "              sparse=True)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "OneHotEncoder(categorical_features=None, categories=None, drop=None,\n",
       "              dtype='uint8', handle_unknown='error', n_values=None,\n",
       "              sparse=True)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "OneHotEncoder(categorical_features=None, categories=None, drop=None,\n",
       "              dtype='uint8', handle_unknown='error', n_values=None,\n",
       "              sparse=True)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "OneHotEncoder(categorical_features=None, categories=None, drop=None,\n",
       "              dtype='uint8', handle_unknown='error', n_values=None,\n",
       "              sparse=True)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "OneHotEncoder(categorical_features=None, categories=None, drop=None,\n",
       "              dtype='uint8', handle_unknown='error', n_values=None,\n",
       "              sparse=True)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "total_train_ohe_df = pd.DataFrame()\n",
    "total_test_ohe_df = pd.DataFrame()\n",
    "\n",
    "ohe_cols = []\n",
    "ohe = OneHotEncoder(dtype='uint8')\n",
    "for f in cat_features:\n",
    "    ohe.fit(train_df[f].values.reshape(-1, 1))\n",
    "    ohe_matrix_train = ohe.transform(train_df[f].values.reshape(-1, 1)).toarray()\n",
    "    ohe_matrix_test = ohe.transform(test_df[f].values.reshape(-1, 1)).toarray()        \n",
    "    ohe_cate = ['{}_{}'.format(f, int(i)) for i in ohe.categories_[0]]\n",
    "    ohe_train_df = pd.DataFrame(ohe_matrix_train, columns=ohe_cate)\n",
    "    ohe_test_df = pd.DataFrame(ohe_matrix_test, columns=ohe_cate)\n",
    "    drop_index = np.random.randint(len(ohe_cate))\n",
    "    ohe_train_df.drop(ohe_cate[drop_index], inplace=True, axis=1)\n",
    "    ohe_test_df.drop(ohe_cate[drop_index], inplace=True, axis=1)\n",
    "    ohe_cols.append(ohe_cate)\n",
    "    total_train_ohe_df = pd.concat([total_train_ohe_df, ohe_train_df], axis=1)\n",
    "    total_test_ohe_df = pd.concat([total_test_ohe_df, ohe_test_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.concat([train_df, total_train_ohe_df], axis=1)\n",
    "test_df = pd.concat([test_df, total_test_ohe_df], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.drop(cat_features, axis=1, inplace=True)\n",
    "test_df.drop(cat_features, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "redundant_cols = ['P_emaildomain', 'R_emaildomain', 'DeviceType', 'DeviceInfo', 'TransactionDT', 'tran_date']\n",
    "features_cols = [c for c in train_df.columns.tolist() if c not in redundant_cols + ['TransactionID', 'isFraud']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "147"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.fillna(-99, inplace=True)\n",
    "test_df.fillna(-99, inplace=True)\n",
    "del total_train_ohe_df, total_test_ohe_df, ohe_train_df, ohe_test_df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "flatten_ohe_cols = list(itertools.chain(*ohe_cols))\n",
    "final_ohe_cols = [i for i in features_cols if i in flatten_ohe_cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Min Max Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_df = pd.concat([train_df[features_cols], test_df[features_cols]], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_binary_cols = []\n",
    "for col in all_data_df.columns:\n",
    "    if all_data_df[col].nunique() != 2:\n",
    "        no_binary_cols.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MinMaxScaler(copy=True, feature_range=(0, 1))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = MinMaxScaler()\n",
    "scaler.fit(all_data_df[no_binary_cols])\n",
    "scaler_all_data = scaler.transform(all_data_df[no_binary_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_df[no_binary_cols] = scaler_all_data\n",
    "tmp_train_df = all_data_df.iloc[:train_df.shape[0], :]\n",
    "tmp_test_df = all_data_df.iloc[train_df.shape[0]:, :]\n",
    "del all_data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem. usage decreased to 770.43 Mb (63.8% reduction)\n",
      "Mem. usage decreased to 661.04 Mb (63.8% reduction)\n"
     ]
    }
   ],
   "source": [
    "tmp_train_df = utils_reduce_memory.reduce_mem_usage(tmp_train_df)\n",
    "tmp_test_df = utils_reduce_memory.reduce_mem_usage(tmp_test_df)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(str(main_path / 'scale_train_df.pkl'), 'wb') as handle:\n",
    "    pickle.dump(tmp_train_df, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "with open(str(main_path / 'scale_test_df.pkl'), 'wb') as handle:\n",
    "    pickle.dump(tmp_test_df, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nearest Neighbors Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from multiprocessing import Pool\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class NearestNeighborsFeats(BaseEstimator, ClassifierMixin):\n",
    "    '''\n",
    "        This class should implement KNN features extraction \n",
    "    '''\n",
    "    def __init__(self, n_jobs, k_list, metric, n_classes=None, n_neighbors=None, eps=1e-6):\n",
    "        self.n_jobs = n_jobs\n",
    "        self.k_list = k_list\n",
    "        self.metric = metric\n",
    "        \n",
    "        if n_neighbors is None:\n",
    "            self.n_neighbors = max(k_list) \n",
    "        else:\n",
    "            self.n_neighbors = n_neighbors\n",
    "            \n",
    "        self.eps = eps        \n",
    "        self.n_classes_ = n_classes\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        '''\n",
    "            Set's up the train set and self.NN object\n",
    "        '''\n",
    "        # Create a NearestNeighbors (NN) object. We will use it in `predict` function \n",
    "        self.NN = NearestNeighbors(n_neighbors=max(self.k_list), \n",
    "                                   metric=self.metric, \n",
    "                                   n_jobs=self.n_jobs, \n",
    "                                   algorithm='brute' if self.metric=='cosine' else 'auto')\n",
    "        self.NN.fit(X)\n",
    "        self.y_train = y\n",
    "        self.n_classes = np.unique(y).shape[0] if self.n_classes_ is None else self.n_classes_                \n",
    "        \n",
    "    def predict(self, X):       \n",
    "        '''\n",
    "            Produces KNN features for every object of a dataset X\n",
    "        '''\n",
    "        if self.n_jobs == 1:\n",
    "            test_feats = []\n",
    "            for i in range(X.shape[0]):               \n",
    "                test_feats.append(self.get_features_for_one(X[i:i+1]))\n",
    "        else:\n",
    "            feat = []\n",
    "            with Pool(processes=self.n_jobs) as pool:\n",
    "                res = pool.map(self.get_features_for_one, list(X))     \n",
    "                #multi_res = [pool.apply_async(self.get_features_for_one, (np.array(i),)) for i in X]\n",
    "                #for res in multi_res:\n",
    "                #    feat.append(res.get())\n",
    "        return np.vstack(res)\n",
    "        \n",
    "        \n",
    "    def get_features_for_one(self, x):\n",
    "        '''\n",
    "            Computes KNN features for a single object `x`\n",
    "        '''       \n",
    "        NN_output = self.NN.kneighbors(x.reshape(1, -1))\n",
    "        \n",
    "        # Stores indices of the neighbors\n",
    "        neighs = NN_output[1][0]\n",
    "    \n",
    "        # Stores distances to corresponding neighbors\n",
    "        neighs_dist = NN_output[0][0] \n",
    "        \n",
    "        # Stores labels of corresponding neighbors\n",
    "        neighs_y = self.y_train[neighs] \n",
    "        \n",
    "        # We will accumulate the computed features here\n",
    "        # Eventually it will be a list of lists or np.arrays\n",
    "        # and we will use np.hstack to concatenate those\n",
    "        return_list = [] \n",
    "        \n",
    "        \n",
    "        ''' \n",
    "            1. Fraction of objects of every class.\n",
    "               It is basically a KNNСlassifiers predictions.\n",
    "\n",
    "               Take a look at `np.bincount` function, it can be very helpful\n",
    "               Note that the values should sum up to one\n",
    "        '''\n",
    "        for k in self.k_list:\n",
    "            feats = np.bincount(neighs_y[:k], minlength=self.n_classes)\n",
    "            feats = feats / sum(feats)\n",
    "            assert len(feats) == self.n_classes\n",
    "            return_list += [feats]\n",
    "        \n",
    "        \n",
    "        '''\n",
    "            2. Same label streak: the largest number N, \n",
    "               such that N nearest neighbors have the same label.\n",
    "               \n",
    "               What can help you: `np.where`\n",
    "        '''\n",
    "        diff = np.where(neighs_y != neighs_y[0])[0]\n",
    "        feats = [diff[0]] if len(diff) else [len(neighs_y)]\n",
    "        \n",
    "        assert len(feats) == 1\n",
    "        return_list += [feats]        \n",
    "\n",
    "        \n",
    "        '''\n",
    "            3. Minimum distance to objects of each class\n",
    "               Find the first instance of a class and take its distance as features.\n",
    "               \n",
    "               If there are no neighboring objects of some classes, \n",
    "               Then set distance to that class to be 999.\n",
    "\n",
    "               `np.where` might be helpful\n",
    "        '''\n",
    "        feats = []\n",
    "        for c in range(self.n_classes):        \n",
    "            first_instance = np.where(neighs_y == c)[0]\n",
    "            feats.append(neighs_dist[first_instance[0]] if len(first_instance) else 999)\n",
    "        \n",
    "        assert len(feats) == self.n_classes\n",
    "        return_list += [feats]\n",
    "        \n",
    "        '''\n",
    "            4. Minimum *normalized* distance to objects of each class\n",
    "               As 3. but we normalize (divide) the distances\n",
    "               by the distance to the closest neighbor.\n",
    "               \n",
    "               If there are no neighboring objects of some classes, \n",
    "               Then set distance to that class to be 999.\n",
    "               \n",
    "               Do not forget to add self.eps to denominator.\n",
    "        '''\n",
    "        feats = []\n",
    "        for c in range(self.n_classes):\n",
    "            # neights_dist 是按照距離小排到大的數值\n",
    "            same = np.where(neighs_y == c)[0]\n",
    "            # normalized 都除以 minimum\n",
    "            feats.append(neighs_dist[same[0]] / (self.eps + neighs_dist[0]) if len(same) else 999)                    \n",
    "        assert len(feats) == self.n_classes\n",
    "        return_list += [feats]\n",
    "        \n",
    "        '''\n",
    "            5. \n",
    "               5.1 Distance to Kth neighbor\n",
    "                   Think of this as of quantiles of a distribution\n",
    "               5.2 Distance to Kth neighbor normalized by \n",
    "                   distance to the first neighbor\n",
    "               \n",
    "               feat_51, feat_52 are answers to 5.1. and 5.2.\n",
    "               should be scalars\n",
    "               \n",
    "               Do not forget to add self.eps to denominator.\n",
    "        '''\n",
    "        for k in self.k_list:            \n",
    "            feat_51 = neighs_dist[k - 1] \n",
    "            feat_52 = neighs_dist[k - 1] / (self.eps + neighs_dist[0])            \n",
    "            return_list += [[feat_51, feat_52]]\n",
    "        \n",
    "        '''\n",
    "            6. Mean distance to neighbors of each class for each K from `k_list` \n",
    "                   For each class select the neighbors of that class among K nearest neighbors \n",
    "                   and compute the average distance to those objects\n",
    "                   \n",
    "                   If there are no objects of a certain class among K neighbors, set mean distance to 999\n",
    "                   \n",
    "               You can use `np.bincount` with appropriate weights\n",
    "               Don't forget, that if you divide by something, \n",
    "               You need to add `self.eps` to denominator.\n",
    "        '''\n",
    "        for k in self.k_list:\n",
    "            numerator = np.bincount(neighs_y[:k], weights=neighs_dist[:k], minlength=self.n_classes)\n",
    "            denominator = self.eps + np.bincount(neighs_y[:k], minlength=self.n_classes)\n",
    "            feats = np.where(numerator > 0, numerator / denominator, 999)     \n",
    "            \n",
    "            assert len(feats) == self.n_classes\n",
    "            return_list += [feats]\n",
    "\n",
    "        # merge        \n",
    "        knn_feats = np.round(np.hstack(return_list), 6)\n",
    "        return knn_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_train_df[target_col] = train_df[target_col]\n",
    "sample_train_df = tmp_train_df[tmp_train_df[target_col] == 0].sample(train_df[train_df.isFraud == 1].shape[0]*2,\n",
    "                                                                     replace=False)\n",
    "sample_train_df = pd.concat([sample_train_df, tmp_train_df[tmp_train_df[target_col] == 1]], axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minkowski\n",
      "===== Fold 0 =====\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# k = int(sample_train_df.shape[0]**(1/2))\n",
    "# 考慮到數據不平衡的狀況，在 k 的選擇應該要縮小，特意放大 negative 的 label\n",
    "\n",
    "k_list = [5, 9, 23]\n",
    "knn_feates_train = np.zeros((train_df.shape[0], max(k_list)))\n",
    "knn_feates_test = np.zeros((train_df.shape[0], max(k_list)))\n",
    "n_splits = 3\n",
    "\n",
    "for metric in ['minkowski', 'cosine']:\n",
    "    print (metric)\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=seed)    \n",
    "    #skf = TimeSeriesSplit(n_splits=n_splits)\n",
    "    Kflods = skf.split(sample_train_df[features_cols].values, sample_train_df[target_col].values)\n",
    "    \n",
    "    for fold, (trn_idx, val_idx) in enumerate(Kflods):\n",
    "        print(\"===== Fold {} =====\".format(fold))\n",
    "        trn_idx = shuffle(trn_idx)\n",
    "        train_x, train_y = sample_train_df.iloc[trn_idx][features_cols], sample_train_df.iloc[trn_idx][target_col]\n",
    "        valid_x, valid_y = sample_train_df.iloc[val_idx][features_cols], sample_train_df.iloc[val_idx][target_col]\n",
    "        \n",
    "        # Create instance of our KNN feature extractor\n",
    "        NNF = NearestNeighborsFeats(n_jobs=multiprocessing.cpu_count(), k_list=k_list, metric=metric)\n",
    "        NNF.fit(train_x.values, train_y.values)\n",
    "        knn_feates_train += NNF.predict(tmp_train_df[features_cols].values) / skf.n_splits\n",
    "        knn_feates_test += NNF.predict(tmp_test_df[features_cols].values) / skf.n_splits\n",
    "    np.save(str(main_path / 'knn_feats_{}_train.npy'.format(metric)), knn_feates_train)\n",
    "    np.save(str(main_path / 'knn_feats_{}_test.npy'.format(metric)), knn_feates_test)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %run knn_features.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
