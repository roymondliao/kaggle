{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from glob import glob # parse the files name\n",
    "from PIL import Image\n",
    "import matplotlib.pylab as plt\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from subprocess import check_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as k\n",
    "from keras.utils import plot_model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing import image\n",
    "from keras.utils import multi_gpu_model\n",
    "from keras.applications import VGG16\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\" \n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = 0,1 #  '':表示強迫使用cpu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set data path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_path = Path('../../../data/humpback-whale-identification-challenge')\n",
    "train_path = main_path / 'train'\n",
    "test_path = main_path / 'test'\n",
    "train_images = glob(str(train_path / '*.jpg'))\n",
    "test_image = glob(str(test_path / '*.jpg'))\n",
    "df = pd.read_csv(str(main_path / 'train_data_clean.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of clean images:8295\n"
     ]
    }
   ],
   "source": [
    "check_image_list = df['Image'].tolist()\n",
    "clean_train_images = []\n",
    "for im in train_images:\n",
    "    if im in check_image_list:\n",
    "        clean_train_images.append(im)\n",
    "print('Number of clean images:{}'.format(len(clean_train_images)))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train images: 9850\n",
      "Number of test images: 15610\n"
     ]
    }
   ],
   "source": [
    "print('Number of train images: {}\\nNumber of test images: {}'.format(\n",
    "    len(train_images), len(test_image)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['Image'] = df['Image'].map(lambda x: str(train_path / x)) # 已在clean的時候處理完\n",
    "ImageToLabelDict = dict(zip(df['Image'], df['Id']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JPEG (699, 500) L\n"
     ]
    }
   ],
   "source": [
    "im = Image.open(df['Image'][0])\n",
    "print(im.format, im.size, im.mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8295 train samples\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "SIZE = 100\n",
    "def ImportImage(filename):\n",
    "    img = Image.open(filename).resize((SIZE, SIZE))\n",
    "    img = np.array(img)\n",
    "    if img.ndim == 2: #imported BW picture and converting to \"dumb RGB\"\n",
    "        img = np.tile(img, (3, 1, 1)).transpose((1, 2, 0))\n",
    "    return img\n",
    "x_train = np.array([ImportImage(img) for img in df['Image'].values], dtype=np.uint8)\n",
    "print(x_train.shape[0], 'train samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sample/class\t number of classes\n",
      "1\t\t\t 2401\n",
      "2\t\t\t 961\n",
      "3\t\t\t 373\n",
      "4\t\t\t 143\n",
      "5\t\t\t 61\n",
      "6\t\t\t 41\n",
      "7\t\t\t 25\n",
      "8\t\t\t 17\n",
      "9\t\t\t 10\n",
      "10\t\t\t 8\n",
      "11\t\t\t 5\n",
      "12\t\t\t 4\n",
      "13\t\t\t 8\n",
      "14\t\t\t 6\n",
      "15\t\t\t 2\n",
      "16\t\t\t 3\n",
      "17\t\t\t 3\n",
      "18\t\t\t 1\n",
      "19\t\t\t 1\n",
      "20\t\t\t 1\n",
      "21\t\t\t 2\n",
      "22\t\t\t 1\n",
      "23\t\t\t 1\n",
      "24\t\t\t 1\n",
      "27\t\t\t 1\n",
      "634\t\t\t 1\n"
     ]
    }
   ],
   "source": [
    "print('Number of sample/class\\t number of classes')\n",
    "for index, val in df['Id'].value_counts().value_counts().sort_index().iteritems():\n",
    "    print('{}\\t\\t\\t {}'.format(index, val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We read that the classes are very **unbalanced**: one class has ~800 samples while ~2000 have only one example in the training set. This calls for a lot of data augmentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One hot encoding on the labels\n",
    "Using a composition of a LabelEncoder and OneHotEncoder to one hot encode the target tail kinds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LabelOneHotEncoder():\n",
    "    def __init__(self):\n",
    "        self.le = LabelEncoder() # label to number\n",
    "        self.ohe = OneHotEncoder() # number to encoding \n",
    "    def fit_transform(self, x):\n",
    "        features = self.le.fit_transform(x)\n",
    "        return self.ohe.fit_transform(features.reshape(-1, 1))\n",
    "    def transform(self, x):\n",
    "        return self.ohe.transform(self.le.transform(x.reshape(-1, 1)))\n",
    "    def inverse_tranform(self, x):\n",
    "        return self.le.inverse_transform(self.ohe.inverse_tranform(x))\n",
    "    def inverse_labels(self, x):\n",
    "        return self.le.inverse_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_data(x):\n",
    "    if not x is None:\n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = list(filter(check_data, map(ImageToLabelDict.get, train_images)))\n",
    "lohe = LabelOneHotEncoder()\n",
    "y_cat = lohe.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<8295x4081 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 8295 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8295, (8295, 4081))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y), y_cat.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image augmentation with Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use of an image generator for preprocessing and data augmentation\n",
    "x_train = x_train.reshape((-1, SIZE, SIZE, 3))\n",
    "input_shape = x_train[0].shape\n",
    "#x_train = x.astype('float32')\n",
    "y_train = y_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_gen = ImageDataGenerator(\n",
    "    #featurewise_center=True,\n",
    "    #featurewise_std_normalization=True,\n",
    "    rescale=1./255,\n",
    "    rotation_range=15,\n",
    "    width_shift_range=0.15,\n",
    "    height_shift_range=0.15,\n",
    "    horizontal_flip=True    \n",
    ")\n",
    "# training the image preprocessing\n",
    "image_gen.fit(x_train, augment=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building and training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (8295, 100, 100, 3)\n",
      "8295 train samples\n"
     ]
    }
   ],
   "source": [
    "batch_size = 256\n",
    "num_classes = len(y_cat.toarray()[0])\n",
    "epochs = x_train.shape[0]//batch_size + 1\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use vgg16 model\n",
    "model = Sequential()\n",
    "conv_base = VGG16(weights='imagenet', include_top=False, input_shape=input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 100, 100, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 100, 100, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 100, 100, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 50, 50, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 50, 50, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 50, 50, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 25, 25, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 25, 25, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 25, 25, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 25, 25, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 12, 12, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 12, 12, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 12, 12, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 12, 12, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 6, 6, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 6, 6, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 6, 6, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 6, 6, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 3, 3, 512)         0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "conv_base.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# freeze layers\n",
    "for layer in conv_base.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 100, 100, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 100, 100, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 100, 100, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 50, 50, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 50, 50, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 50, 50, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 25, 25, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 25, 25, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 25, 25, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 25, 25, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 12, 12, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 12, 12, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 12, 12, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 12, 12, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 6, 6, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 6, 6, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 6, 6, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 6, 6, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 3, 3, 512)         0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 0\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "conv_base.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# maybe unfreeze last layer\n",
    "conv_base.layers[-2].trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(conv_base)\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(48, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(48, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 100, 100, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 100, 100, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 100, 100, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 50, 50, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 50, 50, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 50, 50, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 25, 25, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 25, 25, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 25, 25, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 25, 25, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 12, 12, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 12, 12, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 12, 12, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 12, 12, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 6, 6, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 6, 6, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 6, 6, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 6, 6, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 3, 3, 512)         0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 2,359,808\n",
      "Non-trainable params: 12,354,880\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "conv_base.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "isMultiGPU = 1\n",
    "if isMultiGPU:\n",
    "    parallel_model = multi_gpu_model(model, 2)\n",
    "    parallel_model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "                           optimizer=keras.optimizers.Adadelta(),\n",
    "                           metrics=['accuracy'])\n",
    "else:\n",
    "    model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "                  optimizer=keras.optimizers.Adadelta(),\n",
    "                  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(model, to_file='whale_model_01.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/33\n",
      "32/32 [==============================] - 19s 600ms/step - loss: 7.9336 - acc: 0.0764\n",
      "Epoch 2/33\n",
      "32/32 [==============================] - 19s 604ms/step - loss: 7.8955 - acc: 0.0776\n",
      "Epoch 3/33\n",
      "32/32 [==============================] - 19s 596ms/step - loss: 7.8952 - acc: 0.0751\n",
      "Epoch 4/33\n",
      "32/32 [==============================] - 19s 599ms/step - loss: 7.8753 - acc: 0.0762\n",
      "Epoch 5/33\n",
      "32/32 [==============================] - 19s 599ms/step - loss: 7.8720 - acc: 0.0778\n",
      "Epoch 6/33\n",
      "32/32 [==============================] - 19s 602ms/step - loss: 7.8466 - acc: 0.0776\n",
      "Epoch 7/33\n",
      "32/32 [==============================] - 19s 607ms/step - loss: 7.8480 - acc: 0.0744\n",
      "Epoch 8/33\n",
      "32/32 [==============================] - 19s 601ms/step - loss: 7.8499 - acc: 0.0743\n"
     ]
    }
   ],
   "source": [
    "tbCallBack = [keras.callbacks.EarlyStopping(monitor='loss', \n",
    "                                            min_delta=0.001, \n",
    "                                            patience=5, \n",
    "                                            verbose=0, \n",
    "                                            mode='auto')]\n",
    "\n",
    "#keras.callbacks.TensorBoard(log_dir='/tmp/tensorboard_log', \n",
    "#                                          histogram_freq=1, \n",
    "#                                          write_graph=True, \n",
    "#                                          write_images=True),\n",
    "\n",
    "if isMultiGPU:\n",
    "    parallel_model.fit_generator(image_gen.flow(x_train, y_train.toarray(), \n",
    "                                                batch_size=batch_size),\n",
    "                                 steps_per_epoch=x_train.shape[0]//batch_size,\n",
    "                                 epochs=epochs,\n",
    "                                 shuffle=True,\n",
    "                                 verbose=1,\n",
    "                                 callbacks=tbCallBack)\n",
    "else:\n",
    "    model.fit_generator(image_gen.flow(x_train, y_train.toarray(), \n",
    "                                       batch_size=batch_size),\n",
    "                        steps_per_epoch=x_train.shape[0]//batch_size,\n",
    "                        epochs=epochs,\n",
    "                        verbose=1,\n",
    "                        class_weight=class_weight_dict,\n",
    "                        callbacks=tbCallBack)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions on test samples and export for submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4min 12s, sys: 12.3 s, total: 4min 24s\n",
      "Wall time: 6min 53s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import warnings\n",
    "import os\n",
    "sub_name = 'submission_{}.csv'.format(datetime.now().strftime('%Y%m%d%H%M%S'))\n",
    "with open(str(main_path / sub_name), 'w') as f:\n",
    "    with warnings.catch_warnings():\n",
    "        f.write(\"Image,Id\\n\")\n",
    "        warnings.filterwarnings('ignore', category=DeprecationWarning)\n",
    "        for img in test_image:\n",
    "            tmp_img = ImportImage(img)\n",
    "            x = tmp_img.astype('float32')\n",
    "            x = image_gen.standardize(x.reshape(1, SIZE, SIZE, 3))\n",
    "            y = model.predict_proba(x.reshape(1, SIZE, SIZE, 3))        \n",
    "            predicted_args = np.argsort(y)[0][::-1][:5]\n",
    "            predicted_tags = lohe.inverse_labels(predicted_args)\n",
    "            img = os.path.split(img)[-1]\n",
    "            predicted_tags = \" \".join(predicted_tags)\n",
    "            f.write('%s,%s\\n' %(img, predicted_tags))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((100, 100, 3), (1, 100, 100, 3))"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_img.shape, x.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
